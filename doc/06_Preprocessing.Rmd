---
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  collpse = TRUE,
  comment = "$>"
  )
library(mlr)
set.seed(123)
```

# データの前処理

データの前処理というのは、学習アルゴリズムを適用する前にデータに施すあらゆる種類の変換のことだ。例えば、データの矛盾の発見と解決、欠損値への代入、外れ値の特定・除去・置換、数値データの離散化、カテゴリカルデータからのダミー変数の生成、標準化やBox-Cox変換などのあらゆる種類の変換、次元削減、特徴量の抽出・選択などが含まれる。

`mlr`は前処理に関して幾つかの選択肢を用意している。以下に示すようなタスク(あるいはデータフレーム)を変更する単純な手法の中には、タスクについての説明で既に触れたものもある。

- `capLargeValues`: 大きな値や無限大の値の変換。
- `createDummyFeature`: 因子型特徴量からのダミー変数の生成。
- `dropFeatures`: 特徴量の削除。
- `joinClassLevels`: (分類のみ)複数のクラスを併合して、大きな1つのクラスにする。
- `mergeSmallFactorLevels`: 因子型特徴量において、例数の少ない水準を併合する。
- `normalizeFeatures`: 正規化には複数の異なったやり方がある。標準化や特定の範囲への再スケールなど。
- `removeConstantFeatures`: 1つの値しか持っていない特徴量(=定数)を除去する。
- `subsetTask`: 観測値や特徴量をタスクから除去する。

また、以下のものについてはチュートリアルを用意してある。

- 特徴量選択
- 欠損値への代入

## 前処理と学習器を融合する

`mlr`のラッパー機能により、学習器と前処理を組み合わせることができる。これは、前処理が学習器に属し、訓練や予測の度に実行されるということを意味する。

このようにすることで非常に便利な点がある。データやタスクの変更なしに、簡単に学習器と前処理の組合せを変えることができるのだ。

また、これは前処理を行ってから学習器のパフォーマンスを測定する際にありがちな一般的な間違いを避けることにもつながる。前処理は学習アルゴリズムとは完全に独立したものだと考えられがちだ。学習器のパフォーマンスを測定する場合を考えてみよう。例えば、クロスバリデーションで雨処理を事前にデータセット全体に対して行い、学習と予測は学習器だけで行うような場合だ。前処理として何が行われたかによっては、評価が楽観的になる危険性がある。例えば、(欠損値への)平均値の代入という前処理が学習器の性能評価前に、データ全体を対象に行われたとすると、これは楽観的なパフォーマンス評価につながる。

前処理にはデータ依存的なものとデータ非依存的なものがあることをはっきりさせておこう。データ依存的な前処理とは、前処理のやり方がデータに依存しており、データセットが異なれば結果も異なるというようなもののことだ。一方でデータ非依存的な前処理は常に結果が同じになる。

データの間違いを修正したり、ID列のような学習に使うべきではないデータ列の除去のような前処理は、明らかにデータ非依存的である。一方、先程例に挙げた欠損値への平均値の代入はデータ依存的である。代入を定数で行うのであれば違うが。

前処理と組み合わせた学習器の性能評価を正しく行うためには、全てのデータ依存的な前処理をリサンプリングに含める必要がある。学習器と前処理を融合させれば、これは自動的に可能になる。

この目的のために、`mlr`パッケージは2つのラッパーを用意している。

- `makePreprocWrapperCaret`は`caret`パッケージの`preProcess`関数による前処理オプションのためのインターフェースである。
- `makePreprocWrapper`を使えば、訓練と予測の前の動作を定義することで独自の前処理を作成できる。

