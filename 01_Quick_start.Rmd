# Quick start

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  collpse = TRUE,
  comment = "$>"
  )
set.seed(1)
library(mlr)
```

もしまだ`mlr`パッケージをインストールしていなければインストールしておこう。依存パッケージまで含めるとかなり時間がかかるかもしれない。インストールしたらパッケージを読み込んでおこう。

```r
install.packages("mlr", dependencies = TRUE)
library(mlr)
```

なお、これ以降は`mlr`は読み込み済みだと仮定して話を進める。

インストールが終わったら簡単に`mlr`のワークフローをみてみよう。`mlr`で機械学習の問題を扱う場合の流れは、大雑把に言って5つのステップに分けることができる。

1. タスクの定義
2. 学習器の定義
3. 訓練
4. 予測
5. 評価

## タスクの定義

まずはタスクを定義する。タスクはすぐ次のセクションで説明するが、問題の概要をまとめたオブジェクトのことだ。ここには問題の種類や、扱うデータセットに関する情報が含まれる。以下ではデータセット`iris`を対象に、分類問題のタスクを定義している。

```{r}
task = makeClassifTask(data = iris, target = "Species")
```

## 学習器の定義

ここでは学習器オブジェクトを作成して、タスクに対してどのようなアルゴリズムを適用するかを決定する。このアルゴリズム自体はいろいろなパッケージで実装されているものだが、`mlr`を使うと、これらを統一したインターフェースで取り扱うことができる。以下では分類手法として線形判別分析を指定している。

```{r}
lrn = makeLearner("classif.lda")
```

## (データを訓練セットとテストセットに分割する)

ここではデータセットを訓練セットとテストセットに分割しているが、これは本来`mlr`を使用する場合は行う必要の無い作業だという点に注意してもらいたい。`mlr`にはこのような作業を行うためのもっと良い方法が用意されているが、今はここでの説明を簡単にするためにこのような方法を採っているだけだ。

```{r}
n = nrow(iris)
train.set = sample(n, size = 2/3*n)
test.set = setdiff(1:n, train.set)
```

一応何をしているか説明しておくと、`iris`の行数に対応するインデックスを、無作為に訓練用とテスト用に割り振っている。

## 訓練 

訓練は基本的には作成した学習器とタスクのオブジェクトを`train`関数に渡すと実行できる。ここでは先程作成した訓練セットのインデックスを利用して、タスク内のデータセットから訓練に使用する部分を指定している。

```{r}
model = train(lrn, task, subset = train.set)
```

## 予測

訓練セットを適合したフィット済みモデルを使って、新しいデータに対する出力を予測するには`predict`関数を使う。Rの他の関数(`lm`や`glm`など)と基本的には使い方は同じだ。

```{r}
pred = predict(model, task = task, subset = test.set)
```

## 評価

`mlr`にはいろいろな指標でフィット済みモデルを評価する方法が備えられている。以下では予測結果から性能指標を計算している。

```{r}
performance(pred, measures = list(mmce, acc))
```

誤分類率`r performance(pred, mmce)`、精度`r performance(pred, acc)`で分類できた、という結果が得られた。

なお、ここでは色々と**もっと良いやり方**を省略していることに注意してほしい。では、もっと良いやり方をこの先のセクションで順次見ていこう。