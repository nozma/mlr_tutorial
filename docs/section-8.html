<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>mlrパッケージチュートリアル</title>
  <meta name="description" content="mlrパッケージチュートリアル">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="mlrパッケージチュートリアル" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="mlrパッケージチュートリアル" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-7.html">
<link rel="next" href="section-9.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="1" data-path="quick-start.html"><a href="quick-start.html"><i class="fa fa-check"></i><b>1</b> Quick start</a><ul>
<li class="chapter" data-level="1.1" data-path="quick-start.html"><a href="quick-start.html#section-1.1"><i class="fa fa-check"></i><b>1.1</b> タスクの定義</a></li>
<li class="chapter" data-level="1.2" data-path="quick-start.html"><a href="quick-start.html#section-1.2"><i class="fa fa-check"></i><b>1.2</b> 学習器の定義</a></li>
<li class="chapter" data-level="1.3" data-path="quick-start.html"><a href="quick-start.html#section-1.3"><i class="fa fa-check"></i><b>1.3</b> (データを訓練セットとテストセットに分割する)</a></li>
<li class="chapter" data-level="1.4" data-path="quick-start.html"><a href="quick-start.html#section-1.4"><i class="fa fa-check"></i><b>1.4</b> 訓練</a></li>
<li class="chapter" data-level="1.5" data-path="quick-start.html"><a href="quick-start.html#section-1.5"><i class="fa fa-check"></i><b>1.5</b> 予測</a></li>
<li class="chapter" data-level="1.6" data-path="quick-start.html"><a href="quick-start.html#section-1.6"><i class="fa fa-check"></i><b>1.6</b> 評価</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> タスク</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> タスクの種類と作成</a><ul>
<li class="chapter" data-level="2.1.1" data-path="section-2.html"><a href="section-2.html#section-2.1.1"><i class="fa fa-check"></i><b>2.1.1</b> 回帰</a></li>
<li class="chapter" data-level="2.1.2" data-path="section-2.html"><a href="section-2.html#section-2.1.2"><i class="fa fa-check"></i><b>2.1.2</b> 分類</a></li>
<li class="chapter" data-level="2.1.3" data-path="section-2.html"><a href="section-2.html#section-2.1.3"><i class="fa fa-check"></i><b>2.1.3</b> 生存時間分析</a></li>
<li class="chapter" data-level="2.1.4" data-path="section-2.html"><a href="section-2.html#section-2.1.4"><i class="fa fa-check"></i><b>2.1.4</b> マルチラベル分類</a></li>
<li class="chapter" data-level="2.1.5" data-path="section-2.html"><a href="section-2.html#section-2.1.5"><i class="fa fa-check"></i><b>2.1.5</b> クラスター分析</a></li>
<li class="chapter" data-level="2.1.6" data-path="section-2.html"><a href="section-2.html#section-2.1.6"><i class="fa fa-check"></i><b>2.1.6</b> コスト考慮型分類</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> その他の設定</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> タスクへのアクセス</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> タスクの編集</a></li>
<li class="chapter" data-level="2.5" data-path="section-2.html"><a href="section-2.html#section-2.5"><i class="fa fa-check"></i><b>2.5</b> タスクの例と便利な関数</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 学習器</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 学習器を構築する</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 学習器へアクセスする</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 学習器の編集</a></li>
<li class="chapter" data-level="3.4" data-path="section-3.html"><a href="section-3.html#section-3.4"><i class="fa fa-check"></i><b>3.4</b> 学習器一覧</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 学習器の訓練</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 学習器モデルへのアクセス</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> その他のオプションとコメント</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="-1.html"><a href="-1.html"><i class="fa fa-check"></i><b>5</b> 予測</a><ul>
<li class="chapter" data-level="5.1" data-path="-1.html"><a href="-1.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 新しいデータに対する結果を予測する</a></li>
<li class="chapter" data-level="5.2" data-path="-1.html"><a href="-1.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 予測へのアクセス</a></li>
<li class="chapter" data-level="5.3" data-path="-1.html"><a href="-1.html#-"><i class="fa fa-check"></i><b>5.3</b> 回帰: 標準誤差を取得する</a></li>
<li class="chapter" data-level="5.4" data-path="-1.html"><a href="-1.html#-"><i class="fa fa-check"></i><b>5.4</b> 分類とクラスタリング: 確率を取得する</a></li>
<li class="chapter" data-level="5.5" data-path="-1.html"><a href="-1.html#-"><i class="fa fa-check"></i><b>5.5</b> 分類: 混同行列を取得する</a></li>
<li class="chapter" data-level="5.6" data-path="-1.html"><a href="-1.html#-"><i class="fa fa-check"></i><b>5.6</b> 分類: 決定閾値の調整</a></li>
<li class="chapter" data-level="5.7" data-path="-1.html"><a href="-1.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 予測の可視化</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> データの前処理</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 前処理と学習器を融合する</a></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#makepreprocwrappercaret"><i class="fa fa-check"></i><b>6.2</b> <code>makePreprocWrapperCaret</code>を使用した前処理</a></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 前処理オプションと学習器パラメータの連結チューニング</a></li>
<li class="chapter" data-level="6.4" data-path="section-6.html"><a href="section-6.html#section-6.4"><i class="fa fa-check"></i><b>6.4</b> 独自の前処理ラッパーを書く</a><ul>
<li class="chapter" data-level="6.4.1" data-path="section-6.html"><a href="section-6.html#section-6.4.1"><i class="fa fa-check"></i><b>6.4.1</b> 訓練関数の指定</a></li>
<li class="chapter" data-level="6.4.2" data-path="section-6.html"><a href="section-6.html#section-6.4.2"><i class="fa fa-check"></i><b>6.4.2</b> 予測関数の指定</a></li>
<li class="chapter" data-level="6.4.3" data-path="section-6.html"><a href="section-6.html#section-6.4.3"><i class="fa fa-check"></i><b>6.4.3</b> 前処理ラッパーの作成</a></li>
<li class="chapter" data-level="6.4.4" data-path="section-6.html"><a href="section-6.html#section-6.4.4"><i class="fa fa-check"></i><b>6.4.4</b> 前処理と学習器のパラメータを連結してチューニングする</a></li>
<li class="chapter" data-level="6.4.5" data-path="section-6.html"><a href="section-6.html#section-6.4.5"><i class="fa fa-check"></i><b>6.4.5</b> 前処理ラッパー関数</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 学習器の性能を評価する</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 利用可能な性能指標</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 指標の一覧</a></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 性能指標を計算する</a></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#section-7.4"><i class="fa fa-check"></i><b>7.4</b> 指標計算に必要な情報</a></li>
<li class="chapter" data-level="7.5" data-path="section-7.html"><a href="section-7.html#section-7.5"><i class="fa fa-check"></i><b>7.5</b> 性能指標へのアクセス</a></li>
<li class="chapter" data-level="7.6" data-path="section-7.html"><a href="section-7.html#section-7.6"><i class="fa fa-check"></i><b>7.6</b> 2クラス分類</a><ul>
<li class="chapter" data-level="7.6.1" data-path="section-7.html"><a href="section-7.html#section-7.6.1"><i class="fa fa-check"></i><b>7.6.1</b> 性能と閾値の関係をプロットする</a></li>
<li class="chapter" data-level="7.6.2" data-path="section-7.html"><a href="section-7.html#roc"><i class="fa fa-check"></i><b>7.6.2</b> ROC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> リサンプリング</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> リサンプリング手法を決める</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> リサンプリングを実行する</a></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#section-8.3"><i class="fa fa-check"></i><b>8.3</b> リサンプル結果へのアクセス</a><ul>
<li class="chapter" data-level="8.3.1" data-path="section-8.html"><a href="section-8.html#section-8.3.1"><i class="fa fa-check"></i><b>8.3.1</b> 予測値</a></li>
<li class="chapter" data-level="8.3.2" data-path="section-8.html"><a href="section-8.html#section-8.3.2"><i class="fa fa-check"></i><b>8.3.2</b> 訓練済みモデルの抽出</a></li>
<li class="chapter" data-level="8.3.3" data-path="section-8.html"><a href="section-8.html#section-8.3.3"><i class="fa fa-check"></i><b>8.3.3</b> 他の抽出方法</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="section-8.html"><a href="section-8.html#section-8.4"><i class="fa fa-check"></i><b>8.4</b> 階層化とブロック化</a><ul>
<li class="chapter" data-level="8.4.1" data-path="section-8.html"><a href="section-8.html#section-8.4.1"><i class="fa fa-check"></i><b>8.4.1</b> 目的変数の階層化</a></li>
<li class="chapter" data-level="8.4.2" data-path="section-8.html"><a href="section-8.html#section-8.4.2"><i class="fa fa-check"></i><b>8.4.2</b> 説明変数の階層化</a></li>
<li class="chapter" data-level="8.4.3" data-path="section-8.html"><a href="section-8.html#section-8.4.3"><i class="fa fa-check"></i><b>8.4.3</b> ブロック化</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="section-8.html"><a href="section-8.html#section-8.5"><i class="fa fa-check"></i><b>8.5</b> リサンプリングの詳細とリサンプルのインスタンス</a></li>
<li class="chapter" data-level="8.6" data-path="section-8.html"><a href="section-8.html#section-8.6"><i class="fa fa-check"></i><b>8.6</b> 性能指標の集約</a><ul>
<li class="chapter" data-level="8.6.1" data-path="-1.html"><a href="-1.html#-"><i class="fa fa-check"></i><b>8.6.1</b> 例: 一つの指標に複数の集約方法</a></li>
<li class="chapter" data-level="8.6.2" data-path="-1.html"><a href="-1.html#-"><i class="fa fa-check"></i><b>8.6.2</b> 例: 訓練セットの誤差を計算する</a></li>
<li class="chapter" data-level="8.6.3" data-path="-1.html"><a href="-1.html#-"><i class="fa fa-check"></i><b>8.6.3</b> 例: ブートストラップ</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="section-8.html"><a href="section-8.html#section-8.7"><i class="fa fa-check"></i><b>8.7</b> 便利な関数</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> ハイパーパラメータのチューニング</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> パラメータ探索空間の指定</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 最適化アルゴリズムの指定</a></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> チューニングの実行</a></li>
<li class="chapter" data-level="9.4" data-path="section-9.html"><a href="section-9.html#section-9.4"><i class="fa fa-check"></i><b>9.4</b> チューニング結果へのアクセス</a></li>
<li class="chapter" data-level="9.5" data-path="section-9.html"><a href="section-9.html#section-9.5"><i class="fa fa-check"></i><b>9.5</b> ハイパーパラメータチューニングの影響を調査する</a></li>
<li class="chapter" data-level="9.6" data-path="section-9.html"><a href="section-9.html#section-9.6"><i class="fa fa-check"></i><b>9.6</b> その他いろいろ</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> ベンチマーク試験</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> ベンチマーク試験の実施</a><ul>
<li class="chapter" data-level="10.1.1" data-path="section-10.html"><a href="section-10.html#section-10.1.1"><i class="fa fa-check"></i><b>10.1.1</b> 実験を再現可能にする</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> ベンチマーク結果へのアクセス</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-10.html"><a href="section-10.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 学習器の性能</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-10.html"><a href="section-10.html#-2"><i class="fa fa-check"></i><b>10.2.2</b> 予測</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-10.html"><a href="section-10.html#id"><i class="fa fa-check"></i><b>10.2.3</b> ID</a></li>
<li class="chapter" data-level="10.2.4" data-path="section-10.html"><a href="section-10.html#section-10.2.4"><i class="fa fa-check"></i><b>10.2.4</b> フィット済みモデル</a></li>
<li class="chapter" data-level="10.2.5" data-path="section-10.html"><a href="section-10.html#section-10.2.5"><i class="fa fa-check"></i><b>10.2.5</b> 学習器と性能指標</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> ベンチマーク結果のマージ</a></li>
<li class="chapter" data-level="10.4" data-path="section-10.html"><a href="section-10.html#section-10.4"><i class="fa fa-check"></i><b>10.4</b> ベンチマークの分析と可視化</a><ul>
<li class="chapter" data-level="10.4.1" data-path="section-10.html"><a href="section-10.html#section-10.4.1"><i class="fa fa-check"></i><b>10.4.1</b> 例：線形判別分析と分類木、ランダムフォレストの比較</a></li>
<li class="chapter" data-level="10.4.2" data-path="section-10.html"><a href="section-10.html#section-10.4.2"><i class="fa fa-check"></i><b>10.4.2</b> 可視化</a></li>
<li class="chapter" data-level="10.4.3" data-path="section-10.html"><a href="section-10.html#section-10.4.3"><i class="fa fa-check"></i><b>10.4.3</b> 集約結果の可視化</a></li>
<li class="chapter" data-level="10.4.4" data-path="section-10.html"><a href="section-10.html#section-10.4.4"><i class="fa fa-check"></i><b>10.4.4</b> 順位の計算と可視化</a></li>
<li class="chapter" data-level="10.4.5" data-path="section-10.html"><a href="section-10.html#section-10.4.5"><i class="fa fa-check"></i><b>10.4.5</b> 仮説検定で学習器を比較する</a></li>
<li class="chapter" data-level="10.4.6" data-path="section-10.html"><a href="section-10.html#section-10.4.6"><i class="fa fa-check"></i><b>10.4.6</b> 臨界差ダイアグラム</a></li>
<li class="chapter" data-level="10.4.7" data-path="section-10.html"><a href="section-10.html#section-10.4.7"><i class="fa fa-check"></i><b>10.4.7</b> プロットの調整</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="section-10.html"><a href="section-10.html#section-10.5"><i class="fa fa-check"></i><b>10.5</b> その他のコメント</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 並列化</a><ul>
<li class="chapter" data-level="11.1" data-path="section-11.html"><a href="section-11.html#section-11.1"><i class="fa fa-check"></i><b>11.1</b> 並列化レベル</a></li>
<li class="chapter" data-level="11.2" data-path="section-11.html"><a href="section-11.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 自作の学習器と並列化</a></li>
<li class="chapter" data-level="11.3" data-path="section-11.html"><a href="section-11.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 並列化の話はこれで終わりだ！</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> いろいろな可視化</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#generationplotting"><i class="fa fa-check"></i><b>12.1</b> generation関数とplotting関数</a><ul>
<li class="chapter" data-level="12.1.1" data-path="section-12.html"><a href="section-12.html#section-12.1.1"><i class="fa fa-check"></i><b>12.1.1</b> 例</a></li>
<li class="chapter" data-level="12.1.2" data-path="section-12.html"><a href="section-12.html#section-12.1.2"><i class="fa fa-check"></i><b>12.1.2</b> プロットのカスタマイズ</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="section-12.html"><a href="section-12.html#generationplotting"><i class="fa fa-check"></i><b>12.2</b> 利用可能なgeneration関数とplotting関数</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">mlrパッケージチュートリアル</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-8" class="section level1">
<h1><span class="header-section-number">Section 8</span> リサンプリング</h1>
<p>一般的に学習機の性能評価はリサンプリングを通じて行われる。リサンプリングの概要は次のようなものである。まず、データセット全体を<span class="math inline">\(D\)</span>として、これを訓練セット<span class="math inline">\(D^{*b}\)</span>とテストセット<span class="math inline">\(D\setminus D^{*b}\)</span>に分割する。この種の分割を<span class="math inline">\(B\)</span>回行う(つまり、<span class="math inline">\(b = 1,...,B\)</span>とする)。そして、それぞれのテストセット、訓練セットの対を用いて訓練と予測を行い、性能指標<span class="math inline">\(S(D^{*b}, D\setminus D^{*b}\)</span>)を計算する。これにより<span class="math inline">\(B\)</span>個の性能指標が得られるが、これを集約する(一般的には平均値が用いられる)。リサンプリングの方法には、クロスバリデーションやブートストラップなど様々な手法が存在する。</p>
<p>もしさらに詳しく知りたいのであれば、Simonによる論文(<a href="https://link.springer.com/chapter/10.1007%2F978-0-387-47509-7_8">Resampling Strategies for Model Assessment and Selection | SpringerLink</a>)を読むのは悪い選択ではないだろう。また、Berndらによる論文、<a href="https://www.mitpressjournals.org/doi/pdf/10.1162/EVCO_a_00069">Resampling methods for meta-model validation with recommendations for evolutionary computation</a>では、リサンプリング手法の統計的な背景に対して多くの説明がなされている。</p>
<div id="section-8.1" class="section level2">
<h2><span class="header-section-number">8.1</span> リサンプリング手法を決める</h2>
<p><code>mlr</code>では<code>makeResampleDesc</code>関数を使ってリサンプリング手法を設定する。この関数にはリサンプリング手法の名前とともに、手法に応じてその他の情報(例えば繰り返し数など)を指定する。サポートしているサンプリング手法は以下のとおりである。</p>
<ul>
<li><code>CV</code>: クロスバリデーション(Cross-varidation)</li>
<li><code>LOO</code>: 一つ抜き法(Leave-one-out cross-varidation)</li>
<li><code>RepCV</code>: Repeatedクロスバリデーション(Repeated cross-varidation)</li>
<li><code>Bootstrap</code>: out-of-bagブートストラップとそのバリエーション(b632等)</li>
<li><code>Subsample</code>: サブサンプリング(モンテカルロクロスバリデーションとも呼ばれる)</li>
<li><code>Holdout</code>: ホールドアウト法</li>
</ul>
<p>3-fold(3分割)クロスバリデーションの場合は</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iters =</span> <span class="dv">3</span>)
rdesc</code></pre></div>
<pre><code>$&gt; Resample description: cross-validation with 3 iterations.
$&gt; Predict: test
$&gt; Stratification: FALSE</code></pre>
<p>ホールドアウト法の場合は</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;Holdout&quot;</span>)
rdesc</code></pre></div>
<pre><code>$&gt; Resample description: holdout with 0.67 split rate.
$&gt; Predict: test
$&gt; Stratification: FALSE</code></pre>
<p>という具合だ。</p>
<p>これらのリサンプルdescriptionのうち、よく使うものは予め別名が用意してある。例えばホールドアウト法は<code>hout</code>、クロスバリデーションは<code>cv5</code>や<code>cv10</code>などよく使う分割数に対して定義してある。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hout</code></pre></div>
<pre><code>$&gt; Resample description: holdout with 0.67 split rate.
$&gt; Predict: test
$&gt; Stratification: FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cv3</code></pre></div>
<pre><code>$&gt; Resample description: cross-validation with 3 iterations.
$&gt; Predict: test
$&gt; Stratification: FALSE</code></pre>
</div>
<div id="section-8.2" class="section level2">
<h2><span class="header-section-number">8.2</span> リサンプリングを実行する</h2>
<p><code>resample</code>関数は指定されたリサンプリング手法により、学習機をタスク上で評価する。</p>
<p>最初の例として、<code>BostonHousing</code>データに対する線形回帰を3分割クロスバリデーションで評価してみよう。</p>
<p><span class="math inline">\(K\)</span>分割クロスバリデーションはデータセット<span class="math inline">\(D\)</span>を<span class="math inline">\(K\)</span>個の(ほぼ)等しいサイズのサブセットに分割する。<span class="math inline">\(K\)</span>回の繰り返しの<span class="math inline">\(b\)</span>番目では、<span class="math inline">\(b\)</span>番目のサブセットがテストに、残りが訓練に使用される。</p>
<p><code>resample</code>関数に学習器を指定する際には、<code>Learner</code>クラスのオブジェクトか学習器の名前(<code>regr.lm</code>など)のいずれを渡しても良い。性能指標は指定しなければ学習器に応じたデフォルトが使用される(回帰の場合は平均二乗誤差)。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iters =</span> <span class="dv">3</span>)

r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;regr.lm&quot;</span>, bh.task, rdesc)</code></pre></div>
<pre><code>$&gt; [Resample] cross-validation iter 1: mse.test.mean=20.7
$&gt; [Resample] cross-validation iter 2: mse.test.mean=  25
$&gt; [Resample] cross-validation iter 3: mse.test.mean=25.3
$&gt; [Resample] Aggr. Result: mse.test.mean=23.7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: BostonHousing-example
$&gt; Learner: regr.lm
$&gt; Aggr perf: mse.test.mean=23.7
$&gt; Runtime: 0.041254</code></pre>
<p>ここで<code>r</code>に格納したオブジェクトは<code>ResampleResult</code>クラスである。この中には評価結果の他に、実行時間や予測値、リサンプリング毎のフィット済みモデルなどが格納されている。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 中身をざっと確認
<span class="kw">names</span>(r)</code></pre></div>
<pre><code>$&gt;  [1] &quot;learner.id&quot;     &quot;task.id&quot;        &quot;task.desc&quot;      &quot;measures.train&quot;
$&gt;  [5] &quot;measures.test&quot;  &quot;aggr&quot;           &quot;pred&quot;           &quot;models&quot;        
$&gt;  [9] &quot;err.msgs&quot;       &quot;err.dumps&quot;      &quot;extract&quot;        &quot;runtime&quot;</code></pre>
<p><code>r$measures.test</code>には各テストセットの性能指標が入っている。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 各テストセットの性能指標
r<span class="op">$</span>measures.test</code></pre></div>
<pre><code>$&gt;   iter      mse
$&gt; 1    1 20.74068
$&gt; 2    2 25.00755
$&gt; 3    3 25.25456</code></pre>
<p><code>r$aggr</code>には集約(aggrigate)後の性能指標が入っている。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 集約後の性能指標
r<span class="op">$</span>aggr</code></pre></div>
<pre><code>$&gt; mse.test.mean 
$&gt;       23.6676</code></pre>
<p>名前<code>mse.test.mean</code>は、性能指標が<code>mse</code>であり、<code>test.mean</code>によりデータが集約されていることを表している。<code>test.mean</code>は多くの性能指標においてデフォルトの集約方法であり、その名前が示すようにテストデータの性能指標の平均値である。</p>
<p><code>mlr</code>ではどのような種類の学習器も同じようにリサンプリングを行える。以下では、分類問題の例として<code>Sonar</code>データセットに対する分類木を5反復のサブサンプリングで評価してみよう。</p>
<p>サブサンプリングの各繰り返しでは、データセット<span class="math inline">\(D\)</span>はランダムに訓練データとテストデータに分割される。このとき、テストデータには指定の割合のデータ数が割り当てられる。この反復が1の場合はホールドアウト法と同じである。</p>
<p>評価したい性能指標はリストとしてまとめて指定することもできる。以下の例では平均誤分類、偽陽性・偽陰性率、訓練時間を指定している。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;Subsample&quot;</span>, <span class="dt">iter =</span> <span class="dv">5</span>, <span class="dt">split =</span> <span class="dv">4</span><span class="op">/</span><span class="dv">5</span>)
lrn =<span class="st"> </span><span class="kw">makeLearner</span>(<span class="st">&quot;classif.rpart&quot;</span>, <span class="dt">parms =</span> <span class="kw">list</span>(<span class="dt">split =</span> <span class="st">&quot;information&quot;</span>))
r =<span class="st"> </span><span class="kw">resample</span>(lrn, sonar.task, rdesc, <span class="dt">measures =</span> <span class="kw">list</span>(mmce, fpr, fnr, timetrain))</code></pre></div>
<pre><code>$&gt; [Resample] subsampling iter 1: mmce.test.mean=0.19,fpr.test.mean=0.263,fnr.test.mean=0.13,timetrain.test.mean=0.015
$&gt; [Resample] subsampling iter 2: mmce.test.mean=0.286,fpr.test.mean= 0.2,fnr.test.mean=0.333,timetrain.test.mean=0.016
$&gt; [Resample] subsampling iter 3: mmce.test.mean=0.167,fpr.test.mean=0.263,fnr.test.mean=0.087,timetrain.test.mean=0.015
$&gt; [Resample] subsampling iter 4: mmce.test.mean=0.286,fpr.test.mean= 0.4,fnr.test.mean=0.182,timetrain.test.mean=0.014
$&gt; [Resample] subsampling iter 5: mmce.test.mean=0.238,fpr.test.mean=0.278,fnr.test.mean=0.208,timetrain.test.mean=0.015
$&gt; [Resample] Aggr. Result: mmce.test.mean=0.233,fpr.test.mean=0.281,fnr.test.mean=0.188,timetrain.test.mean=0.015</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: Sonar-example
$&gt; Learner: classif.rpart
$&gt; Aggr perf: mmce.test.mean=0.233,fpr.test.mean=0.281,fnr.test.mean=0.188,timetrain.test.mean=0.015
$&gt; Runtime: 0.145858</code></pre>
<p>もし指標を後から追加したくなったら、<code>addRRMeasure</code>関数を使うと良い。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">addRRMeasure</span>(r, <span class="kw">list</span>(ber, timepredict))</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: Sonar-example
$&gt; Learner: classif.rpart
$&gt; Aggr perf: mmce.test.mean=0.233,fpr.test.mean=0.281,fnr.test.mean=0.188,timetrain.test.mean=0.015,ber.test.mean=0.234,timepredict.test.mean=0.0056
$&gt; Runtime: 0.145858</code></pre>
<p>デフォルトでは<code>resample</code>関数は進捗と途中結果を表示するが、<code>show.info=FALSE</code>で非表示にもできる。このようなメッセージを完全に制御したかったら、<a href="https://mlr-org.github.io/mlr-tutorial/devel/html/configureMlr/index.html">Configuration - mlr tutorial</a>を確認してもらいたい。</p>
<p>上記例では学習器を明示的に作成してから<code>resample</code>に渡したが、代わりに学習器の名前を指定しても良い。その場合、学習器のパラメータは<code>...</code>引数を通じて渡すことができる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">resample</span>(<span class="st">&quot;classif.rpart&quot;</span>, <span class="dt">parms =</span> <span class="kw">list</span>(<span class="dt">split =</span> <span class="st">&quot;information&quot;</span>), sonar.task, rdesc,
         <span class="dt">measures =</span> <span class="kw">list</span>(mmce, fpr, fnr, timetrain), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: Sonar-example
$&gt; Learner: classif.rpart
$&gt; Aggr perf: mmce.test.mean=0.262,fpr.test.mean=0.256,fnr.test.mean=0.273,timetrain.test.mean=0.0152
$&gt; Runtime: 0.138143</code></pre>
</div>
<div id="section-8.3" class="section level2">
<h2><span class="header-section-number">8.3</span> リサンプル結果へのアクセス</h2>
<p>学習器の性能以外にも、リサンプル結果から様々な情報を得ることが出来る。例えばリサンプリングの各繰り返しに対応する予測値やフィット済みモデル等だ。以下で情報の取得の仕方をみていこう。</p>
<div id="section-8.3.1" class="section level3">
<h3><span class="header-section-number">8.3.1</span> 予測値</h3>
<p>デフォルトでは、<code>ResampleResult</code>はリサンプリングで得た予測値を含んでいる。メモリ節約などの目的でこれを止めさせたければ、<code>resample</code>関数に<code>keep.pred = FALSE</code>を指定する。</p>
<p>予測値は<code>$pred</code>スロットに格納されている。また、<code>getRRPredictions</code>関数を使ってアクセスすることもできる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r<span class="op">$</span>pred</code></pre></div>
<pre><code>$&gt; Resampled Prediction for:
$&gt; Resample description: subsampling with 5 iterations and 0.80 split rate.
$&gt; Predict: test
$&gt; Stratification: FALSE
$&gt; predict.type: response
$&gt; threshold: 
$&gt; time (mean): 0.01
$&gt;    id truth response iter  set
$&gt; 1 194     M        M    1 test
$&gt; 2  59     R        R    1 test
$&gt; 3 113     M        R    1 test
$&gt; 4 191     M        M    1 test
$&gt; 5  32     R        M    1 test
$&gt; 6 170     M        M    1 test
$&gt; ... (210 rows, 5 cols)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred =<span class="st"> </span><span class="kw">getRRPredictions</span>(r)
pred</code></pre></div>
<pre><code>$&gt; Resampled Prediction for:
$&gt; Resample description: subsampling with 5 iterations and 0.80 split rate.
$&gt; Predict: test
$&gt; Stratification: FALSE
$&gt; predict.type: response
$&gt; threshold: 
$&gt; time (mean): 0.01
$&gt;    id truth response iter  set
$&gt; 1 194     M        M    1 test
$&gt; 2  59     R        R    1 test
$&gt; 3 113     M        R    1 test
$&gt; 4 191     M        M    1 test
$&gt; 5  32     R        M    1 test
$&gt; 6 170     M        M    1 test
$&gt; ... (210 rows, 5 cols)</code></pre>
<p>ここで作成した<code>pred</code>は<code>ResamplePrediction</code>クラスのオブジェクトである。これは<code>Prediction</code>オブジェクトのように<code>$data</code>にデータフレームとして予測値と真値(教師あり学習の場合)が格納されている。<code>as.data.frame</code>を使って直接<code>$data</code>スロットの中身を取得できる。さらに、<code>Prediction</code>オブジェクトに対するゲッター関数は全て利用可能である。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">as.data.frame</span>(pred))</code></pre></div>
<pre><code>$&gt;    id truth response iter  set
$&gt; 1 194     M        M    1 test
$&gt; 2  59     R        R    1 test
$&gt; 3 113     M        R    1 test
$&gt; 4 191     M        M    1 test
$&gt; 5  32     R        M    1 test
$&gt; 6 170     M        M    1 test</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">getPredictionTruth</span>(pred))</code></pre></div>
<pre><code>$&gt; [1] M R M M R M
$&gt; Levels: M R</code></pre>
<p>データフレームの<code>iter</code>と<code>set</code>は繰り返し回数とデータセットの種類(訓練なのかテストなのか)を示している。</p>
<p>デフォルトでは予測はテストセットだけに行われるが、<code>makeResampleDesc</code>に対し、<code>predict = &quot;train&quot;</code>を指定で訓練セットだけに、<code>predict = &quot;both&quot;</code>を指定で訓練セットとテストセットの両方に予測を行うことが出来る。後で例を見るが、<em>b632</em>や<em>b632+</em>のようなブートストラップ手法ではこれらの設定が必要となる。</p>
<p>以下では単純なホールドアウト法の例を見よう。つまり、テストセットと訓練セットへの分割は一度だけ行い、予測は両方のデータセットを用いて行う。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;Holdout&quot;</span>, <span class="dt">predict =</span> <span class="st">&quot;both&quot;</span>)

r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;classif.lda&quot;</span>, iris.task, rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: iris-example
$&gt; Learner: classif.lda
$&gt; Aggr perf: mmce.test.mean=0.02
$&gt; Runtime: 0.0160549</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r<span class="op">$</span>aggr</code></pre></div>
<pre><code>$&gt; mmce.test.mean 
$&gt;           0.02</code></pre>
<p>(<code>predict=&quot;both&quot;</code>の指定にかかわらず、<code>r$aggr</code>ではテストデータに対するmmceしか計算しないことに注意してもらいたい。訓練セットに対して計算する方法はこの後で説明する。)</p>
<p>リサンプリング結果から予測を取り出す方法として、<code>getRRPredictionList</code>を使う方法もある。これは、分割されたデータセット(訓練/テスト)それぞれと、リサンプリングの繰り返し毎に分割した単位でまとめた予測結果のリストを返す。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">getRRPredictionList</span>(r)</code></pre></div>
<pre><code>$&gt; $train
$&gt; $train$`1`
$&gt; Prediction: 100 observations
$&gt; predict.type: response
$&gt; threshold: 
$&gt; time: 0.00
$&gt;      id      truth   response
$&gt; 2     2     setosa     setosa
$&gt; 118 118  virginica  virginica
$&gt; 65   65 versicolor versicolor
$&gt; 42   42     setosa     setosa
$&gt; 124 124  virginica  virginica
$&gt; 34   34     setosa     setosa
$&gt; ... (100 rows, 3 cols)
$&gt; 
$&gt; 
$&gt; 
$&gt; $test
$&gt; $test$`1`
$&gt; Prediction: 50 observations
$&gt; predict.type: response
$&gt; threshold: 
$&gt; time: 0.00
$&gt;      id      truth   response
$&gt; 91   91 versicolor versicolor
$&gt; 78   78 versicolor versicolor
$&gt; 7     7     setosa     setosa
$&gt; 146 146  virginica  virginica
$&gt; 139 139  virginica  virginica
$&gt; 9     9     setosa     setosa
$&gt; ... (50 rows, 3 cols)</code></pre>
</div>
<div id="section-8.3.2" class="section level3">
<h3><span class="header-section-number">8.3.2</span> 訓練済みモデルの抽出</h3>
<p>リサンプリング毎に学習器は訓練セットにフィットさせられる。標準では、<code>WrappedModel</code>は<code>ResampleResult</code>オブジェクトには含まれておらず、<code>$models</code>スロットは空だ。これを保持するためには、<code>resample</code>関数を呼び出す際に引数<code>models = TRUE</code>を指定する必要がある。以下に生存時間分析の例を見よう。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 3分割クロスバリデーション
rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iters =</span> <span class="dv">3</span>)

r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;surv.coxph&quot;</span>, lung.task, rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>, <span class="dt">models =</span> <span class="ot">TRUE</span>)
r<span class="op">$</span>models</code></pre></div>
<pre><code>$&gt; [[1]]
$&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph
$&gt; Trained on: task.id = lung-example; obs = 111; features = 8
$&gt; Hyperparameters: 
$&gt; 
$&gt; [[2]]
$&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph
$&gt; Trained on: task.id = lung-example; obs = 111; features = 8
$&gt; Hyperparameters: 
$&gt; 
$&gt; [[3]]
$&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph
$&gt; Trained on: task.id = lung-example; obs = 112; features = 8
$&gt; Hyperparameters:</code></pre>
</div>
<div id="section-8.3.3" class="section level3">
<h3><span class="header-section-number">8.3.3</span> 他の抽出方法</h3>
<p>完全なフィット済みモデルを保持しようとすると、リサンプリングの繰り返し数が多かったりオブジェクトが大きかったりする場合にメモリの消費量が大きくなってしまう。モデルの全ての情報を保持する代わりに、<code>resample</code>関数の<code>extract</code>引数に指定することで必要な情報だけを保持することができる。引数<code>extract</code>に対しては、リサンプリング毎の各<code>WrapedModel</code>オブジェクトに適用するための関数を渡す必要がある。</p>
<p>以下では、<code>mtcars</code>データセットをk=3のk-meansでクラスタリングし、クラスター中心だけを保持する例を紹介する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter =</span> <span class="dv">3</span>)

r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;cluster.kmeans&quot;</span>, mtcars.task, rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>,
             <span class="dt">centers =</span> <span class="dv">3</span>, <span class="dt">extract =</span> <span class="cf">function</span>(x){<span class="kw">getLearnerModel</span>(x)<span class="op">$</span>centers})
r<span class="op">$</span>extract</code></pre></div>
<pre><code>$&gt; [[1]]
$&gt;        mpg      cyl     disp       hp     drat       wt     qsec        vs
$&gt; 1 24.33333 4.666667 119.9111 105.4444 3.972222 2.388667 17.98556 0.6666667
$&gt; 2 17.31667 7.333333 271.4000 150.8333 2.968333 3.629167 18.25500 0.3333333
$&gt; 3 14.53333 8.000000 386.8333 229.0000 3.423333 4.131500 16.33500 0.0000000
$&gt;          am     gear     carb
$&gt; 1 0.7777778 4.222222 2.555556
$&gt; 2 0.0000000 3.000000 2.166667
$&gt; 3 0.1666667 3.333333 3.666667
$&gt; 
$&gt; [[2]]
$&gt;        mpg      cyl     disp        hp     drat       wt     qsec   vs
$&gt; 1 24.69167 4.666667 121.1333  93.83333 4.018333 2.560833 18.68167 0.75
$&gt; 2 14.76667 8.000000 437.3333 203.33333 3.080000 4.813333 17.48333 0.00
$&gt; 3 15.35714 8.000000 328.8286 227.71429 3.438571 3.543571 16.09571 0.00
$&gt;          am     gear     carb
$&gt; 1 0.7500000 4.083333 2.500000
$&gt; 2 0.0000000 3.000000 3.333333
$&gt; 3 0.2857143 3.571429 3.857143
$&gt; 
$&gt; [[3]]
$&gt;       mpg cyl    disp      hp    drat       wt     qsec    vs    am  gear
$&gt; 1 19.5000   6 195.640 114.200 3.51600 3.286000 18.77600 0.800 0.200 3.600
$&gt; 2 14.9250   8 350.825 198.750 3.07500 4.105500 17.07750 0.000 0.125 3.250
$&gt; 3 26.3375   4 110.675  83.625 4.04625 2.324125 19.13875 0.875 0.625 4.125
$&gt;    carb
$&gt; 1 2.800
$&gt; 2 3.500
$&gt; 3 1.625</code></pre>
<p>他の例として、フィット済みの回帰木から変数の重要度を<code>getFeatureImportance</code>を使って抽出してみよう(より詳しい内容は<a href="https://mlr-org.github.io/mlr-tutorial/devel/html/feature_selection/index.html">Feature Selection - mlr tutorial</a>を確認してもらいたい)。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;regr.rpart&quot;</span>, bh.task, rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>, <span class="dt">extract =</span> getFeatureImportance)
r<span class="op">$</span>extract</code></pre></div>
<pre><code>$&gt; [[1]]
$&gt; FeatureImportance:
$&gt; Task: BostonHousing-example
$&gt; 
$&gt; Learner: regr.rpart
$&gt; Measure: NA
$&gt; Contrast: NA
$&gt; Aggregation: function (x)  x
$&gt; Replace: NA
$&gt; Number of Monte-Carlo iterations: NA
$&gt; Local: FALSE
$&gt;       crim       zn    indus chas      nox       rm      age      dis
$&gt; 1 3399.046 1192.183 4051.922    0 2303.742 15941.78 2269.408 2636.903
$&gt;        rad      tax  ptratio b    lstat
$&gt; 1 830.9189 1045.856 2626.595 0 11415.22
$&gt; 
$&gt; [[2]]
$&gt; FeatureImportance:
$&gt; Task: BostonHousing-example
$&gt; 
$&gt; Learner: regr.rpart
$&gt; Measure: NA
$&gt; Contrast: NA
$&gt; Aggregation: function (x)  x
$&gt; Replace: NA
$&gt; Number of Monte-Carlo iterations: NA
$&gt; Local: FALSE
$&gt;      crim       zn    indus     chas      nox       rm      age      dis
$&gt; 1 2122.88 579.2956 4377.805 188.1338 3020.542 14975.56 3097.911 3183.877
$&gt;        rad      tax  ptratio b    lstat
$&gt; 1 657.2457 2952.654 2856.316 0 10148.19
$&gt; 
$&gt; [[3]]
$&gt; FeatureImportance:
$&gt; Task: BostonHousing-example
$&gt; 
$&gt; Learner: regr.rpart
$&gt; Measure: NA
$&gt; Contrast: NA
$&gt; Aggregation: function (x)  x
$&gt; Replace: NA
$&gt; Number of Monte-Carlo iterations: NA
$&gt; Local: FALSE
$&gt;       crim      zn    indus     chas      nox       rm      age     dis
$&gt; 1 2588.126 1981.96 3616.241 365.7574 3703.958 16503.61 3212.413 4428.26
$&gt;        rad      tax  ptratio        b    lstat
$&gt; 1 639.1926 2930.041 2398.208 747.6475 11787.72</code></pre>
</div>
</div>
<div id="section-8.4" class="section level2">
<h2><span class="header-section-number">8.4</span> 階層化とブロック化</h2>
<ul>
<li>カテゴリー変数に対する階層化とは、訓練セットとテストセット内で各値の比率が変わらないようにすることを指す。階層化が可能なのは目的変数がカテゴリーである場合(教師あり学習における分類や生存時間分析)や、説明変数がカテゴリーである場合に限られる。</li>
<li>ブロック化とは、観測値の一部分をブロックとして扱い、リサンプリングの間にブロックが分割されないように扱うことを指す。つまり、ブロック全体は訓練セットかテストセットのいずれかにまとまって属すことになる。</li>
</ul>
<div id="section-8.4.1" class="section level3">
<h3><span class="header-section-number">8.4.1</span> 目的変数の階層化</h3>
<p>分類においては、元のデータと同じ比率で各クラスの値が含まれていることが望ましい。これはクラス間の観測数が不均衡であったり、データセットの大きさが小さい場合に有効である。さもなければ、観測数が少ないクラスのデータが訓練セットに含まれないということが起こりうる。これは分類性能の低下やモデルのクラッシュにつながる。階層化リサンプリングを行うためには、<code>makeResampleDesc</code>実行時に<code>stratify = TRUE</code>を指定する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iters =</span> <span class="dv">3</span>, <span class="dt">stratify =</span> <span class="ot">TRUE</span>)

r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;classif.lda&quot;</span>, iris.task, rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: iris-example
$&gt; Learner: classif.lda
$&gt; Aggr perf: mmce.test.mean=0.0199
$&gt; Runtime: 0.0345778</code></pre>
<p>階層化を生存時間分析に対して行う場合は、打ち切りの割合が制御される。</p>
</div>
<div id="section-8.4.2" class="section level3">
<h3><span class="header-section-number">8.4.2</span> 説明変数の階層化</h3>
<p>説明変数の階層化が必要な場合もある。この場合は、<code>stratify.cols</code>引数に対して階層化したい因子型変数を指定する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter =</span> <span class="dv">3</span>, <span class="dt">stratify.cols =</span> <span class="st">&quot;chas&quot;</span>)

r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;regr.rpart&quot;</span>, bh.task, rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: BostonHousing-example
$&gt; Learner: regr.rpart
$&gt; Aggr perf: mse.test.mean=  23
$&gt; Runtime: 0.045939</code></pre>
</div>
<div id="section-8.4.3" class="section level3">
<h3><span class="header-section-number">8.4.3</span> ブロック化</h3>
<p>いくつかの観測値が互いに関連しており、これらが訓練データとテストデータに分割されるのが望ましくない場合には、タスク作成時にその情報を<code>blocking</code>引数に因子型ベクトルを与えることで指定する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## それぞれ30の観測値からなる5つのブロックを指定する例
task =<span class="st"> </span><span class="kw">makeClassifTask</span>(<span class="dt">data =</span> iris, <span class="dt">target =</span> <span class="st">&quot;Species&quot;</span>, <span class="dt">blocking =</span> <span class="kw">factor</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="dt">each =</span> <span class="dv">30</span>)))
task</code></pre></div>
<pre><code>$&gt; Supervised task: iris
$&gt; Type: classif
$&gt; Target: Species
$&gt; Observations: 150
$&gt; Features:
$&gt; numerics  factors  ordered 
$&gt;        4        0        0 
$&gt; Missings: FALSE
$&gt; Has weights: FALSE
$&gt; Has blocking: TRUE
$&gt; Classes: 3
$&gt;     setosa versicolor  virginica 
$&gt;         50         50         50 
$&gt; Positive class: NA</code></pre>
</div>
</div>
<div id="section-8.5" class="section level2">
<h2><span class="header-section-number">8.5</span> リサンプリングの詳細とリサンプルのインスタンス</h2>
<p>既に説明したように、リサンプリング手法は<code>makeResampleDesc</code>関数を使って指定する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter =</span> <span class="dv">3</span>)
rdesc</code></pre></div>
<pre><code>$&gt; Resample description: cross-validation with 3 iterations.
$&gt; Predict: test
$&gt; Stratification: FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(rdesc)</code></pre></div>
<pre><code>$&gt; List of 4
$&gt;  $ id      : chr &quot;cross-validation&quot;
$&gt;  $ iters   : int 3
$&gt;  $ predict : chr &quot;test&quot;
$&gt;  $ stratify: logi FALSE
$&gt;  - attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;</code></pre>
<p>上記<code>rdesc</code>は<code>ResampleDesc</code>クラス(resample descriptionの略)を継承しており、原則として、リサンプリング手法に関する必要な情報(繰り返し数、訓練セットとテストセットの比率、階層化したい変数など)を全て含んでいる。</p>
<p><code>makeResampleInstance</code>関数は、データセットに含まれるデータ数を直接指定するか、タスクを指定することで、<code>ResampleDesc</code>に従って訓練セットとテストセットの概要を生成する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## taskに基づくリサンプルインスタンスの生成
rin =<span class="st"> </span><span class="kw">makeResampleInstance</span>(rdesc, iris.task)
rin</code></pre></div>
<pre><code>$&gt; Resample instance for 150 cases.
$&gt; Resample description: cross-validation with 3 iterations.
$&gt; Predict: test
$&gt; Stratification: FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(rin)</code></pre></div>
<pre><code>$&gt; List of 5
$&gt;  $ desc      :List of 4
$&gt;   ..$ id      : chr &quot;cross-validation&quot;
$&gt;   ..$ iters   : int 3
$&gt;   ..$ predict : chr &quot;test&quot;
$&gt;   ..$ stratify: logi FALSE
$&gt;   ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;
$&gt;  $ size      : int 150
$&gt;  $ train.inds:List of 3
$&gt;   ..$ : int [1:100] 104 35 40 114 123 13 9 31 146 16 ...
$&gt;   ..$ : int [1:100] 104 55 35 114 13 8 17 97 78 111 ...
$&gt;   ..$ : int [1:100] 55 40 123 9 8 31 146 16 17 128 ...
$&gt;  $ test.inds :List of 3
$&gt;   ..$ : int [1:50] 6 8 12 15 17 24 26 29 33 36 ...
$&gt;   ..$ : int [1:50] 2 4 9 14 16 18 20 22 23 31 ...
$&gt;   ..$ : int [1:50] 1 3 5 7 10 11 13 19 21 25 ...
$&gt;  $ group     : Factor w/ 0 levels: 
$&gt;  - attr(*, &quot;class&quot;)= chr &quot;ResampleInstance&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## データセットのサイズを指定してリサンプルインスタンスを生成する例
rin =<span class="st"> </span><span class="kw">makeResampleInstance</span>(rdesc, <span class="dt">size =</span> <span class="kw">nrow</span>(iris))
<span class="kw">str</span>(rin)</code></pre></div>
<pre><code>$&gt; List of 5
$&gt;  $ desc      :List of 4
$&gt;   ..$ id      : chr &quot;cross-validation&quot;
$&gt;   ..$ iters   : int 3
$&gt;   ..$ predict : chr &quot;test&quot;
$&gt;   ..$ stratify: logi FALSE
$&gt;   ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;
$&gt;  $ size      : int 150
$&gt;  $ train.inds:List of 3
$&gt;   ..$ : int [1:100] 119 64 54 128 100 34 63 110 22 56 ...
$&gt;   ..$ : int [1:100] 119 128 140 47 100 34 115 139 95 58 ...
$&gt;   ..$ : int [1:100] 64 54 140 47 63 110 22 56 115 139 ...
$&gt;  $ test.inds :List of 3
$&gt;   ..$ : int [1:50] 1 4 8 11 12 17 18 19 24 26 ...
$&gt;   ..$ : int [1:50] 3 6 7 10 14 20 22 23 25 28 ...
$&gt;   ..$ : int [1:50] 2 5 9 13 15 16 21 27 29 31 ...
$&gt;  $ group     : Factor w/ 0 levels: 
$&gt;  - attr(*, &quot;class&quot;)= chr &quot;ResampleInstance&quot;</code></pre>
<p>ここで<code>rin</code>は<code>ResampleInstance</code>クラスを継承しており、訓練セットとテストセットのインデックスをリストとして含んでいる。</p>
<p><code>ResampleDesc</code>が<code>resample</code>に渡されると、インスタンスの生成は内部的に行われる。もちろん、<code>ResampleInstance</code>を直接渡すこともできる。</p>
<p>リサンプルの詳細(resample description)とリサンプルのインスタンス、そしてリサンプル関数と分割するのは、複雑にしすぎているのではと感じるかもしれないが、幾つかの利点がある。</p>
<ul>
<li>リサンプルインスタンスを用いると、同じ訓練セットとテストセットを用いて学習器の性能比較を行うことが容易になる。これは、既に実施した性能比較試験に対し、他の手法を追加したい場合などに特に便利である。また、後で結果を再現するためにデータとリサンプルインスタンスをセットで保管しておくこともできる。</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter =</span> <span class="dv">3</span>)
rin =<span class="st"> </span><span class="kw">makeResampleInstance</span>(rdesc, <span class="dt">task =</span> iris.task)

## 同じインスタンスを使い、2種類の学習器で性能指標を計算する
r.lda =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;classif.lda&quot;</span>, iris.task, rin, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r.rpart =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;classif.rpart&quot;</span>, iris.task, rin, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
<span class="kw">c</span>(<span class="st">&quot;lda&quot;</span> =<span class="st"> </span>r.lda<span class="op">$</span>aggr, <span class="st">&quot;rpart&quot;</span> =<span class="st"> </span>r.rpart<span class="op">$</span>aggr)</code></pre></div>
<pre><code>$&gt;   lda.mmce.test.mean rpart.mmce.test.mean 
$&gt;           0.04000000           0.06666667</code></pre>
<ul>
<li>新しいリサンプリング手法を追加したければ、<code>ResampleDesc</code>および<code>ResampleInstance</code>クラスのインスタンスを作成すればよく、<code>resample</code>関数やそれ以上のメソッドに触る必要はない。</li>
</ul>
<p>通常、<code>makeResampleInstance</code>を呼び出したときの訓練セットとテストセットのインデックスはランダムに割り当てられる。主にホールドアウト法においては、これを完全にマニュアルで行わなければならない場面がある。これは<code>makeFixedHoldoutInstance</code>関数を使うと実現できる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rin =<span class="st"> </span><span class="kw">makeFixedHoldoutInstance</span>(<span class="dt">train.inds =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dt">test.inds =</span> <span class="dv">101</span><span class="op">:</span><span class="dv">150</span>, <span class="dt">size =</span> <span class="dv">150</span>)
rin</code></pre></div>
<pre><code>$&gt; Resample instance for 150 cases.
$&gt; Resample description: holdout with 0.67 split rate.
$&gt; Predict: test
$&gt; Stratification: FALSE</code></pre>
</div>
<div id="section-8.6" class="section level2">
<h2><span class="header-section-number">8.6</span> 性能指標の集約</h2>
<p>リサンプリングそれぞれに対して性能指標を計算したら、それを集計する必要がある。</p>
<p>大半のリサンプリング手法(ホールドアウト法、クロスバリデーション、サブサンプリングなど)では、性能指標はテストデータのみで計算され、平均によって集約される。</p>
<p><code>mlr</code>における性能指標を表現する<code>Measure</code>クラスのオブジェクトは、<code>$aggr</code>スロットに対応するデフォルトの集約手法を格納している。大半は<code>test.mean</code>である。例外の一つは平均二乗誤差平方根(rmse)である。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 一般的な集約手法
mmce<span class="op">$</span>aggr</code></pre></div>
<pre><code>$&gt; Aggregation function: test.mean</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 具体的な計算方法
mmce<span class="op">$</span>aggr<span class="op">$</span>fun</code></pre></div>
<pre><code>$&gt; function (task, perf.test, perf.train, measure, group, pred) 
$&gt; mean(perf.test)
$&gt; &lt;bytecode: 0x7ffe780abd58&gt;
$&gt; &lt;environment: namespace:mlr&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## rmseの場合
rmse<span class="op">$</span>aggr</code></pre></div>
<pre><code>$&gt; Aggregation function: test.rmse</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## test.rmseの具体的な計算方法
rmse<span class="op">$</span>aggr<span class="op">$</span>fun</code></pre></div>
<pre><code>$&gt; function (task, perf.test, perf.train, measure, group, pred) 
$&gt; sqrt(mean(perf.test^2))
$&gt; &lt;bytecode: 0x7ffe7e83d5c8&gt;
$&gt; &lt;environment: namespace:mlr&gt;</code></pre>
<p><code>setAggrigation</code>関数を使うと、集約方法を変更することも出来る。利用可能な集約手法の一覧は<a href="https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/aggregations">aggregations function | R Documentation</a>を確認してほしい。</p>
<div id="-" class="section level3">
<h3><span class="header-section-number">8.6.1</span> 例: 一つの指標に複数の集約方法</h3>
<p><code>test.median</code>、<code>test.min</code>、<code>test.max</code>はそれぞれテストセットから求めた性能指標を中央値、最小値、最大値で集約する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mseTestMedian =<span class="st"> </span><span class="kw">setAggregation</span>(mse, test.median)
mseTestMin =<span class="st"> </span><span class="kw">setAggregation</span>(mse, test.min)
mseTestMax =<span class="st"> </span><span class="kw">setAggregation</span>(mse, test.max)
rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter =</span> <span class="dv">3</span>)
r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;regr.lm&quot;</span>, bh.task, rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>, 
             <span class="dt">measures =</span> <span class="kw">list</span>(mse, mseTestMedian, mseTestMin, mseTestMax))
r</code></pre></div>
<pre><code>$&gt; Resample Result
$&gt; Task: BostonHousing-example
$&gt; Learner: regr.lm
$&gt; Aggr perf: mse.test.mean=25.7,mse.test.median=25.5,mse.test.min=18.5,mse.test.max=33.1
$&gt; Runtime: 0.0344691</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r<span class="op">$</span>aggr</code></pre></div>
<pre><code>$&gt;   mse.test.mean mse.test.median    mse.test.min    mse.test.max 
$&gt;        25.69050        25.50319        18.46241        33.10591</code></pre>
</div>
<div id="-" class="section level3">
<h3><span class="header-section-number">8.6.2</span> 例: 訓練セットの誤差を計算する</h3>
<p>平均誤分類率を訓練セットとテストセットに対して計算する例を示す。<code>makeResampleDesc</code>実行時に<code>predict = &quot;both&quot;</code>を指定しておく必要があることに注意してもらいたい。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mmceTrainMean =<span class="st"> </span><span class="kw">setAggregation</span>(mmce, train.mean)
rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iters =</span> <span class="dv">3</span>, <span class="dt">predict =</span> <span class="st">&quot;both&quot;</span>)
r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;classif.rpart&quot;</span>, iris.task, rdesc, <span class="dt">measures =</span> <span class="kw">list</span>(mmce, mmceTrainMean))</code></pre></div>
<pre><code>$&gt; [Resample] cross-validation iter 1: mmce.train.mean=0.03,mmce.test.mean=0.18
$&gt; [Resample] cross-validation iter 2: mmce.train.mean=0.04,mmce.test.mean=0.04
$&gt; [Resample] cross-validation iter 3: mmce.train.mean=0.03,mmce.test.mean=0.06
$&gt; [Resample] Aggr. Result: mmce.test.mean=0.0933,mmce.train.mean=0.0333</code></pre>
</div>
<div id="-" class="section level3">
<h3><span class="header-section-number">8.6.3</span> 例: ブートストラップ</h3>
<p>out-of-bagブートストラップ推定では、まず元のデータセット<span class="math inline">\(D\)</span>から重複ありの抽出によって<span class="math inline">\(D^{*1}, ...,D^{*B}\)</span>と<span class="math inline">\(B\)</span>個の新しいデータセット(要素数は元のデータセットと同じ)を作成する。そして、<span class="math inline">\(b\)</span>回目の繰り返しでは、<span class="math inline">\(D^{*b}\)</span>を訓練セットに使い、使われなかった要素<span class="math inline">\(D\setminus D^{*b}\)</span>をテストセットに用いて各繰り返しに対する推定値を計算し、最終的に<span class="math inline">\(B\)</span>個の推定値を得る。</p>
<p>out-of-bagブートストラップの変種である<em>b632</em>と<em>b632+</em>では、訓練セットのパフォーマンスとOOBサンプルのパフォーマンスの凸結合を計算するため、訓練セットに対する予測と適切な集計方法を必要とする。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## ブートストラップをリサンプリング手法に選び、予測は訓練セットとテストセットの両方に行う
rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;Bootstrap&quot;</span>, <span class="dt">predict =</span> <span class="st">&quot;both&quot;</span>, <span class="dt">iters =</span> <span class="dv">10</span>)

## b632およびb632+専用の集計手法を設定する
mmceB632 =<span class="st"> </span><span class="kw">setAggregation</span>(mmce, b632)
mmceB632plus =<span class="st"> </span><span class="kw">setAggregation</span>(mmce, b632plus)

r =<span class="st"> </span><span class="kw">resample</span>(<span class="st">&quot;classif.rpart&quot;</span>, iris.task, rdesc, <span class="dt">measures =</span> <span class="kw">list</span>(mmce, mmceB632, mmceB632plus),
             <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r<span class="op">$</span>measures.train</code></pre></div>
<pre><code>$&gt;    iter        mmce        mmce        mmce
$&gt; 1     1 0.026666667 0.026666667 0.026666667
$&gt; 2     2 0.020000000 0.020000000 0.020000000
$&gt; 3     3 0.026666667 0.026666667 0.026666667
$&gt; 4     4 0.026666667 0.026666667 0.026666667
$&gt; 5     5 0.013333333 0.013333333 0.013333333
$&gt; 6     6 0.020000000 0.020000000 0.020000000
$&gt; 7     7 0.020000000 0.020000000 0.020000000
$&gt; 8     8 0.020000000 0.020000000 0.020000000
$&gt; 9     9 0.006666667 0.006666667 0.006666667
$&gt; 10   10 0.020000000 0.020000000 0.020000000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r<span class="op">$</span>aggr</code></pre></div>
<pre><code>$&gt; mmce.test.mean      mmce.b632  mmce.b632plus 
$&gt;     0.07758371     0.05639290     0.05790858</code></pre>
</div>
</div>
<div id="section-8.7" class="section level2">
<h2><span class="header-section-number">8.7</span> 便利な関数</h2>
<p>これまでに説明した方法は柔軟ではあるが、学習器を少し試してみたい場合にはタイプ数が多くて面倒である。<code>mlr</code>には様々な略記法が用意してあるが、リサンプリング手法についても同様である。ホールドアウトやクロスバリデーション、ブートストラップ(b632)等のよく使うリサンプリング手法にはそれぞれ特有の関数が用意してある。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">crossval</span>(<span class="st">&quot;classif.lda&quot;</span>, iris.task, <span class="dt">iters =</span> <span class="dv">3</span>, <span class="dt">measures =</span> <span class="kw">list</span>(mmce, ber))</code></pre></div>
<pre><code>$&gt; [Resample] cross-validation iter 1: mmce.test.mean=0.02,ber.test.mean=0.0222
$&gt; [Resample] cross-validation iter 2: mmce.test.mean=0.04,ber.test.mean=0.0333
$&gt; [Resample] cross-validation iter 3: mmce.test.mean=0.02,ber.test.mean=0.0167
$&gt; [Resample] Aggr. Result: mmce.test.mean=0.0267,ber.test.mean=0.0241</code></pre>
<pre><code>$&gt; Resample Result
$&gt; Task: iris-example
$&gt; Learner: classif.lda
$&gt; Aggr perf: mmce.test.mean=0.0267,ber.test.mean=0.0241
$&gt; Runtime: 0.0395842</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bootstrapB632plus</span>(<span class="st">&quot;regr.lm&quot;</span>, bh.task, <span class="dt">iters =</span> <span class="dv">3</span>, <span class="dt">measures =</span> <span class="kw">list</span>(mse, mae))</code></pre></div>
<pre><code>$&gt; [Resample] OOB bootstrapping iter 1: mse.b632plus=18.6,mae.b632plus=3.06,mse.b632plus=30.8,mae.b632plus=3.42
$&gt; [Resample] OOB bootstrapping iter 2: mse.b632plus=23.2,mae.b632plus=3.49,mse.b632plus=17.3,mae.b632plus=3.06
$&gt; [Resample] OOB bootstrapping iter 3: mse.b632plus=18.9,mae.b632plus=2.96,mse.b632plus=27.4,mae.b632plus=3.58
$&gt; [Resample] Aggr. Result: mse.b632plus=23.5,mae.b632plus=3.29</code></pre>
<pre><code>$&gt; Resample Result
$&gt; Task: BostonHousing-example
$&gt; Learner: regr.lm
$&gt; Aggr perf: mse.b632plus=23.5,mae.b632plus=3.29
$&gt; Runtime: 0.0683589</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-7.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-9.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
