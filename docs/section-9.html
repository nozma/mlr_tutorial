<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>mlrパッケージチュートリアル</title>
  <meta name="description" content="mlrパッケージチュートリアル">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="mlrパッケージチュートリアル" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="mlrパッケージチュートリアル" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-8.html">
<link rel="next" href="section-10.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="1" data-path="quick-start.html"><a href="quick-start.html"><i class="fa fa-check"></i><b>1</b> Quick start</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> タスク</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> タスクの種類と作成</a><ul>
<li class="chapter" data-level="2.1.1" data-path="section-2.html"><a href="section-2.html#section-2.1.1"><i class="fa fa-check"></i><b>2.1.1</b> 回帰</a></li>
<li class="chapter" data-level="2.1.2" data-path="section-2.html"><a href="section-2.html#section-2.1.2"><i class="fa fa-check"></i><b>2.1.2</b> 分類</a></li>
<li class="chapter" data-level="2.1.3" data-path="section-2.html"><a href="section-2.html#section-2.1.3"><i class="fa fa-check"></i><b>2.1.3</b> 生存時間分析</a></li>
<li class="chapter" data-level="2.1.4" data-path="section-2.html"><a href="section-2.html#section-2.1.4"><i class="fa fa-check"></i><b>2.1.4</b> マルチラベル分類</a></li>
<li class="chapter" data-level="2.1.5" data-path="section-2.html"><a href="section-2.html#section-2.1.5"><i class="fa fa-check"></i><b>2.1.5</b> クラスター分析</a></li>
<li class="chapter" data-level="2.1.6" data-path="section-2.html"><a href="section-2.html#section-2.1.6"><i class="fa fa-check"></i><b>2.1.6</b> コスト考慮型分類</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> その他の設定</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> タスクへのアクセス</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> タスクの編集</a></li>
<li class="chapter" data-level="2.5" data-path="section-2.html"><a href="section-2.html#section-2.5"><i class="fa fa-check"></i><b>2.5</b> タスクの例と便利な関数</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 学習器</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 学習器を構築する</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 学習器へアクセスする</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 学習器の編集</a></li>
<li class="chapter" data-level="3.4" data-path="section-3.html"><a href="section-3.html#section-3.4"><i class="fa fa-check"></i><b>3.4</b> 学習器一覧</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 学習器の訓練</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 学習器モデルへのアクセス</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> その他のオプションとコメント</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 予測</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 新しいデータに対する結果を予測する</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 予測へのアクセス</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#-"><i class="fa fa-check"></i><b>5.3</b> 回帰: 標準誤差を取得する</a></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#-"><i class="fa fa-check"></i><b>5.4</b> 分類とクラスタリング: 確率を取得する</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#-"><i class="fa fa-check"></i><b>5.5</b> 分類: 混同行列を取得する</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#-"><i class="fa fa-check"></i><b>5.6</b> 分類: 決定閾値の調整</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 予測の可視化</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> データの前処理</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 前処理と学習器を融合する</a></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#makepreprocwrappercaret"><i class="fa fa-check"></i><b>6.2</b> <code>makePreprocWrapperCaret</code>を使用した前処理</a></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 前処理オプションと学習器パラメータの連結チューニング</a></li>
<li class="chapter" data-level="6.4" data-path="section-6.html"><a href="section-6.html#section-6.4"><i class="fa fa-check"></i><b>6.4</b> 独自の前処理ラッパーを書く</a><ul>
<li class="chapter" data-level="6.4.1" data-path="section-6.html"><a href="section-6.html#section-6.4.1"><i class="fa fa-check"></i><b>6.4.1</b> 訓練関数の指定</a></li>
<li class="chapter" data-level="6.4.2" data-path="section-6.html"><a href="section-6.html#section-6.4.2"><i class="fa fa-check"></i><b>6.4.2</b> 予測関数の指定</a></li>
<li class="chapter" data-level="6.4.3" data-path="section-6.html"><a href="section-6.html#section-6.4.3"><i class="fa fa-check"></i><b>6.4.3</b> 前処理ラッパーの作成</a></li>
<li class="chapter" data-level="6.4.4" data-path="section-6.html"><a href="section-6.html#section-6.4.4"><i class="fa fa-check"></i><b>6.4.4</b> 前処理と学習器のパラメータを連結してチューニングする</a></li>
<li class="chapter" data-level="6.4.5" data-path="section-6.html"><a href="section-6.html#section-6.4.5"><i class="fa fa-check"></i><b>6.4.5</b> 前処理ラッパー関数</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 学習器の性能を評価する</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 利用可能な性能指標</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 指標の一覧</a></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 性能指標を計算する</a></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#section-7.4"><i class="fa fa-check"></i><b>7.4</b> 指標計算に必要な情報</a></li>
<li class="chapter" data-level="7.5" data-path="section-7.html"><a href="section-7.html#section-7.5"><i class="fa fa-check"></i><b>7.5</b> 性能指標へのアクセス</a></li>
<li class="chapter" data-level="7.6" data-path="section-7.html"><a href="section-7.html#section-7.6"><i class="fa fa-check"></i><b>7.6</b> 2クラス分類</a><ul>
<li class="chapter" data-level="7.6.1" data-path="section-7.html"><a href="section-7.html#section-7.6.1"><i class="fa fa-check"></i><b>7.6.1</b> 性能と閾値の関係をプロットする</a></li>
<li class="chapter" data-level="7.6.2" data-path="section-7.html"><a href="section-7.html#roc"><i class="fa fa-check"></i><b>7.6.2</b> ROC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> リサンプリング</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> リサンプリング手法を決める</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> リサンプリングを実行する</a></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#section-8.3"><i class="fa fa-check"></i><b>8.3</b> リサンプル結果へのアクセス</a><ul>
<li class="chapter" data-level="8.3.1" data-path="section-8.html"><a href="section-8.html#section-8.3.1"><i class="fa fa-check"></i><b>8.3.1</b> 予測値</a></li>
<li class="chapter" data-level="8.3.2" data-path="section-8.html"><a href="section-8.html#section-8.3.2"><i class="fa fa-check"></i><b>8.3.2</b> 訓練済みモデルの抽出</a></li>
<li class="chapter" data-level="8.3.3" data-path="section-8.html"><a href="section-8.html#section-8.3.3"><i class="fa fa-check"></i><b>8.3.3</b> 他の抽出方法</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="section-8.html"><a href="section-8.html#section-8.4"><i class="fa fa-check"></i><b>8.4</b> 階層化とブロック化</a><ul>
<li class="chapter" data-level="8.4.1" data-path="section-8.html"><a href="section-8.html#section-8.4.1"><i class="fa fa-check"></i><b>8.4.1</b> 目的変数の階層化</a></li>
<li class="chapter" data-level="8.4.2" data-path="section-8.html"><a href="section-8.html#section-8.4.2"><i class="fa fa-check"></i><b>8.4.2</b> 説明変数の階層化</a></li>
<li class="chapter" data-level="8.4.3" data-path="section-8.html"><a href="section-8.html#section-8.4.3"><i class="fa fa-check"></i><b>8.4.3</b> ブロック化</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="section-8.html"><a href="section-8.html#section-8.5"><i class="fa fa-check"></i><b>8.5</b> リサンプリングの詳細とリサンプルのインスタンス</a></li>
<li class="chapter" data-level="8.6" data-path="section-8.html"><a href="section-8.html#section-8.6"><i class="fa fa-check"></i><b>8.6</b> 性能指標の集約</a><ul>
<li class="chapter" data-level="8.6.1" data-path="section-5.html"><a href="section-5.html#-"><i class="fa fa-check"></i><b>8.6.1</b> 例: 一つの指標に複数の集約方法</a></li>
<li class="chapter" data-level="8.6.2" data-path="section-5.html"><a href="section-5.html#-"><i class="fa fa-check"></i><b>8.6.2</b> 例: 訓練セットの誤差を計算する</a></li>
<li class="chapter" data-level="8.6.3" data-path="section-5.html"><a href="section-5.html#-"><i class="fa fa-check"></i><b>8.6.3</b> 例: ブートストラップ</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="section-8.html"><a href="section-8.html#section-8.7"><i class="fa fa-check"></i><b>8.7</b> 便利な関数</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> ハイパーパラメータのチューニング</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> パラメータ探索空間の指定</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 最適化アルゴリズムの指定</a></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> チューニングの実行</a></li>
<li class="chapter" data-level="9.4" data-path="section-9.html"><a href="section-9.html#section-9.4"><i class="fa fa-check"></i><b>9.4</b> チューニング結果へのアクセス</a></li>
<li class="chapter" data-level="9.5" data-path="section-9.html"><a href="section-9.html#section-9.5"><i class="fa fa-check"></i><b>9.5</b> ハイパーパラメータチューニングの影響を調査する</a></li>
<li class="chapter" data-level="9.6" data-path="section-9.html"><a href="section-9.html#section-9.6"><i class="fa fa-check"></i><b>9.6</b> その他いろいろ</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> ベンチマーク試験</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> ベンチマーク試験の実施</a><ul>
<li class="chapter" data-level="10.1.1" data-path="section-10.html"><a href="section-10.html#section-10.1.1"><i class="fa fa-check"></i><b>10.1.1</b> 実験を再現可能にする</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> ベンチマーク結果へのアクセス</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-10.html"><a href="section-10.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 学習器の性能</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-10.html"><a href="section-10.html#-1"><i class="fa fa-check"></i><b>10.2.2</b> 予測</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-10.html"><a href="section-10.html#id"><i class="fa fa-check"></i><b>10.2.3</b> ID</a></li>
<li class="chapter" data-level="10.2.4" data-path="section-10.html"><a href="section-10.html#section-10.2.4"><i class="fa fa-check"></i><b>10.2.4</b> フィット済みモデル</a></li>
<li class="chapter" data-level="10.2.5" data-path="section-10.html"><a href="section-10.html#section-10.2.5"><i class="fa fa-check"></i><b>10.2.5</b> 学習器と性能指標</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> ベンチマーク結果のマージ</a></li>
<li class="chapter" data-level="10.4" data-path="section-10.html"><a href="section-10.html#section-10.4"><i class="fa fa-check"></i><b>10.4</b> ベンチマークの分析と可視化</a><ul>
<li class="chapter" data-level="10.4.1" data-path="section-10.html"><a href="section-10.html#section-10.4.1"><i class="fa fa-check"></i><b>10.4.1</b> 例：線形判別分析と分類木、ランダムフォレストの比較</a></li>
<li class="chapter" data-level="10.4.2" data-path="section-10.html"><a href="section-10.html#section-10.4.2"><i class="fa fa-check"></i><b>10.4.2</b> 可視化</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">mlrパッケージチュートリアル</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-9" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> ハイパーパラメータのチューニング</h1>
<p>多くの機械学習アルゴリズムはハイパーパラメータを持っている。学習器のチュートリアルでも説明したが、ハイパーパラメータとして特定の値を設定したければその値を<code>makeLearner</code>に渡すだけで良い。しかし、ハイパーパラメータの最適な値というのは大抵の場合は自明ではなく、できれば自動的に調整する手法が欲しい。</p>
<p>機械学習アルゴリズムをチューニングするためには、以下の点を指定する必要がある。</p>
<ul>
<li>パラメータの探索範囲</li>
<li>最適化アルゴリズム(チューニングメソッドとも呼ぶ)</li>
<li>評価手法(すなわち、リサンプリング手法と性能指標)</li>
</ul>
<p>パラメータの探索範囲: 例としてサポートベクターマシン(SVM)におけるパラメータ<code>C</code>の探索範囲を指定してみよう。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ps =<span class="st"> </span><span class="kw">makeParamSet</span>(
  <span class="kw">makeNumericParam</span>(<span class="st">&quot;C&quot;</span>, <span class="dt">lower =</span> <span class="fl">0.01</span>, <span class="dt">upper =</span> <span class="fl">0.1</span>)
)</code></pre></div>
<p>最適化アルゴリズム: 例としてランダムサーチを指定してみよう。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw">makeTuneControlRandom</span>(<span class="dt">maxit =</span> 100L)</code></pre></div>
<p>評価手法: リサンプリング手法として3分割クロスバリデーションを、性能指標として精度を指定してみよう。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter =</span> 3L)
measure =<span class="st"> </span>acc</code></pre></div>
<p>評価手法の指定方法については既に説明したところであるので、ここから先は探索範囲と最適化アルゴリズムの指定方法と、チューニングをどのように行い、結果にどのようにアクセスし、さらにチューニング結果を可視化する方法について幾つかの例を通して説明していこう。</p>
<p>このセクションを通して、例としては分類問題を取り上げるが、他の学習問題についても同様の手順で実行できるはずだ。</p>
<p>このさき、irisの分類タスクを使用して、SVMのハイパーパラメータを放射基底関数(RBF)カーネルを使ってチューニングする例を説明する。以下の例では、コストパラメータ<code>C</code>と、RBFカーネルのパラメータ<code>sigma</code>をチューニングする。</p>
<div id="section-9.1" class="section level2">
<h2><span class="header-section-number">9.1</span> パラメータ探索空間の指定</h2>
<p>チューニングの際にまず指定しなければならないのは値の探索範囲である。これは例えば“いくつかの値の中のどれか”かもしれないし、“<span class="math inline">\(10^{-10}\)</span>から<span class="math inline">\(10^{10}\)</span>までの間の中のどこか”かもしれない。</p>
<p>探索空間の指定に際して、パラメータの探索範囲についての情報を含む<code>ParamSet</code>オブジェクトを作成する。これには<code>makeParamSet</code>関数を用いる。</p>
<p>例として、パメータ<code>C</code>と<code>sigma</code>の探索範囲を両方共0.5, 1.0, 1.5, 2.0という離散値に設定する例を見よう。それぞれのパラメータにどのような名前が使われているのかは、<code>kernlab</code>パッケージで定義されている(cf. <a href="https://www.rdocumentation.org/packages/kernlab/versions/0.9-25">kernlab package | R Documentation</a>)。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">discrete_ps =<span class="st"> </span><span class="kw">makeParamSet</span>(
  <span class="kw">makeDiscreteParam</span>(<span class="st">&quot;C&quot;</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>, <span class="fl">2.0</span>)),
  <span class="kw">makeDiscreteParam</span>(<span class="st">&quot;sigma&quot;</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>, <span class="fl">2.0</span>))
)
discrete_ps</code></pre></div>
<pre><code>$&gt;           Type len Def      Constr Req Tunable Trafo
$&gt; C     discrete   -   - 0.5,1,1.5,2   -    TRUE     -
$&gt; sigma discrete   -   - 0.5,1,1.5,2   -    TRUE     -</code></pre>
<p>連続値の探索範囲を指定する際には<code>makeDiscreteParam</code>の代わりに<code>makeNumericParam</code>を使用する。また、探索範囲として<span class="math inline">\(10^{-10}\)</span>から<span class="math inline">\(10^{10}\)</span>のような範囲を指定する際には、<code>trafo</code>引数に変換用の関数を指定できる(trafoはtransformationの略)。変換用の関数を指定した場合、変換前のスケールで行われ、学習アルゴリズムに値を渡す前に変換が行われる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">num_ps =<span class="st"> </span><span class="kw">makeParamSet</span>(
  <span class="kw">makeNumericParam</span>(<span class="st">&quot;C&quot;</span>, <span class="dt">lower =</span> <span class="op">-</span><span class="dv">10</span>, <span class="dt">upper =</span> <span class="dv">10</span>, <span class="dt">trafo =</span> <span class="cf">function</span>(x) <span class="dv">10</span><span class="op">^</span>x),
  <span class="kw">makeNumericParam</span>(<span class="st">&quot;sigma&quot;</span>, <span class="dt">lower =</span> <span class="op">-</span><span class="dv">10</span>, <span class="dt">upper =</span> <span class="dv">10</span>, <span class="dt">trafo =</span> <span class="cf">function</span>(x) <span class="dv">10</span><span class="op">^</span>x)
)</code></pre></div>
<p>他にも数多くのパラメータが利用できるが、詳しくは<a href="https://www.rdocumentation.org/packages/ParamHelpers/versions/1.10/topics/makeParamSet">makeParamSet function | R Documentation</a>を確認してもらいたい。</p>
<p>パラメータをリストの形で指定しなければならない関数もあるが、<code>mlr</code>を通じてその関数を扱う場合、<code>mlr</code>はできるかぎりリスト構造を除去し、パラメータを直接指定できるように試みる。例えばSVMを実行する関数の<code>ksvm</code>は、<code>kpar</code>引数に<code>sigma</code>のようなカーネルパラメータをリストで渡す必要がある。今例を見たように、<code>mlr</code>は<code>sigma</code>を直接扱うことができる。この仕組みのおかげで、<code>mlr</code>は様々なパッケージの学習器を統一したインターフェースで扱うことができるのだ。</p>
</div>
<div id="section-9.2" class="section level2">
<h2><span class="header-section-number">9.2</span> 最適化アルゴリズムの指定</h2>
<p>パラメータの探索範囲を決めたら次は最適化アルゴリズムを指定する。<code>mlr</code>において最適化アルゴリズムは<code>TuneControl</code>クラスのオブジェクトとして扱われる。</p>
<p>グリッドサーチは適切なパラメータを見つけるための標準的な(しかし遅い)方法の一つだ。</p>
<p>先に例を挙げた<code>discrete_ps</code>の場合、グリッドサーチは単純に値の全ての組合せを探索する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw">makeTuneControlGrid</span>()</code></pre></div>
<p><code>num_ps</code>の場合は、グリッドサーチは探索範囲をまず均等なサイズのステップに分割する。標準では分割数は10だが、これは<code>resolution</code>引数で変更できる。ここでは<code>resolution</code>に15を指定してみよう。なお、ここで言う均等な15分割というのは、<code>10^seq(-10, 10, length.out = 15)</code>という意味である。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw">makeTuneControlGrid</span>(<span class="dt">resolution =</span> 15L)</code></pre></div>
<p>クロスバリデーション以外にも多くの最適化アルゴリズムが利用可能であるが、詳しくは<a href="https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/TuneControl">TuneControl function | R Documentation</a>を確認してもらいたい。</p>
<p>グリッドサーチは一般的には遅すぎるので、ランダムサーチについても検討してみよう。ランダムサーチはその名の通り値をランダムに選択する。<code>maxit</code>引数に試行回数を指定できる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw">makeTuneControlRandom</span>(<span class="dt">maxit =</span> 200L)</code></pre></div>
</div>
<div id="section-9.3" class="section level2">
<h2><span class="header-section-number">9.3</span> チューニングの実行</h2>
<p>パラメータの探索範囲と最適化アルゴリズムを決めたら、いよいよチューニングの実行の時だ。あとは、リサンプリング手法と評価尺度を設定する必要がある。</p>
<p>今回は3分割クロスバリデーションをパラメータ設定の評価に使用する。まずはリサンプリングdescriptionを生成する。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iters =</span> 3L)</code></pre></div>
<p>では、今まで作成したものを組合せて、<code>tuneParams</code>関数によりパラメータチューニングを実行しよう。今回は<code>discrete_ps</code>に対してグリッドサーチを行う。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw">makeTuneControlGrid</span>()
res =<span class="st"> </span><span class="kw">tuneParams</span>(<span class="st">&quot;classif.ksvm&quot;</span>, <span class="dt">task =</span> iris.task, <span class="dt">resampling =</span> rdesc,
                 <span class="dt">par.set =</span> discrete_ps, <span class="dt">control =</span> ctrl)</code></pre></div>
<pre><code>$&gt; [Tune] Started tuning learner classif.ksvm for parameter set:</code></pre>
<pre><code>$&gt;           Type len Def      Constr Req Tunable Trafo
$&gt; C     discrete   -   - 0.5,1,1.5,2   -    TRUE     -
$&gt; sigma discrete   -   - 0.5,1,1.5,2   -    TRUE     -</code></pre>
<pre><code>$&gt; With control class: TuneControlGrid</code></pre>
<pre><code>$&gt; Imputation value: 1</code></pre>
<pre><code>$&gt; [Tune-x] 1: C=0.5; sigma=0.5</code></pre>
<pre><code>$&gt; [Tune-y] 1: mmce.test.mean=0.0533; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 2: C=1; sigma=0.5</code></pre>
<pre><code>$&gt; [Tune-y] 2: mmce.test.mean=0.0533; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 3: C=1.5; sigma=0.5</code></pre>
<pre><code>$&gt; [Tune-y] 3: mmce.test.mean=0.06; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 4: C=2; sigma=0.5</code></pre>
<pre><code>$&gt; [Tune-y] 4: mmce.test.mean=0.06; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 5: C=0.5; sigma=1</code></pre>
<pre><code>$&gt; [Tune-y] 5: mmce.test.mean=0.0667; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 6: C=1; sigma=1</code></pre>
<pre><code>$&gt; [Tune-y] 6: mmce.test.mean=0.06; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 7: C=1.5; sigma=1</code></pre>
<pre><code>$&gt; [Tune-y] 7: mmce.test.mean=0.0467; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 8: C=2; sigma=1</code></pre>
<pre><code>$&gt; [Tune-y] 8: mmce.test.mean=0.0533; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 9: C=0.5; sigma=1.5</code></pre>
<pre><code>$&gt; [Tune-y] 9: mmce.test.mean=0.06; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 10: C=1; sigma=1.5</code></pre>
<pre><code>$&gt; [Tune-y] 10: mmce.test.mean=0.06; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 11: C=1.5; sigma=1.5</code></pre>
<pre><code>$&gt; [Tune-y] 11: mmce.test.mean=0.0667; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 12: C=2; sigma=1.5</code></pre>
<pre><code>$&gt; [Tune-y] 12: mmce.test.mean=0.06; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 13: C=0.5; sigma=2</code></pre>
<pre><code>$&gt; [Tune-y] 13: mmce.test.mean=0.0667; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 14: C=1; sigma=2</code></pre>
<pre><code>$&gt; [Tune-y] 14: mmce.test.mean=0.0667; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 15: C=1.5; sigma=2</code></pre>
<pre><code>$&gt; [Tune-y] 15: mmce.test.mean=0.0667; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune-x] 16: C=2; sigma=2</code></pre>
<pre><code>$&gt; [Tune-y] 16: mmce.test.mean=0.06; time: 0.0 min</code></pre>
<pre><code>$&gt; [Tune] Result: C=1.5; sigma=1 : mmce.test.mean=0.0467</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res</code></pre></div>
<pre><code>$&gt; Tune result:
$&gt; Op. pars: C=1.5; sigma=1
$&gt; mmce.test.mean=0.0467</code></pre>
<p><code>tuneParams</code>はパラメータの全ての組み合わせに対してクロスバリデーションによる性能評価を行い、最も良い値を出した組合せをパラメータとして採用する。性能指標を指定しなかった場合は誤分類率(mmce)が使用される。</p>
<p>それぞれの<code>measure</code>は、その値を最大化すべきか最小化すべきかを<strong>知って</strong>いる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mmce<span class="op">$</span>minimize</code></pre></div>
<pre><code>$&gt; [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">acc<span class="op">$</span>minimize</code></pre></div>
<pre><code>$&gt; [1] FALSE</code></pre>
<p>もちろん、他の指標をリストとして同時に<code>tuneParams</code>に渡すこともできる。この場合、最初の指標が最適化に使われ、残りの指標は単に計算されるだけとなる。もし複数の指標を同時に最適化したいと考えるのであれば、<a href="https://mlr-org.github.io/mlr-tutorial/devel/html/advanced_tune/index.html">Advanced Tuning - mlr tutorial</a>を参照してほしい。</p>
<p>誤分類率の代わりに精度(acc)を計算する例を示そう。同時に、他の性能指標として精度の標準偏差を求めるため、<code>setAggregation</code>関数を使用している。また、今回は探索範囲<code>num_set</code>に対して100回のランダムサーチを行う。100回分の出力は長くなるので、<code>show.info = FALSE</code>を指定している。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw">makeTuneControlRandom</span>(<span class="dt">maxit =</span> 100L)
res =<span class="st"> </span><span class="kw">tuneParams</span>(<span class="st">&quot;classif.ksvm&quot;</span>, <span class="dt">task =</span> iris.task, <span class="dt">resampling =</span> rdesc, <span class="dt">par.set =</span> num_ps,
                 <span class="dt">control =</span> ctrl, <span class="dt">measures =</span> <span class="kw">list</span>(acc, <span class="kw">setAggregation</span>(acc, test.sd)), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
res</code></pre></div>
<pre><code>$&gt; Tune result:
$&gt; Op. pars: C=7.99e+03; sigma=5.62e-05
$&gt; acc.test.mean=0.953,acc.test.sd=0.0115</code></pre>
</div>
<div id="section-9.4" class="section level2">
<h2><span class="header-section-number">9.4</span> チューニング結果へのアクセス</h2>
<p>チューニングの結果は<code>TuneResult</code>クラスのオブジェクトである。見つかった最適値は<code>$x</code>スロット、性能指標については<code>$y</code>スロットを通じてアクセスできる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res<span class="op">$</span>x</code></pre></div>
<pre><code>$&gt; $C
$&gt; [1] 7985.08
$&gt; 
$&gt; $sigma
$&gt; [1] 5.623177e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res<span class="op">$</span>y</code></pre></div>
<pre><code>$&gt; acc.test.mean   acc.test.sd 
$&gt;    0.95333333    0.01154701</code></pre>
<p>最適化されたパラメータをセットした学習器は次のように作成できる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw">setHyperPars</span>(<span class="kw">makeLearner</span>(<span class="st">&quot;classif.ksvm&quot;</span>), <span class="dt">par.vals =</span> res<span class="op">$</span>x)
lrn</code></pre></div>
<pre><code>$&gt; Learner classif.ksvm from package kernlab
$&gt; Type: classif
$&gt; Name: Support Vector Machines; Short name: ksvm
$&gt; Class: classif.ksvm
$&gt; Properties: twoclass,multiclass,numerics,factors,prob,class.weights
$&gt; Predict-Type: response
$&gt; Hyperparameters: fit=FALSE,C=7.99e+03,sigma=5.62e-05</code></pre>
<p>あとはこれまでと同じだ。irisデータセットに対して再度学習と予測を行ってみよう。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m =<span class="st"> </span><span class="kw">train</span>(lrn, iris.task)
<span class="kw">predict</span>(m, <span class="dt">task =</span> iris.task)</code></pre></div>
<pre><code>$&gt; Prediction: 150 observations
$&gt; predict.type: response
$&gt; threshold: 
$&gt; time: 0.00
$&gt;   id  truth response
$&gt; 1  1 setosa   setosa
$&gt; 2  2 setosa   setosa
$&gt; 3  3 setosa   setosa
$&gt; 4  4 setosa   setosa
$&gt; 5  5 setosa   setosa
$&gt; 6  6 setosa   setosa
$&gt; ... (150 rows, 3 cols)</code></pre>
<p>しかし、この方法だと最適化された状態のハイパーパラメータの影響しか見ることができない。検索時に生成された他の値を使った場合の影響はどのように確認すれば良いだろうか？</p>
</div>
<div id="section-9.5" class="section level2">
<h2><span class="header-section-number">9.5</span> ハイパーパラメータチューニングの影響を調査する</h2>
<p><code>generateHyperParsEffectData</code>を使うと、サーチ中に生成された全ての値について調査を行うことができる。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">generateHyperParsEffectData</span>(res)</code></pre></div>
<pre><code>$&gt; HyperParsEffectData:
$&gt; Hyperparameters: C,sigma
$&gt; Measures: acc.test.mean,acc.test.sd
$&gt; Optimizer: TuneControlRandom
$&gt; Nested CV Used: FALSE
$&gt; Snapshot of data:
$&gt;             C     sigma acc.test.mean acc.test.sd iteration exec.time
$&gt; 1  3.90155148  9.392509     0.2733333  0.02309401         1     0.051
$&gt; 2 -0.47745952  3.929691     0.2733333  0.02309401         2     0.053
$&gt; 3  0.99951412  9.447758     0.2733333  0.02309401         3     0.048
$&gt; 4  6.24138379 -8.314684     0.8866667  0.03055050         4     0.065
$&gt; 5  0.04530898  2.955353     0.2733333  0.02309401         5     0.048
$&gt; 6  8.61392138 -5.444293     0.9400000  0.06928203         6     0.047</code></pre>
<p>この中に含まれているパラメータの値は<strong>オリジナルのスケール</strong>であることに注意しよう。<code>trafo</code>に指定した関数で変換後の値が欲しければ、<code>trafo</code>引数に<code>TRUE</code>を指定する必要がある。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">generateHyperParsEffectData</span>(res, <span class="dt">trafo =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>$&gt; HyperParsEffectData:
$&gt; Hyperparameters: C,sigma
$&gt; Measures: acc.test.mean,acc.test.sd
$&gt; Optimizer: TuneControlRandom
$&gt; Nested CV Used: FALSE
$&gt; Snapshot of data:
$&gt;              C        sigma acc.test.mean acc.test.sd iteration exec.time
$&gt; 1 7.971710e+03 2.468934e+09     0.2733333  0.02309401         1     0.051
$&gt; 2 3.330738e-01 8.505326e+03     0.2733333  0.02309401         2     0.053
$&gt; 3 9.988818e+00 2.803873e+09     0.2733333  0.02309401         3     0.048
$&gt; 4 1.743347e+06 4.845250e-09     0.8866667  0.03055050         4     0.065
$&gt; 5 1.109964e+00 9.023045e+02     0.2733333  0.02309401         5     0.048
$&gt; 6 4.110753e+08 3.595068e-06     0.9400000  0.06928203         6     0.047</code></pre>
<p>また、リサンプリングの部分で説明したように、テストデータに加えて訓練データに対しても性能指標を求められることに注意してもらいたい。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rdesc2 =<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;Holdout&quot;</span>, <span class="dt">predict =</span> <span class="st">&quot;both&quot;</span>)
res2 =<span class="st"> </span><span class="kw">tuneParams</span>(<span class="st">&quot;classif.ksvm&quot;</span>, <span class="dt">task =</span> iris.task, <span class="dt">resampling =</span> rdesc2, <span class="dt">par.set =</span> num_ps,
                  <span class="dt">control =</span> ctrl, <span class="dt">measures =</span> <span class="kw">list</span>(acc, <span class="kw">setAggregation</span>(acc, train.mean)), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
<span class="kw">generateHyperParsEffectData</span>(res2)</code></pre></div>
<pre><code>$&gt; HyperParsEffectData:
$&gt; Hyperparameters: C,sigma
$&gt; Measures: acc.test.mean,acc.train.mean
$&gt; Optimizer: TuneControlRandom
$&gt; Nested CV Used: FALSE
$&gt; Snapshot of data:
$&gt;            C       sigma acc.test.mean acc.train.mean iteration exec.time
$&gt; 1 -9.6272136  2.46479089          0.28           0.36         1     0.028
$&gt; 2  0.5922449 -2.19815745          0.98           0.94         2     0.025
$&gt; 3  5.2125327 -0.46505868          0.96           1.00         3     0.026
$&gt; 4 -1.1182917  3.99346631          0.28           0.36         4     0.039
$&gt; 5  0.5484059  9.10947156          0.30           1.00         5     0.027
$&gt; 6  3.8318971  0.04571449          0.96           1.00         6     0.024</code></pre>
<p>パラメータ値の評価結果は<code>plotHyperParsEffect</code>関数を使うと簡単に可視化できる。例を示そう。以下では、繰り返し毎の性能指標の変化をプロットしている。ここで<code>res</code>は先に示したものとほぼ同じだが、2つの性能指標を使用している。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res =<span class="st"> </span><span class="kw">tuneParams</span>(<span class="st">&quot;classif.ksvm&quot;</span>, <span class="dt">task =</span> iris.task, <span class="dt">resampling =</span> rdesc, <span class="dt">par.set =</span> num_ps,
                 <span class="dt">control =</span> ctrl, <span class="dt">measures =</span> <span class="kw">list</span>(acc, mmce), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
data =<span class="st"> </span><span class="kw">generateHyperParsEffectData</span>(res)
<span class="kw">plotHyperParsEffect</span>(data, <span class="dt">x =</span> <span class="st">&quot;iteration&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;acc.test.mean&quot;</span>, <span class="dt">plot.type =</span> <span class="st">&quot;line&quot;</span>)</code></pre></div>
<p><img src="mlr_tutorial_ja_files/figure-html/unnamed-chunk-173-1.png" width="672" /></p>
<p>デフォルトではプロットされるのは現在の大域的な最適値のみであるという点に注意してほしい。これは<code>global.only</code>引数で制御できる。</p>
<p>ハイパーパラメータチューニング結果のプロットについてより詳細な話題は<a href="https://mlr-org.github.io/mlr-tutorial/devel/html/hyperpar_tuning_effects/index.html">Hyperparameter Tuning Effects - mlr tutorial</a>を確認してほしい。</p>
</div>
<div id="section-9.6" class="section level2">
<h2><span class="header-section-number">9.6</span> その他いろいろ</h2>
<ul>
<li>回帰や生存時間分析、その他のタスクについてもチューニングのやり方は変わらない。</li>
<li>時間のかかるチューニングで、数値エラーやその他のエラーで計算が停止してしまうのは非常に煩わしい。この点に関する解決策を得るには、<code>configureMlr</code>関数の<code>on.learner.error</code>引数について調べてみると良いだろう。<a href="https://mlr-org.github.io/mlr-tutorial/devel/html/configureMlr/index.html">Configuration - mlr tutorial</a>にこの件に関するチュートリアルがある。また、<a href="https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/TuneControl">TuneControl function | R Documentation</a>の<code>impute.val</code>引数に関する情報も役立つだろう。</li>
<li>チューニングは同じデータに対して継続的に実施するため、推定値は楽観的な方向にバイアスがかかっている可能性がある。バイアスのない推定値を得るためのより良いアプローチとしてnested resamplingがある。これは、モデル選択のプロセスを外部リサンプリングループに埋め込む。詳しくは<a href="https://mlr-org.github.io/mlr-tutorial/devel/html/nested_resampling/index.html">Nested Resampling - mlr tutorial</a>を参照。</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-8.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-10.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
