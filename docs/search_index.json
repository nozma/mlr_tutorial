[
["index.html", "mlrパッケージチュートリアル", " mlrパッケージチュートリアル mlrのチュートリアル(mlr tutorial)の訳です(未完)。 内容は開発版に基づいています。 最終更新: 2018-03-04 "],
["quick-start.html", "Section 1 Quick start 1.1 タスクの定義 1.2 学習器の定義 1.3 (データを訓練セットとテストセットに分割する) 1.4 訓練 1.5 予測 1.6 評価", " Section 1 Quick start もしまだmlrパッケージをインストールしていなければインストールしておこう。依存パッケージまで含めるとかなり時間がかかるかもしれない。インストールしたらパッケージを読み込んでおこう。 install.packages(&quot;mlr&quot;, dependencies = TRUE) library(mlr) なお、これ以降はmlrは読み込み済みだと仮定して話を進める。 インストールが終わったら簡単にmlrのワークフローをみてみよう。mlrで機械学習の問題を扱う場合の流れは、大雑把に言って5つのステップに分けることができる。 タスクの定義 学習器の定義 訓練 予測 評価 1.1 タスクの定義 まずはタスクを定義する。タスクはすぐ次のセクションで説明するが、問題の概要をまとめたオブジェクトのことだ。ここには問題の種類や、扱うデータセットに関する情報が含まれる。以下ではデータセットirisを対象に、分類問題のタスクを定義している。 task = makeClassifTask(data = iris, target = &quot;Species&quot;) 1.2 学習器の定義 ここでは学習器オブジェクトを作成して、タスクに対してどのようなアルゴリズムを適用するかを決定する。このアルゴリズム自体はいろいろなパッケージで実装されているものだが、mlrを使うと、これらを統一したインターフェースで取り扱うことができる。以下では分類手法として線形判別分析を指定している。 lrn = makeLearner(&quot;classif.lda&quot;) 1.3 (データを訓練セットとテストセットに分割する) ここではデータセットを訓練セットとテストセットに分割しているが、これは本来mlrを使用する場合は行う必要の無い作業だという点に注意してもらいたい。mlrにはこのような作業を行うためのもっと良い方法が用意されているが、今はここでの説明を簡単にするためにこのような方法を採っているだけだ。 n = nrow(iris) train.set = sample(n, size = 2/3*n) test.set = setdiff(1:n, train.set) 一応何をしているか説明しておくと、irisの行数に対応するインデックスを、無作為に訓練用とテスト用に割り振っている。 1.4 訓練 訓練は基本的には作成した学習器とタスクのオブジェクトをtrain関数に渡すと実行できる。ここでは先程作成した訓練セットのインデックスを利用して、タスク内のデータセットから訓練に使用する部分を指定している。 model = train(lrn, task, subset = train.set) 1.5 予測 訓練セットを適合したフィット済みモデルを使って、新しいデータに対する出力を予測するにはpredict関数を使う。Rの他の関数(lmやglmなど)と基本的には使い方は同じだ。 pred = predict(model, task = task, subset = test.set) 1.6 評価 mlrにはいろいろな指標でフィット済みモデルを評価する方法が備えられている。以下では予測結果から性能指標を計算している。 performance(pred, measures = list(mmce, acc)) $&gt; mmce acc $&gt; 0.04 0.96 誤分類率0.04、精度0.96で分類できた、という結果が得られた。 なお、ここでは色々ともっと良いやり方を省略していることに注意してほしい。では、もっと良いやり方をこの先のセクションで順次見ていこう。 "],
["section-2.html", "Section 2 タスク 2.1 タスクの種類と作成 2.2 その他の設定 2.3 タスクへのアクセス 2.4 タスクの編集 2.5 タスクの例と便利な関数", " Section 2 タスク タスクはデータ及び機械学習問題に関する情報、例えば教師あり学習におけるターゲットの名前などをカプセル化したものだ。 2.1 タスクの種類と作成 全てのタスクはTaskクラスを頂点とする階層構造を持っている。以下に示すクラスは全てTaskのサブクラスである。 RegrTask: 回帰分析に関するタスク。 ClassifTask: 2クラス分類または多クラス分類に関するタスク(注: コストがクラス依存であるコスト考慮型分類も扱うことができる)。 SurvTask: 生存時間分析に関するタスク。 ClusterTask: クラスター分析に関するタスク。 MultilabelTask: マルチラベル分類に関するタスク。 CostSensTask: 一般のコスト考慮型分類に関するタスク(コストが事例に依存するもの)。 タスクを作成するには、make&lt;タスク名&gt;というような名前の関数を使う。例えば分類タスクであればmakeClassifTaskである。全てのタスクはID(引数idに指定する)とデータフレーム(引数dataに指定する)を最低限必要とする。ただし、IDを未指定の場合は、データの変数名に基づいて自動的に割り当てられる。IDはプロットの際の注釈や、ベンチマークテストの際に名前として使われる。また、問題の性質に応じて、追加の引数が必要となる場合もある。 以下にそれぞれのタスクの生成方法を説明する。 2.1.1 回帰 教師あり学習である回帰では、dataの他に目的変数列名であるtargetを指定する必要がある。これは後に見る分類と生存時間分析においても同様である。 data(BostonHousing, package = &quot;mlbench&quot;) regr.task = makeRegrTask(id = &quot;bh&quot;, data = BostonHousing, target = &quot;medv&quot;) regr.task $&gt; Supervised task: bh $&gt; Type: regr $&gt; Target: medv $&gt; Observations: 506 $&gt; Features: $&gt; numerics factors ordered $&gt; 12 1 0 $&gt; Missings: FALSE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE Taskオブジェクトの中には、学習問題のタイプと、データセットに関する基本的な情報(例えば特徴量の型やデータ数、欠測値の有無など)が格納されている。 分類でも生存時間分析でもタスク作成の基本的な枠組みは同じである。ただし、dataの中の目的変数の種類は異なる。これについては以下で述べる。 2.1.2 分類 分類問題では、目的変数は因子型でなければならない。 以下にBreastCancerデータセットを使って分類タスクを作成する例を示そう。ここではId列を除外していることに注意してもらいたい(訳注: Id列はその意味から考えて特徴量に含めるのが適当でないのは当然のこと、character型であるため特徴量に含めようとしてもエラーがでる)。 data(BreastCancer, package = &quot;mlbench&quot;) df = BreastCancer df$Id = NULL classif.task = makeClassifTask(id = &quot;BreastCancer&quot;, data = df, target = &quot;Class&quot;) classif.task $&gt; Supervised task: BreastCancer $&gt; Type: classif $&gt; Target: Class $&gt; Observations: 699 $&gt; Features: $&gt; numerics factors ordered $&gt; 0 4 5 $&gt; Missings: TRUE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE $&gt; Classes: 2 $&gt; benign malignant $&gt; 458 241 $&gt; Positive class: benign 2クラス分類においては、しばしばそれぞれのクラスをpositiveとnegativeに対応させる。上記例を見るとわかるように、デフォルトでは因子型における最初のレベルがpositiveに割り当てられるが、引数positiveによって明示的に指定することもできる。 makeClassifTask(data = df, target = &quot;Class&quot;, positive = &quot;malignant&quot;) $&gt; Supervised task: df $&gt; Type: classif $&gt; Target: Class $&gt; Observations: 699 $&gt; Features: $&gt; numerics factors ordered $&gt; 0 4 5 $&gt; Missings: TRUE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE $&gt; Classes: 2 $&gt; benign malignant $&gt; 458 241 $&gt; Positive class: malignant 2.1.3 生存時間分析 生存時間分析においては目的変数列が2つ必要になる。左打ち切り及び右打ち切りデータでは、生存時間と打ち切りかどうかを示す二値変数が必要である。区間打ち切りデータでは、interval2形式でのデータ指定が必要である(詳しくはSurv function | R Documentationを参照)。 data(lung, package = &quot;survival&quot;) # statusは1=censored, 2=deadとして符号化されているので、 # 論理値に変換する必要がある。 lung$status = (lung$status == 2) surv.task = makeSurvTask(data = lung, target = c(&quot;time&quot;, &quot;status&quot;)) surv.task $&gt; Supervised task: lung $&gt; Type: surv $&gt; Target: time,status $&gt; Events: 165 $&gt; Observations: 228 $&gt; Features: $&gt; numerics factors ordered $&gt; 8 0 0 $&gt; Missings: TRUE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE 打ち切りの種類はcensoring引数で明示的に指定できる。デフォルトはrcens(右打ち切り)である。 2.1.4 マルチラベル分類 マルチラベル分類とは、対象が複数のカテゴリに同時に属す可能性があるような分類問題である。 dataにはクラスラベルと同じだけの数の目的変数列が必要である。また、それぞれの目的変数列は論理値によってそのクラスに属するかどうかを示す必要がある。 以下にyeastデータを用いた例を示そう。 yeast = getTaskData(yeast.task) labels = colnames(yeast)[1:14] yeast.task = makeMultilabelTask(id = &quot;multi&quot;, data = yeast, target = labels) yeast.task $&gt; Supervised task: multi $&gt; Type: multilabel $&gt; Target: label1,label2,label3,label4,label5,label6,label7,label8,label9,label10,label11,label12,label13,label14 $&gt; Observations: 2417 $&gt; Features: $&gt; numerics factors ordered $&gt; 103 0 0 $&gt; Missings: FALSE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE $&gt; Classes: 14 $&gt; label1 label2 label3 label4 label5 label6 label7 label8 label9 $&gt; 762 1038 983 862 722 597 428 480 178 $&gt; label10 label11 label12 label13 label14 $&gt; 253 289 1816 1799 34 2.1.5 クラスター分析 クラスター分析は教師なし学習の一種である。タスクの作成に必須の引数はdataだけだ。mtcarsを使ってクラスター分析のタスクを作成する例を示そう。 data(mtcars, package = &quot;datasets&quot;) cluster.task = makeClusterTask(data = mtcars) cluster.task $&gt; Unsupervised task: mtcars $&gt; Type: cluster $&gt; Observations: 32 $&gt; Features: $&gt; numerics factors ordered $&gt; 11 0 0 $&gt; Missings: FALSE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE 2.1.6 コスト考慮型分類 一般に分類問題では精度を最大化すること、つまり誤分類の数を最小化することが目的となる。つまり、これは全ての誤分類の価値を平等と考えるということである。しかし、問題によっては間違いの価値は平等とは言えないことがある。例えば健康や金融に関わる問題では、ある間違いは他の間違いよりより深刻であるということがあり得ることは容易に想像できるだろう。 コスト考慮型問題のうち、コストがクラスラベルの種類にのみ依存するような問題は、ClassifTaskにて扱うことができる。 一方、コストが事例に依存するような例はCostSensTaskでタスクを作成する必要がある。このケースでは入力\\(x\\)と出力\\(y\\)からなる事例\\((x, y)\\)がそれぞれコストベクトル\\(K\\)に結びついていることを想定する。コストベクトル\\(K\\)はクラスラベルの数と同じ長さをもち、\\(k\\)番目の要素は\\(x\\)をクラス\\(k\\)に結びつけた場合のコストを表す。当然、\\(y\\)はコストを最小化するように選択されることが期待される。 コストベクトルはクラス\\(y\\)に関する全ての情報を包含するので、CostSensTaskを作成するために必要なのは、全ての事例に対するコストベクトルをまとめたコスト行列と、特徴量のみである。 irisと人工的に作成したコスト行列を使ってコスト考慮型分類タスクを作成する例を示そう。 set.seed(123) df = iris cost = matrix(runif(150 * 3, 0, 2000), 150) * (1 - diag(3))[df$Species, ] df$Species = NULL costsens.task = makeCostSensTask(data = df, cost = cost) costsens.task $&gt; Supervised task: df $&gt; Type: costsens $&gt; Observations: 150 $&gt; Features: $&gt; numerics factors ordered $&gt; 4 0 0 $&gt; Missings: FALSE $&gt; Has blocking: FALSE $&gt; Classes: 3 $&gt; y1, y2, y3 2.2 その他の設定 それぞれのタスク作成関数のヘルプページを確認すると、その他の引数についての情報を得ることができるだろう。 例えば、blocking引数は、幾つかの観測値が一緒であることを示す。これによって、リサンプリングの際にそれらのデータが分割されなくなる。 他にweightsという引数がある。これは単に観測頻度やデータ採取方法に由来する重みを表現するための方法であって、重みが本当にタスクに属している場合にのみ使用するようにしてもらいたい。もし、同じタスク内で重みを変化させて訓練をしたいと考えているのであれば、mlrはそのための他の方法を用意している。詳しくはtrainingのチュートリアルページかmakeWeightedClassesWrapper関数のヘルプを確認してもらいたい。 2.3 タスクへのアクセス タスクオブジェクト内の要素を取得する方法は複数ある。これらの中で重要なものは各タスクおよびgetTaskDataのヘルプページにリストアップされている。 まずは?TaskDescでリストアップされている要素を取得する方法を示そう。 getTaskDesc(classif.task) $&gt; $id $&gt; [1] &quot;BreastCancer&quot; $&gt; $&gt; $type $&gt; [1] &quot;classif&quot; $&gt; $&gt; $target $&gt; [1] &quot;Class&quot; $&gt; $&gt; $size $&gt; [1] 699 $&gt; $&gt; $n.feat $&gt; numerics factors ordered $&gt; 0 4 5 $&gt; $&gt; $has.missings $&gt; [1] TRUE $&gt; $&gt; $has.weights $&gt; [1] FALSE $&gt; $&gt; $has.blocking $&gt; [1] FALSE $&gt; $&gt; $class.levels $&gt; [1] &quot;benign&quot; &quot;malignant&quot; $&gt; $&gt; $positive $&gt; [1] &quot;benign&quot; $&gt; $&gt; $negative $&gt; [1] &quot;malignant&quot; $&gt; $&gt; attr(,&quot;class&quot;) $&gt; [1] &quot;ClassifTaskDesc&quot; &quot;SupervisedTaskDesc&quot; &quot;TaskDesc&quot; 取得できる要素の種類はタスクの種類によって多少異なる。 よく使う要素については、直接アクセスする手段が用意されている。 ## ID getTaskId(classif.task) $&gt; [1] &quot;BreastCancer&quot; ## タスクの種類 getTaskType(classif.task) $&gt; [1] &quot;classif&quot; ## 目的変数の列名 getTaskTargetNames(classif.task) $&gt; [1] &quot;Class&quot; ## 観測値の数 getTaskSize(classif.task) $&gt; [1] 699 ## 特徴量の種類数 getTaskNFeats(classif.task) $&gt; [1] 9 ## クラスレベル getTaskClassLevels(classif.task) $&gt; [1] &quot;benign&quot; &quot;malignant&quot; mlrはさらに幾つかの関数を提供する。 ## タスク内のデータ str(getTaskData(classif.task)) $&gt; &#39;data.frame&#39;: 699 obs. of 10 variables: $&gt; $ Cl.thickness : Ord.factor w/ 10 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;&lt;&quot;4&quot;&lt;..: 5 5 3 6 4 8 1 2 2 4 ... $&gt; $ Cell.size : Ord.factor w/ 10 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;&lt;&quot;4&quot;&lt;..: 1 4 1 8 1 10 1 1 1 2 ... $&gt; $ Cell.shape : Ord.factor w/ 10 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;&lt;&quot;4&quot;&lt;..: 1 4 1 8 1 10 1 2 1 1 ... $&gt; $ Marg.adhesion : Ord.factor w/ 10 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;&lt;&quot;4&quot;&lt;..: 1 5 1 1 3 8 1 1 1 1 ... $&gt; $ Epith.c.size : Ord.factor w/ 10 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;&lt;&quot;4&quot;&lt;..: 2 7 2 3 2 7 2 2 2 2 ... $&gt; $ Bare.nuclei : Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 10 2 4 1 10 10 1 1 1 ... $&gt; $ Bl.cromatin : Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 3 3 3 3 3 9 3 3 1 2 ... $&gt; $ Normal.nucleoli: Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 1 7 1 7 1 1 1 1 ... $&gt; $ Mitoses : Factor w/ 9 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 1 1 1 1 1 5 1 ... $&gt; $ Class : Factor w/ 2 levels &quot;benign&quot;,&quot;malignant&quot;: 1 1 1 1 1 2 1 1 1 1 ... ## 特徴量の名前 getTaskFeatureNames(cluster.task) $&gt; [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; $&gt; [11] &quot;carb&quot; ## 目的変数の値 head(getTaskTargets(surv.task)) $&gt; time status $&gt; 1 306 TRUE $&gt; 2 455 TRUE $&gt; 3 1010 FALSE $&gt; 4 210 TRUE $&gt; 5 883 TRUE $&gt; 6 1022 FALSE ## コスト行列 head(getTaskCosts(costsens.task)) $&gt; y1 y2 y3 $&gt; [1,] 0 1694.9063 1569.15053 $&gt; [2,] 0 995.0545 18.85981 $&gt; [3,] 0 775.8181 1558.13177 $&gt; [4,] 0 492.8980 1458.78130 $&gt; [5,] 0 222.1929 1260.26371 $&gt; [6,] 0 779.9889 961.82166 2.4 タスクの編集 mlrには既存のタスクを編集するための関数も用意されている。既存タスクの編集は、新しいタスクをゼロから作成するよりも便利な場合がある。以下に例を示そう。 ## dataの編集 cluster.task2 = subsetTask(cluster.task, subset = 4:17) getTaskData(cluster.task) $&gt; mpg cyl disp hp drat wt qsec vs am gear carb $&gt; Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 $&gt; Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 $&gt; Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 $&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 $&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 $&gt; Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 $&gt; Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 $&gt; Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 $&gt; Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 $&gt; Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 $&gt; Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 $&gt; Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 $&gt; Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 $&gt; Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 $&gt; Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 $&gt; Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 $&gt; Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 $&gt; Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 $&gt; Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 $&gt; Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 $&gt; Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 $&gt; Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 $&gt; AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 $&gt; Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 $&gt; Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 $&gt; Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 $&gt; Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 $&gt; Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 $&gt; Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 $&gt; Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 $&gt; Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 $&gt; Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 getTaskData(cluster.task2) $&gt; mpg cyl disp hp drat wt qsec vs am gear carb $&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 $&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 $&gt; Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 $&gt; Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 $&gt; Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 $&gt; Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 $&gt; Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 $&gt; Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 $&gt; Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 $&gt; Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 $&gt; Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 $&gt; Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 $&gt; Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 $&gt; Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 dataのサブセットをとると、特徴量によっては値に変化がなくなる場合がある。上記の例ではam列の値が全て0になる。このような特徴量を除外する関数としてremoveConstantFeaturesがある。 removeConstantFeatures(cluster.task2) $&gt; Removing 1 columns: am $&gt; Unsupervised task: mtcars $&gt; Type: cluster $&gt; Observations: 14 $&gt; Features: $&gt; numerics factors ordered $&gt; 10 0 0 $&gt; Missings: FALSE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE 特定の特徴量を除外したい場合は、dropFeaturesが使える。 dropFeatures(surv.task, c(&quot;meal.cal&quot;, &quot;wt.loss&quot;)) $&gt; Supervised task: lung $&gt; Type: surv $&gt; Target: time,status $&gt; Events: 165 $&gt; Observations: 228 $&gt; Features: $&gt; numerics factors ordered $&gt; 6 0 0 $&gt; Missings: TRUE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE 数値型の特徴量を正規化したければnormalizeFeaturesを使おう。 task = normalizeFeatures(cluster.task, method = &quot;range&quot;) summary(getTaskData(task)) $&gt; mpg cyl disp hp $&gt; Min. :0.0000 Min. :0.0000 Min. :0.0000 Min. :0.0000 $&gt; 1st Qu.:0.2138 1st Qu.:0.0000 1st Qu.:0.1240 1st Qu.:0.1572 $&gt; Median :0.3745 Median :0.5000 Median :0.3123 Median :0.2509 $&gt; Mean :0.4124 Mean :0.5469 Mean :0.3982 Mean :0.3346 $&gt; 3rd Qu.:0.5277 3rd Qu.:1.0000 3rd Qu.:0.6358 3rd Qu.:0.4523 $&gt; Max. :1.0000 Max. :1.0000 Max. :1.0000 Max. :1.0000 $&gt; drat wt qsec vs $&gt; Min. :0.0000 Min. :0.0000 Min. :0.0000 Min. :0.0000 $&gt; 1st Qu.:0.1475 1st Qu.:0.2731 1st Qu.:0.2848 1st Qu.:0.0000 $&gt; Median :0.4309 Median :0.4633 Median :0.3821 Median :0.0000 $&gt; Mean :0.3855 Mean :0.4358 Mean :0.3987 Mean :0.4375 $&gt; 3rd Qu.:0.5346 3rd Qu.:0.5362 3rd Qu.:0.5238 3rd Qu.:1.0000 $&gt; Max. :1.0000 Max. :1.0000 Max. :1.0000 Max. :1.0000 $&gt; am gear carb $&gt; Min. :0.0000 Min. :0.0000 Min. :0.0000 $&gt; 1st Qu.:0.0000 1st Qu.:0.0000 1st Qu.:0.1429 $&gt; Median :0.0000 Median :0.5000 Median :0.1429 $&gt; Mean :0.4062 Mean :0.3438 Mean :0.2589 $&gt; 3rd Qu.:1.0000 3rd Qu.:0.5000 3rd Qu.:0.4286 $&gt; Max. :1.0000 Max. :1.0000 Max. :1.0000 2.5 タスクの例と便利な関数 利便性のために、mlrには予めいくつかのタスクが定義してある。チュートリアルでもコードを短くするためにこれらを使う場合がある。これらの一覧はExample Tasks - mlr tutorialを参照のこと。 また、convertMLBenchObjToTask関数は、mlbenchパッケージに含まれるデータセットやデータ生成関数に由来するデータからタスクを生成するための関数である。 "],
["section-3.html", "Section 3 学習器 3.1 学習器を構築する 3.2 学習器へアクセスする 3.3 学習器の編集 3.4 学習器一覧", " Section 3 学習器 以下に示すクラスは、(コスト考慮型)分類、回帰、生存時間分析、クラスタリングのための統一的なインターフェースを提供する。多くの手法はすでにmlrに統合されているが、そうでないものもある。しかし、パッケージは容易に拡張できるよう設計されている。 Integrated Learners - mlr tutorialには実装済みの手法とその特徴について一覧が示してある。もし使いたい手法が見つからなければ、issueに書き込むか、Create Custom Learners - mlr tutorialを確認してもらいたい。 まずは実装済みの手法についていかに使用するかを説明しよう。 3.1 学習器を構築する 学習器はmakeLearner関数で作成する。このとき、どのような学習手法を使うのかを指定する。加えて以下の要素を指定できる。 ハイパーパラメータの指定。 予測後の出力方法(例えば、分類問題において予測されたクラスラベルなのか、確率なのか) ID(いくつかの手法ではこのIDを出力やプロット時の名前として利用できる) ## ランダムフォレストによる分類で確率も出力する classif.lrn = makeLearner( &quot;classif.randomForest&quot;, predict.type = &quot;prob&quot;, fix.factors.prediction = TRUE) ## 勾配ブースティング回帰でハイパーパラメータも指定する regr.lrn = makeLearner( &quot;regr.gbm&quot;, par.vals = list(n.trees = 500, interaction.depth = 3)) ## コックス比例ハザードモデルでidも指定する surv.lrn = makeLearner(&quot;surv.coxph&quot;, id = &quot;cph&quot;) ## K平均法でクラスタ数を指定する cluster.lrn = makeLearner(&quot;cluster.kmeans&quot;, centers = 5) ## マルチラベルRandom-Ferns multilabel.lrn = makeLearner(&quot;multilabel.rFerns&quot;) 最初の引数はどのアルゴリズムを使うのかを指定する。アルゴリズム名は以下の命名規則に従っている。 classif.&lt;Rのメソッド名&gt;: 分類 regr.&lt;Rのメソッド名&gt;: 回帰 surv.&lt;Rのメソッド名&gt;: 生存時間分析 cluster.&lt;Rのメソッド名&gt;: クラスター分析 multilabel.&lt;Rのメソッド名&gt;: マルチラベル分類 ハイパーパラメータは...引数として渡すか、par.vals引数にリストとして渡せる。 因子型の特徴量は、訓練データよりテストデータの方が水準が少なくなってしまうという問題が起こるときがある。fix.factors.prediction = TRUEを指定しておけば、不足する水準をテストデータに加えるという方法によってこの問題を回避できる。 では、先ほど作成した学習器の中身を見てみよう。 classif.lrn $&gt; Learner classif.randomForest from package randomForest $&gt; Type: classif $&gt; Name: Random Forest; Short name: rf $&gt; Class: classif.randomForest $&gt; Properties: twoclass,multiclass,numerics,factors,ordered,prob,class.weights,oobpreds,featimp $&gt; Predict-Type: prob $&gt; Hyperparameters: surv.lrn $&gt; Learner cph from package survival $&gt; Type: surv $&gt; Name: Cox Proportional Hazard Model; Short name: coxph $&gt; Class: surv.coxph $&gt; Properties: numerics,factors,weights,rcens $&gt; Predict-Type: response $&gt; Hyperparameters: 全ての学習器はLearnerクラスのオブジェクトである。クラスには、どのような種類の特徴量を扱えるのか、予測の際にはどのような種類の出力が可能か、マルチクラス分類の問題なのか、観測値は重み付けられているのか、欠測値はサポートされているのか、といった、手法に関する情報が含まれている。 気づいたかも知れないが、今のところコスト考慮型分類に関する専用のクラスはない。一般的な誤分類コストについては、標準的な分類手法で扱うことができる。事例依存的なコストについては、コスト考慮型の学習器を一般的な回帰と分類の学習機から生成するための方法がいくつかある。この点についてはこのセクションで扱うには大きすぎるので、別途セクションを設けて解説してある。 3.2 学習器へアクセスする Learnerオブジェクトはリストであり、ハイパーパラメータと予測の種類に関する情報を含んでいる。 ## デフォルト値以外を指定したハイパーパラメータ cluster.lrn$par.vals $&gt; $centers $&gt; [1] 5 ## ハイパーパラメータ一覧 cluster.lrn$par.set $&gt; Type len Def Constr $&gt; centers untyped - - - $&gt; iter.max integer - 10 1 to Inf $&gt; nstart integer - 1 1 to Inf $&gt; algorithm discrete - Hartigan-Wong Hartigan-Wong,Lloyd,Forgy,MacQueen $&gt; trace logical - - - $&gt; Req Tunable Trafo $&gt; centers - TRUE - $&gt; iter.max - TRUE - $&gt; nstart - TRUE - $&gt; algorithm - TRUE - $&gt; trace - FALSE - ##予測のタイプ regr.lrn$predict.type $&gt; [1] &quot;response&quot; $par.setスロットにはParamSetクラスのオブジェクトが入っている。これには、ハイパーパラメータの型(数値なのか論理型なのか)、デフォルト値、そして可能な値の範囲が格納されている。 また、mlrはLernerの現在のハイパーパラメータの設定にアクセスするgetHyperParsやgetLernerParVals、可能な設定項目の詳細を取得するgetParamSet関数を用意している。これらは、ラップされた学習器において特に有用である場合がある。例えば、学習器が特徴量選択の手法と融合しており、特徴量選択手法と学習器の両方がハイパーパラメータを持つような場合である。この点については別途セクションを設けて解説している。 ## ハイパーパラメータのセッティングの取得 getHyperPars(cluster.lrn) $&gt; $centers $&gt; [1] 5 ## 設定可能なハイパーパラメータの詳細一覧 getParamSet(cluster.lrn) $&gt; Type len Def Constr $&gt; centers untyped - - - $&gt; iter.max integer - 10 1 to Inf $&gt; nstart integer - 1 1 to Inf $&gt; algorithm discrete - Hartigan-Wong Hartigan-Wong,Lloyd,Forgy,MacQueen $&gt; trace logical - - - $&gt; Req Tunable Trafo $&gt; centers - TRUE - $&gt; iter.max - TRUE - $&gt; nstart - TRUE - $&gt; algorithm - TRUE - $&gt; trace - FALSE - また、getParamSet(またはそのエイリアスであるgetLearnerParamSet)を使い、Lernerオブジェクトを作成すること無くそのデフォルト値を取得することもできる。 getParamSet(&quot;classif.randomForest&quot;) $&gt; Type len Def Constr Req Tunable Trafo $&gt; ntree integer - 500 1 to Inf - TRUE - $&gt; mtry integer - - 1 to Inf - TRUE - $&gt; replace logical - TRUE - - TRUE - $&gt; classwt numericvector &lt;NA&gt; - 0 to Inf - TRUE - $&gt; cutoff numericvector &lt;NA&gt; - 0 to 1 - TRUE - $&gt; strata untyped - - - - FALSE - $&gt; sampsize integervector &lt;NA&gt; - 1 to Inf - TRUE - $&gt; nodesize integer - 1 1 to Inf - TRUE - $&gt; maxnodes integer - - 1 to Inf - TRUE - $&gt; importance logical - FALSE - - TRUE - $&gt; localImp logical - FALSE - - TRUE - $&gt; proximity logical - FALSE - - FALSE - $&gt; oob.prox logical - - - Y FALSE - $&gt; norm.votes logical - TRUE - - FALSE - $&gt; do.trace logical - FALSE - - FALSE - $&gt; keep.forest logical - TRUE - - FALSE - $&gt; keep.inbag logical - FALSE - - FALSE - 学習器に関するメタデータにアクセスするための関数も用意してある。 ## 学習器のID getLearnerId(surv.lrn) $&gt; [1] &quot;cph&quot; ## 学習器の略称 getLearnerShortName(classif.lrn) $&gt; [1] &quot;rf&quot; ## 学習機のタイプ getLearnerType(multilabel.lrn) $&gt; [1] &quot;multilabel&quot; ## 学習器に必要なパッケージ getLearnerPackages(cluster.lrn) $&gt; [1] &quot;stats&quot; &quot;clue&quot; 3.3 学習器の編集 Learnerオブジェクトを作り直すことなしに編集する関数が用意されている。以下に例を示そう。 ## IDの変更 surv.lrn = setLearnerId(surv.lrn, &quot;CoxModel&quot;) surv.lrn $&gt; Learner CoxModel from package survival $&gt; Type: surv $&gt; Name: Cox Proportional Hazard Model; Short name: coxph $&gt; Class: surv.coxph $&gt; Properties: numerics,factors,weights,rcens $&gt; Predict-Type: response $&gt; Hyperparameters: ## 予測タイプの変更 classif.lrn = setPredictType(classif.lrn, &quot;response&quot;) ## ハイパーパラメータ cluster.lrn = setHyperPars(cluster.lrn, centers = 4) ## 設定値を除去してデフォルト値に戻す regr.lrn = removeHyperPars(regr.lrn, c(&quot;n.trees&quot;, &quot;interaction.depth&quot;)) 3.4 学習器一覧 mlrに統合されている学習器とその特性はIntegrated Learners - mlr tutorialに示してある。 もし、特定のプロパティや特定のタスクに対して利用可能な学習器の一覧がほしければ、listLearners関数を使うと良いだろう。 ## 全ての学習器一覧 head(listLearners()[c(&quot;class&quot;, &quot;package&quot;)]) $&gt; class package $&gt; 1 classif.ada ada $&gt; 2 classif.bartMachine bartMachine $&gt; 3 classif.bdk kohonen $&gt; 4 classif.binomial stats $&gt; 5 classif.blackboost mboost,party $&gt; 6 classif.boosting adabag,rpart ## 確率を出力可能な分類器 head(listLearners(&quot;classif&quot;, properties = &quot;prob&quot;)[c(&quot;class&quot;, &quot;package&quot;)]) $&gt; class package $&gt; 1 classif.ada ada $&gt; 2 classif.bartMachine bartMachine $&gt; 3 classif.bdk kohonen $&gt; 4 classif.binomial stats $&gt; 5 classif.blackboost mboost,party $&gt; 6 classif.boosting adabag,rpart ## iris(つまり多クラス)に使えて、確率を出力できる head(listLearners(iris.task, properties = &quot;prob&quot;)[c(&quot;class&quot;, &quot;package&quot;)]) $&gt; class package $&gt; 1 classif.bdk kohonen $&gt; 2 classif.boosting adabag,rpart $&gt; 3 classif.C50 C50 $&gt; 4 classif.cforest party $&gt; 5 classif.ctree party $&gt; 6 classif.cvglmnet glmnet ## Learnerオブジェクトを作成することもできる listLearners(&quot;cluster&quot;, create = TRUE)[[1]] "],
["section-4.html", "Section 4 学習器の訓練 4.1 学習器モデルへのアクセス 4.2 その他のオプションとコメント", " Section 4 学習器の訓練 学習器の訓練というのは要するにモデルをデータセットに適合させることだ。これにより学習器はデータセットに合わせた予測能力を得る。mlrパッケージでは、train関数を学習器とタスクに対し呼び出すことで実行できる。 まずは分類問題の例として、irisデータセットで線形判別分析を行ってみよう。 ## タスクの作成 task = makeClassifTask(data = iris, target = &quot;Species&quot;) ## 学習器の作成 lrn = makeLearner(&quot;classif.lda&quot;) ## 学習器の訓練 mod = train(lrn, task) mod $&gt; Model for learner.id=classif.lda; learner.class=classif.lda $&gt; Trained on: task.id = iris; obs = 150; features = 4 $&gt; Hyperparameters: 上記の例では実際には明示的に学習器を作成する必要はない。学習器のデフォルト値(ハイパーパラメータや予測タイプなど)を変更したい場合には、明示的に学習器を作成する必要がある。そうでなければ、trainや他の多くの関数にはLernerのクラス名を指定すればよい。そうすればデフォルトの設定でmakeLearnerが呼び出され、学習器に指定される。 mod = train(&quot;classif.lda&quot;, task) mod $&gt; Model for learner.id=classif.lda; learner.class=classif.lda $&gt; Trained on: task.id = iris; obs = 150; features = 4 $&gt; Hyperparameters: どのようなタイプの問題でも、学習器の訓練の仕方は同じだ。生存時間分析の例として、コックス比例ハザードモデルをlungデータセットに適用する例を示す(タスクとしてmlrパッケージに予め用意されているlung.taskを使用している点に注意してもらいたい)。 mod = train(&quot;surv.coxph&quot;, lung.task) mod $&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph $&gt; Trained on: task.id = lung-example; obs = 167; features = 8 $&gt; Hyperparameters: 4.1 学習器モデルへのアクセス train関数はWrappedModelクラスのオブジェクトを返す。このオブジェクトはフィット済みのモデル、すなわち基礎となるRの学習メソッドの出力をカプセル化している。加えて、オブジェクトには学習器、タスク、訓練に使った特徴量と観測値、訓練にかかった時間なども含まれている。WrappedModelは続けて新しい観測値を使った予測に使用することができる。 フィット済みモデルは$learner.modelスロットに入っており、getLearnerModel関数でアクセスできる。 以下にruspiniデータセット(これは4つのグループと2つの特徴量を持つ)を\\(K\\)=4の\\(K\\)-means法でクラスタ化する例を示すとともに、基本となるkmeans関数から出力を抽出する。 data(ruspini, package = &quot;cluster&quot;) plot(y~x, ruspini) ## タスクの作成 ruspini.task = makeClusterTask(data = ruspini) ## 学習器の作成 lrn = makeLearner(&quot;cluster.kmeans&quot;, centers = 4) ## 学習機の訓練 mod = train(lrn, ruspini.task) mod $&gt; Model for learner.id=cluster.kmeans; learner.class=cluster.kmeans $&gt; Trained on: task.id = ruspini; obs = 75; features = 2 $&gt; Hyperparameters: centers=4 ## モデルの中身を覗いてみる names(mod) $&gt; [1] &quot;learner&quot; &quot;learner.model&quot; &quot;task.desc&quot; &quot;subset&quot; $&gt; [5] &quot;features&quot; &quot;factor.levels&quot; &quot;time&quot; &quot;dump&quot; mod$features $&gt; [1] &quot;x&quot; &quot;y&quot; mod$time $&gt; [1] 0.002 ## フィット済みモデルの抽出 getLearnerModel(mod) $&gt; K-means clustering with 4 clusters of sizes 17, 23, 15, 20 $&gt; $&gt; Cluster means: $&gt; x y $&gt; 1 98.17647 114.8824 $&gt; 2 43.91304 146.0435 $&gt; 3 68.93333 19.4000 $&gt; 4 20.15000 64.9500 $&gt; $&gt; Clustering vector: $&gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 $&gt; 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 $&gt; 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 $&gt; 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 $&gt; 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 $&gt; 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 $&gt; $&gt; Within cluster sum of squares by cluster: $&gt; [1] 4558.235 3176.783 1456.533 3689.500 $&gt; (between_SS / total_SS = 94.7 %) $&gt; $&gt; Available components: $&gt; $&gt; [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; $&gt; [5] &quot;tot.withinss&quot; &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; $&gt; [9] &quot;ifault&quot; 4.2 その他のオプションとコメント デフォルトではタスクに含まれる全てのデータが訓練に使用される。subset引数に論理型または整数ベクトルを与えることで、どのデータを訓練に使用するのかを指定できる。これは例えば、データを訓練データとテストデータに分割したい場合や、データの部分ごとに異なるモデルを適用したい場合などに活用できる。 ランダムに選んだ1/3のデータを訓練データとして、BostonHousingデータに線形回帰モデルを適用する例を示そう。 ## 観測値の例数を取得 n = getTaskSize(bh.task) ## 1:nからランダムにn/3個非復元抽出 train.set = sample(n, size = n/3) ## 学習器を訓練する mod = train(&quot;regr.lm&quot;, bh.task, subset = train.set) mod $&gt; Model for learner.id=regr.lm; learner.class=regr.lm $&gt; Trained on: task.id = BostonHousing-example; obs = 168; features = 13 $&gt; Hyperparameters: ところであとで見るように、標準的なリサンプリング手法はサポートされている。したがって、基本的には自分でデータのサブセットを指定する必要はない。 また、学習器がサポートしている場合には、weights引数にこれを指定することで訓練に観測値の重みを反映させることができる。重みは観測値の信頼性や、外れ値の影響の低減、(長期間に渡ってデータを採取する場合)最近取得したデータの重要性を高めるなど、様々な目的で使用できる。教師あり分類においては、誤分類コストを組み込んだり、クラス間の不均衡を反映したりできる。 例えばBreastCancerデータではbenignはmalignantのほぼ2倍発生している。この2つのクラスを平等に扱うために、各事例をクラス頻度の逆数によって重み付けすることができる。以下に例を示そう。 ## 観測値の重みを計算する target = getTaskTargets(bc.task) tab = as.numeric(table(target)) w = 1/tab[target] train(&quot;classif.rpart&quot;, task = bc.task, weights = w) $&gt; Model for learner.id=classif.rpart; learner.class=classif.rpart $&gt; Trained on: task.id = BreastCancer-example; obs = 683; features = 9 $&gt; Hyperparameters: xval=0 あとで見るように、mlrは上記例のような不均衡な分類問題を扱うために非常に多くの機能を備えている。 上級者へ: trainを呼び出す際の重みを変えることで、任意のmlrの学習器をベースとしたブースティングタイプのアルゴリズムを実装することもできる。 気づいたと思うが、Taskオブジェクト作成時に重み付けをすることもできる。一般的には、重みが本質的にタスクに属しており、常に設定されるべきだと考える場合にはTaskオブジェクト作成時に設定すべきだ。そうでなければ、訓練時に設定しよう。なお、train呼び出し時に設定した重みは、Taskオブジェクト作成時に設定したものよりも優先される。 "],
["-1.html", "Section 5 予測 5.1 新しいデータに対する結果を予測する 5.2 予測へのアクセス 5.3 回帰: 標準誤差を取得する 5.4 分類とクラスタリング: 確率を取得する 5.5 分類: 混同行列を取得する 5.6 分類: 決定閾値の調整 5.7 予測の可視化", " Section 5 予測 5.1 新しいデータに対する結果を予測する 新しい観測値に対する目的変数の予測は、Rの他の予測手法と同じように実装されている。一般的には、predictをtrainが返すオブジェクトに対して呼び出し、予測したいデータを渡すだけだ。 データを渡す方法は2種類ある。 task引数を通じてTaskオブジェクトを渡す。 newdata引数を通じてdata.frameを渡す。 最初の方法は、予測したいデータが既にTaskオブジェクトに含まれている場合に適している。 trainと同様に、predictもsubset引数を備えている。したがって、Taskオブジェクトに含まれるデータの異なる部分を訓練と予測に割り当てることができる(より進んだデータ分割の方法はリサンプリングのセクションであらためて解説する)。 以下に、BostonHousingデータに対し、1つおきの観測値に勾配ブースティングマシンによるフィットを行い、残った観測値に対して予測を行う例を示す。データはbh.taskに予め入っているものを使用する。 n = getTaskSize(bh.task) train.set = seq(1, n, by = 2) test.set = seq(2, n, by = 2) lrn = makeLearner(&quot;regr.gbm&quot;, n.trees = 100) mod = train(lrn, bh.task, subset = train.set) task.pred = predict(mod, task = bh.task, subset = test.set) task.pred $&gt; Prediction: 253 observations $&gt; predict.type: response $&gt; threshold: $&gt; time: 0.00 $&gt; id truth response $&gt; 2 2 21.6 22.19745 $&gt; 4 4 33.4 23.25992 $&gt; 6 6 28.7 22.38456 $&gt; 8 8 27.1 22.13503 $&gt; 10 10 18.9 22.13503 $&gt; 12 12 18.9 22.13503 $&gt; ... (253 rows, 3 cols) 2つめの方法は予測したいデータがTaskオブジェクトに含まれていない場合に使える。 目的変数を除外したirisを使ってクラスター分析を行う例を示そう。奇数インデックスの要素をTaskオブジェクトに含めて訓練を行い、残ったオブジェクトに対して予測を行う。 n = nrow(iris) iris.train = iris[seq(1, n, by = 2), -5] iris.test = iris[seq(2, n, by = 2), -5] task = makeClusterTask(data = iris.train) mod = train(&quot;cluster.kmeans&quot;, task) newdata.pred = predict(mod, newdata = iris.test) newdata.pred $&gt; Prediction: 75 observations $&gt; predict.type: response $&gt; threshold: $&gt; time: 0.00 $&gt; response $&gt; 2 1 $&gt; 4 1 $&gt; 6 1 $&gt; 8 1 $&gt; 10 1 $&gt; 12 1 $&gt; ... (75 rows, 1 cols) なお、教師あり学習の場合はデータセットから目的変数列を削除する必要はない。これはpredictを呼び出す際に自動的に削除される。 5.2 予測へのアクセス predict関数はPredictionクラスの名前付きリストを返す。もっとも重要な要素は$dataであり、このdata.frameは目的変数の真値と予測値の列を含む(教師あり学習の場合)。as.data.frameを使うとこれに直接アクセスできる。 ## task引数を通じてデータを渡した例の結果 head(as.data.frame(task.pred)) $&gt; id truth response $&gt; 2 2 21.6 22.19745 $&gt; 4 4 33.4 23.25992 $&gt; 6 6 28.7 22.38456 $&gt; 8 8 27.1 22.13503 $&gt; 10 10 18.9 22.13503 $&gt; 12 12 18.9 22.13503 ## newdata引数を通じてデータを渡した場合の結果 head(as.data.frame(newdata.pred)) $&gt; response $&gt; 2 1 $&gt; 4 1 $&gt; 6 1 $&gt; 8 1 $&gt; 10 1 $&gt; 12 1 Taskオブジェクトを通じてデータを渡した例の結果を見るとわかるように、結果のdata.frameにはid列が追加されている。これは、予測値が元のデータセットのどの値に対応しているのかを示している。 真値と予測値に直接アクセスするための関数としてgetPredictionTruth関数とgetPredictionResponse関数が用意されている。 head(getPredictionTruth(task.pred)) $&gt; [1] 21.6 33.4 28.7 27.1 18.9 18.9 head(getPredictionResponse(task.pred)) $&gt; [1] 22.19745 23.25992 22.38456 22.13503 22.13503 22.13503 5.3 回帰: 標準誤差を取得する 学習器のなかには標準誤差の出力に対応しているものがあるが、これもmlrからアクセスできる。対応している学習器の一覧は、listLearners関数に引数properties = &quot;se&quot;を指定して呼び出すことで取得できる。このとき、check.packages = FALSEを指定することで、他のパッケージ由来の学習器で当該パッケージをまだインストールしていないものについても一覧に含めることができる。 listLearners(&quot;regr&quot;, properties = &quot;se&quot;, check.packages = FALSE)[c(&quot;class&quot;, &quot;name&quot;)] $&gt; class $&gt; 1 regr.bcart $&gt; 2 regr.bgp $&gt; 3 regr.bgpllm $&gt; 4 regr.blm $&gt; 5 regr.btgp $&gt; 6 regr.btgpllm $&gt; name $&gt; 1 Bayesian CART $&gt; 2 Bayesian Gaussian Process $&gt; 3 Bayesian Gaussian Process with jumps to the Limiting Linear Model $&gt; 4 Bayesian Linear Model $&gt; 5 Bayesian Treed Gaussian Process $&gt; 6 Bayesian Treed Gaussian Process with jumps to the Limiting Linear Model $&gt; ... (15 rows, 2 cols) 標準誤差出力の例として、BostonHousingに線形回帰モデルを適用する場合を示そう。標準誤差を計算するためには、predict.typeに&quot;se&quot;を指定する。 lrn.lm = makeLearner(&quot;regr.lm&quot;, predict.type = &quot;se&quot;) mod.lm = train(lrn.lm, bh.task, subset = train.set) task.pred.lm = predict(mod.lm, task = bh.task, subset = test.set) task.pred.lm $&gt; Prediction: 253 observations $&gt; predict.type: se $&gt; threshold: $&gt; time: 0.00 $&gt; id truth response se $&gt; 2 2 21.6 24.83734 0.7501615 $&gt; 4 4 33.4 28.38206 0.8742590 $&gt; 6 6 28.7 25.16725 0.8652139 $&gt; 8 8 27.1 19.38145 1.1963265 $&gt; 10 10 18.9 18.66449 1.1793944 $&gt; 12 12 18.9 21.25802 1.0727918 $&gt; ... (253 rows, 4 cols) 標準誤差だけが欲しければ、getPredictionSE関数を使用する。 head(getPredictionSE(task.pred.lm)) $&gt; [1] 0.7501615 0.8742590 0.8652139 1.1963265 1.1793944 1.0727918 5.4 分類とクラスタリング: 確率を取得する 予測値に対する確率はPredictionオブジェクトにgetPredictionProbabilities関数を使うことで取得できる。以下にクラスタ分析の別の例を示そう。ここではファジイc-means法によりmtcarsデータセットをクラスタリングしている。 lrn = makeLearner(&quot;cluster.cmeans&quot;, predict.type = &quot;prob&quot;) mod = train(lrn, mtcars.task) pred = predict(mod, task = mtcars.task) head(getPredictionProbabilities(pred)) $&gt; 1 2 $&gt; Mazda RX4 0.97959380 0.020406201 $&gt; Mazda RX4 Wag 0.97963402 0.020365983 $&gt; Datsun 710 0.99266041 0.007339591 $&gt; Hornet 4 Drive 0.54291331 0.457086691 $&gt; Hornet Sportabout 0.01870551 0.981294490 $&gt; Valiant 0.75745946 0.242540537 分類問題においては、注目すべきものがいくつかあるが、デフォルトではクラスラベルが予測される。 mod = train(&quot;classif.lda&quot;, task = iris.task) pred = predict(mod, task = iris.task) pred $&gt; Prediction: 150 observations $&gt; predict.type: response $&gt; threshold: $&gt; time: 0.00 $&gt; id truth response $&gt; 1 1 setosa setosa $&gt; 2 2 setosa setosa $&gt; 3 3 setosa setosa $&gt; 4 4 setosa setosa $&gt; 5 5 setosa setosa $&gt; 6 6 setosa setosa $&gt; ... (150 rows, 3 cols) 事後確率を得たければ、学習器を作成する際にpredict.type引数に適当な値を指定する必要がある。 lrn = makeLearner(&quot;classif.rpart&quot;, predict.type = &quot;prob&quot;) mod = train(lrn, iris.task) pred = predict(mod, newdata = iris) head(as.data.frame(pred)) $&gt; truth prob.setosa prob.versicolor prob.virginica response $&gt; 1 setosa 1 0 0 setosa $&gt; 2 setosa 1 0 0 setosa $&gt; 3 setosa 1 0 0 setosa $&gt; 4 setosa 1 0 0 setosa $&gt; 5 setosa 1 0 0 setosa $&gt; 6 setosa 1 0 0 setosa クラスラベルは確率が最大のものが選択され、確率がタイの要素があればアトランダムに選択される。 もし事後確率だけがほしければgetPredictionProbabilities関数を使う。 head(getPredictionProbabilities(pred)) $&gt; setosa versicolor virginica $&gt; 1 1 0 0 $&gt; 2 1 0 0 $&gt; 3 1 0 0 $&gt; 4 1 0 0 $&gt; 5 1 0 0 $&gt; 6 1 0 0 5.5 分類: 混同行列を取得する 混同行列はcalculateConfusionMatrix関数により得ることが出来る。列は予測したクラス、行は真のクラスのラベルを表す。 calculateConfusionMatrix(pred) $&gt; predicted $&gt; true setosa versicolor virginica -err.- $&gt; setosa 50 0 0 0 $&gt; versicolor 0 49 1 1 $&gt; virginica 0 5 45 5 $&gt; -err.- 0 5 1 6 対角成分には正しく分類された要素の数が、それ以外の部分には誤分類された要素の数が現れる。また、-err.-の行および列には誤分類された要素の合計数が表示される。 relative=TRUEを指定することで、相対頻度を得ることも出来る。 conf.matrix = calculateConfusionMatrix(pred, relative = TRUE) conf.matrix $&gt; Relative confusion matrix (normalized by row/column): $&gt; predicted $&gt; true setosa versicolor virginica -err.- $&gt; setosa 1.00/1.00 0.00/0.00 0.00/0.00 0.00 $&gt; versicolor 0.00/0.00 0.98/0.91 0.02/0.02 0.02 $&gt; virginica 0.00/0.00 0.10/0.09 0.90/0.98 0.10 $&gt; -err.- 0.00 0.09 0.02 0.04 $&gt; $&gt; $&gt; Absolute confusion matrix: $&gt; predicted $&gt; true setosa versicolor virginica -err.- $&gt; setosa 50 0 0 0 $&gt; versicolor 0 49 1 1 $&gt; virginica 0 5 45 5 $&gt; -err.- 0 5 1 6 相対頻度を計算する際、行方向と列方向の2通りの正規化の仕方があるため、上記相対混同行列の中には各要素ごとに2つの値が現れている。セットになった2つの値の1つめは行方向、つまり真のラベルについてグループ化した値で、2つめは予測値についてグループ化した値である。 相対値は$relative.rowおよび$relative.colを通して直接アクセスすることもできる。詳しくはConfusionMatrixのドキュメント(ConfusionMatrix function | R Documentation)を参照してもらいたい。 conf.matrix$relative.row $&gt; setosa versicolor virginica -err- $&gt; setosa 1 0.00 0.00 0.00 $&gt; versicolor 0 0.98 0.02 0.02 $&gt; virginica 0 0.10 0.90 0.10 最後に、予測値および真値について、各クラスに振り分けられた要素数をsums=TRUEを指定することで結果に追加できる。これは相対混同行列と絶対混同行列の両方に追加される(訳注: 相対と絶対で行列が入れ替わっているのはなぜだ…？)。 calculateConfusionMatrix(pred, relative = TRUE, sums = TRUE) $&gt; Relative confusion matrix (normalized by row/column): $&gt; predicted $&gt; true setosa versicolor virginica -err.- -n- $&gt; setosa 1.00/1.00 0.00/0.00 0.00/0.00 0.00 50 $&gt; versicolor 0.00/0.00 0.98/0.91 0.02/0.02 0.02 54 $&gt; virginica 0.00/0.00 0.10/0.09 0.90/0.98 0.10 46 $&gt; -err.- 0.00 0.09 0.02 0.04 &lt;NA&gt; $&gt; -n- 50 50 50 &lt;NA&gt; 150 $&gt; $&gt; $&gt; Absolute confusion matrix: $&gt; setosa versicolor virginica -err.- -n- $&gt; setosa 50 0 0 0 50 $&gt; versicolor 0 49 1 1 50 $&gt; virginica 0 5 45 5 50 $&gt; -err.- 0 5 1 6 NA $&gt; -n- 50 54 46 NA 150 5.6 分類: 決定閾値の調整 事後確率をクラスラベルに割り当てるために用いる閾値は調整することができる。閾値を調整するためには、そもそも確率を予測する学習器を使用する必要があるという点に注意しよう。2クラス分類では、閾値はpositiveクラスに分類するための基準となる。デフォルトは0.5だ。例として閾値を0.9にしてみよう。つまり、事後確率が0.9を上回った時にpositiveに分類するということだ。2つのクラスのどちらがpositiveになっているかは(以前確認したとおり)Taskオブジェクトを通じて確認できる。今回は2クラス分類の例としてmlbenchパッケージのSonarデータを使おう。 ## 学習器の作成と訓練。タスクは用意されているものを使う。 lrn = makeLearner(&quot;classif.rpart&quot;, predict.type = &quot;prob&quot;) mod = train(lrn, task = sonar.task) ## positiveクラスのラベルを確認する getTaskDesc(sonar.task)$positive $&gt; [1] &quot;M&quot; ## デフォルトの閾値で予測する pred1 = predict(mod, sonar.task) pred1$threshold $&gt; M R $&gt; 0.5 0.5 ## positiveクラスに分類する閾値を変更する pred2 = setThreshold(pred1, threshold = 0.9) pred2$threshold $&gt; M R $&gt; 0.9 0.1 pred2 $&gt; Prediction: 208 observations $&gt; predict.type: prob $&gt; threshold: M=0.90,R=0.10 $&gt; time: 0.01 $&gt; id truth prob.M prob.R response $&gt; 1 1 R 0.1060606 0.8939394 R $&gt; 2 2 R 0.7333333 0.2666667 R $&gt; 3 3 R 0.0000000 1.0000000 R $&gt; 4 4 R 0.1060606 0.8939394 R $&gt; 5 5 R 0.9250000 0.0750000 M $&gt; 6 6 R 0.0000000 1.0000000 R $&gt; ... (208 rows, 5 cols) 閾値の変更は混同行列に対しても影響する。 calculateConfusionMatrix(pred1) $&gt; predicted $&gt; true M R -err.- $&gt; M 95 16 16 $&gt; R 10 87 10 $&gt; -err.- 10 16 26 calculateConfusionMatrix(pred2) $&gt; predicted $&gt; true M R -err.- $&gt; M 84 27 27 $&gt; R 6 91 6 $&gt; -err.- 6 27 33 getPredictionProbabilitiesはデフォルトではpositiveクラスの事後確率しか返さない事に注意しよう。 head(getPredictionProbabilities(pred1)) $&gt; [1] 0.1060606 0.7333333 0.0000000 0.1060606 0.9250000 0.0000000 次のようにすると全ての事例について確率を得ることができる。 head(getPredictionProbabilities(pred1, cl = c(&quot;M&quot;, &quot;R&quot;))) $&gt; M R $&gt; 1 0.1060606 0.8939394 $&gt; 2 0.7333333 0.2666667 $&gt; 3 0.0000000 1.0000000 $&gt; 4 0.1060606 0.8939394 $&gt; 5 0.9250000 0.0750000 $&gt; 6 0.0000000 1.0000000 多クラス分類の場合は、閾値は名前付き数値ベクトルとして与える。予測結果の確率は与えた数値で除算された後に比較され、最大値を持つクラスが予測クラスとして選択される。 lrn = makeLearner(&quot;classif.rpart&quot;, predict.type = &quot;prob&quot;) mod = train(lrn, iris.task) pred = predict(mod, newdata = iris) pred$threshold # デフォルトの閾値 $&gt; setosa versicolor virginica $&gt; 0.3333333 0.3333333 0.3333333 ## 閾値の変更 大きな値を指定するほど予測されにくくなる pred = setThreshold(pred, c(setosa = 0.01, versicolor = 50, virginica = 1)) pred$threshold $&gt; setosa versicolor virginica $&gt; 0.01 50.00 1.00 table(as.data.frame(pred)$response) $&gt; $&gt; setosa versicolor virginica $&gt; 50 0 100 5.7 予測の可視化 モデルの説明や教育目的で予測を可視化したければ、plotLearnerPrediction関数を使うことができる。この関数は学習器から1つないし2つの特徴量を選んで訓練したのち、その結果をggplot2パッケージを用いてプロットする。 分類では、2つの特徴量(デフォルトではデータセットのはじめの2つが選ばれる)を選んで散布図を作成する。シンボルの形状は真のクラスラベルに対応する。誤分類されたシンボルは、周囲が白色の線で囲われることで強調される。学習器がサポートしていれば、事後確率は背景色の彩度により表現され、事後確率が高い部分ほど高彩度となる。 set.seed(777) lrn = makeLearner(&quot;classif.rpart&quot;, id = &quot;CART&quot;) plotLearnerPrediction(lrn, task = iris.task) クラスター分析も2つの特徴量による散布図を作成する。この場合はシンボルの色がクラスターに対応する。 lrn = makeLearner(&quot;cluster.kmeans&quot;) plotLearnerPrediction(lrn, mtcars.task, features = c(&quot;disp&quot;, &quot;drat&quot;), cv = 0) $&gt; $&gt; This is package &#39;modeest&#39; written by P. PONCET. $&gt; For a complete list of functions, use &#39;library(help = &quot;modeest&quot;)&#39; or &#39;help.start()&#39;. 回帰に対してはプロットが2種類ある。1Dプロットでは一つの特徴量と目的変数の関係が示される。このとき、回帰曲線と(学習器がサポートしていれば)推定標準誤差が示される。 plotLearnerPrediction(&quot;regr.lm&quot;, features = &quot;lstat&quot;, task = bh.task) 2Dプロットでは分類の場合と同様に2つの特徴量による散布図が作成される。この場合シンボルの塗りつぶし色が目的変数の値に対応し、予測値は背景色として示される。標準誤差は示すことができない。 plotLearnerPrediction(&quot;regr.lm&quot;, features = c(&quot;lstat&quot;, &quot;rm&quot;), task = bh.task) "],
["section-6.html", "Section 6 データの前処理 6.1 前処理と学習器を融合する 6.2 makePreprocWrapperCaretを使用した前処理 6.3 前処理オプションと学習器パラメータの連結チューニング 6.4 独自の前処理ラッパーを書く", " Section 6 データの前処理 データの前処理というのは、学習アルゴリズムを適用する前にデータに施すあらゆる種類の変換のことだ。例えば、データの矛盾の発見と解決、欠損値への代入、外れ値の特定・除去・置換、数値データの離散化、カテゴリカルデータからのダミー変数の生成、標準化やBox-Cox変換などのあらゆる種類の変換、次元削減、特徴量の抽出・選択などが含まれる。 mlrは前処理に関して幾つかの選択肢を用意している。以下に示すようなタスク(あるいはデータフレーム)を変更する単純な手法の中には、タスクについての説明で既に触れたものもある。 capLargeValues: 大きな値や無限大の値の変換。 createDummyFeature: 因子型特徴量からのダミー変数の生成。 dropFeatures: 特徴量の削除。 joinClassLevels: (分類のみ)複数のクラスを併合して、大きな1つのクラスにする。 mergeSmallFactorLevels: 因子型特徴量において、例数の少ない水準を併合する。 normalizeFeatures: 正規化には複数の異なったやり方がある。標準化や特定の範囲への再スケールなど。 removeConstantFeatures: 1つの値しか持っていない特徴量(=定数)を除去する。 subsetTask: 観測値や特徴量をタスクから除去する。 また、以下のものについてはチュートリアルを用意してある。 特徴量選択 欠損値への代入 6.1 前処理と学習器を融合する mlrのラッパー機能により、学習器と前処理を組み合わせることができる。これは、前処理が学習器に属し、訓練や予測の度に実行されるということを意味する。 このようにすることで非常に便利な点がある。データやタスクの変更なしに、簡単に学習器と前処理の組合せを変えることができるのだ。 また、これは前処理を行ってから学習器のパフォーマンスを測定する際にありがちな一般的な間違いを避けることにもつながる。前処理は学習アルゴリズムとは完全に独立したものだと考えられがちだ。学習器のパフォーマンスを測定する場合を考えてみよう。例えば、クロスバリデーションで雨処理を事前にデータセット全体に対して行い、学習と予測は学習器だけで行うような場合だ。前処理として何が行われたかによっては、評価が楽観的になる危険性がある。例えば、(欠損値への)平均値の代入という前処理が学習器の性能評価前に、データ全体を対象に行われたとすると、これは楽観的なパフォーマンス評価につながる。 前処理にはデータ依存的なものとデータ非依存的なものがあることをはっきりさせておこう。データ依存的な前処理とは、前処理のやり方がデータに依存しており、データセットが異なれば結果も異なるというようなもののことだ。一方でデータ非依存的な前処理は常に結果が同じになる。 データの間違いを修正したり、ID列のような学習に使うべきではないデータ列の除去のような前処理は、明らかにデータ非依存的である。一方、先程例に挙げた欠損値への平均値の代入はデータ依存的である。代入を定数で行うのであれば違うが。 前処理と組み合わせた学習器の性能評価を正しく行うためには、全てのデータ依存的な前処理をリサンプリングに含める必要がある。学習器と前処理を融合させれば、これは自動的に可能になる。 この目的のために、mlrパッケージは2つのラッパーを用意している。 makePreprocWrapperCaretはcaretパッケージのpreProcess関数に対するインターフェースを提供するラッパー。 makePreprocWrapperを使えば、訓練と予測の前の動作を定義することで独自の前処理を作成できる。 これらを使用する前処理は、normalizeFeaturesなどを使う前処理とは異なり、ラップされた学習器に組み込まれる。 タスクそのものは変更されない。 前処理はデータ全体に対して予め行われるのではなく、リサンプリングなど、訓練とテストの対が発生する毎に実行される。 前処理に関わる制御可能なパラメータは、学習器のパラメータと一緒に調整できる。 まずはmakePreprocWrapperCaretの例から見ていこう。 6.2 makePreprocWrapperCaretを使用した前処理 makePreprocWrapperCaretはcaretパッケージのpreProcess関数へのインターフェースだ。PreProcess関数は、欠損値への代入やスケール変換やBox-Cox変換、独立主成分分析による次元削減など、様々な手法を提供する関数だ。具体的に何が可能かはpreProcess関数のヘルプページ(preProcess function | R Documentation)を確認してもらいたい。 まず、makePreprocWrapperCaretとpreProcessの違いを確認しておこう。 makePreprocWrapperCaretはpreProcessとほぼ同じ仮引数を持つが、仮引数名にppc.というプレフィックスが付く。 上記の例外はmethod引数だ。この引数はmakePreprocWrapperCaretには無い。その代わりに、本来methodに渡す前処理に関するオプションは、対応する仮引数に論理値を指定することで制御する。 例を見よう。preProcessでは行列またはデータフレームxに対して、次のように前処理を行う。 preProcess(x, method= c(&quot;knnInpute&quot;, &quot;pca&quot;), pcaComp = 10) 一方、makePreporcWrapperCaretでは、Learnerクラスのオブジェクトまたはクラスの名前(&quot;classif.lda&quot;など)を引数にとって、次のように前処理を指定する。 makePreprocWrapperCaret(learner, ppc.knnImpute = TRUE, ppc.pca = TRUE, ppc.pcaComp = 10) この例のように複数の前処理(注: kNNを使った代入と主成分分析)を有効にした場合、それらは特定の順序で実行される。詳細はpreProcess関数のヘルプを確認してほしい(訳注: Details後半の“The operations are applied in this order:…”以下。主成分分析は代入後に実施。)。 以下に主成分分析による次元削減の例を示そう。これは無闇に使用して良い手法ではないが、高次元のデータで問題が起こるような学習器や、データの回転が有用な学習器に対しては有効である。 例ではsoner.taskを用いる。これは208の観測値と60の特徴量を持つ。 sonar.task $&gt; Supervised task: Sonar-example $&gt; Type: classif $&gt; Target: Class $&gt; Observations: 208 $&gt; Features: $&gt; numerics factors ordered $&gt; 60 0 0 $&gt; Missings: FALSE $&gt; Has weights: FALSE $&gt; Has blocking: FALSE $&gt; Classes: 2 $&gt; M R $&gt; 111 97 $&gt; Positive class: M 今回は、MASSパッケージによる二次判別分析と、主成分分析による前処理を組み合わせる。また、閾値として0.9を設定する。これはつまり、主成分が累積寄与率90%を保持しなければならないという指示になる。データは主成分分析の前に自動的に標準化される。 lrn = makePreprocWrapperCaret(&quot;classif.qda&quot;, ppc.pca = TRUE, ppc.thresh = 0.9) lrn $&gt; Learner classif.qda.preproc from package MASS $&gt; Type: classif $&gt; Name: ; Short name: $&gt; Class: PreprocWrapperCaret $&gt; Properties: twoclass,multiclass,numerics,factors,prob $&gt; Predict-Type: response $&gt; Hyperparameters: ppc.BoxCox=FALSE,ppc.YeoJohnson=FALSE,ppc.expoTrans=FALSE,ppc.center=TRUE,ppc.scale=TRUE,ppc.range=FALSE,ppc.knnImpute=FALSE,ppc.bagImpute=FALSE,ppc.medianImpute=FALSE,ppc.pca=TRUE,ppc.ica=FALSE,ppc.spatialSign=FALSE,ppc.thresh=0.9,ppc.na.remove=TRUE,ppc.k=5,ppc.fudge=0.2,ppc.numUnique=3 ラップされた学習器をsoner.taskによって訓練する。訓練したモデルを確認することで、22の主成分が訓練に使われたことがわかるだろう。 mod = train(lrn, sonar.task) mod $&gt; Model for learner.id=classif.qda.preproc; learner.class=PreprocWrapperCaret $&gt; Trained on: task.id = Sonar-example; obs = 208; features = 60 $&gt; Hyperparameters: ppc.BoxCox=FALSE,ppc.YeoJohnson=FALSE,ppc.expoTrans=FALSE,ppc.center=TRUE,ppc.scale=TRUE,ppc.range=FALSE,ppc.knnImpute=FALSE,ppc.bagImpute=FALSE,ppc.medianImpute=FALSE,ppc.pca=TRUE,ppc.ica=FALSE,ppc.spatialSign=FALSE,ppc.thresh=0.9,ppc.na.remove=TRUE,ppc.k=5,ppc.fudge=0.2,ppc.numUnique=3 getLearnerModel(mod) $&gt; Model for learner.id=classif.qda; learner.class=classif.qda $&gt; Trained on: task.id = Sonar-example; obs = 208; features = 22 $&gt; Hyperparameters: getLearnerModel(mod, more.unwrap = TRUE) $&gt; Call: $&gt; qda(f, data = getTaskData(.task, .subset, recode.target = &quot;drop.levels&quot;)) $&gt; $&gt; Prior probabilities of groups: $&gt; M R $&gt; 0.5336538 0.4663462 $&gt; $&gt; Group means: $&gt; PC1 PC2 PC3 PC4 PC5 PC6 $&gt; M 0.5976122 -0.8058235 0.9773518 0.03794232 -0.04568166 -0.06721702 $&gt; R -0.6838655 0.9221279 -1.1184128 -0.04341853 0.05227489 0.07691845 $&gt; PC7 PC8 PC9 PC10 PC11 PC12 $&gt; M 0.2278162 -0.01034406 -0.2530606 -0.1793157 -0.04084466 -0.0004789888 $&gt; R -0.2606969 0.01183702 0.2895848 0.2051963 0.04673977 0.0005481212 $&gt; PC13 PC14 PC15 PC16 PC17 PC18 $&gt; M -0.06138758 -0.1057137 0.02808048 0.05215865 -0.07453265 0.03869042 $&gt; R 0.07024765 0.1209713 -0.03213333 -0.05968671 0.08528994 -0.04427460 $&gt; PC19 PC20 PC21 PC22 $&gt; M -0.01192247 0.006098658 0.01263492 -0.001224809 $&gt; R 0.01364323 -0.006978877 -0.01445851 0.001401586 二次判別分析について、主成分分析を使う場合と使わない場合をベンチマーク試験により比較してみよう。今回の例では各クラスの例数が少ないので、二次判別分析の際のエラーを防ぐためにリサンプリングにおいて層別サンプリングを行っている。 rin = makeResampleInstance(&quot;CV&quot;, iters = 3, stratify = TRUE, task = sonar.task) res = benchmark(list(&quot;classif.qda&quot;, lrn), sonar.task, rin, show.info = FALSE) res $&gt; task.id learner.id mmce.test.mean $&gt; 1 Sonar-example classif.qda 0.3848861 $&gt; 2 Sonar-example classif.qda.preproc 0.1826087 今回の場合では、二次判別分析に対して主成分分析による前処理が効果的だったことがわかる。 6.3 前処理オプションと学習器パラメータの連結チューニング 今の例をもう少し最適化できないか考えてみよう。今回、任意に設定した0.9という閾値によって、主成分は22になった。しかし、主成分の数はもっと多いほうが良いかもしれないし、少ないほうが良いかもしれない。また、qda関数にはクラス共分散行列やクラス確率の推定方法を制御するためのいくつかのオプションがある。 学習機と前処理のパラメータは、連結してチューニングすることができる。まずは、ラップされた学習器の全てのパラメータをgetParamSet関数で確認してみよう。 getParamSet(lrn) $&gt; Type len Def Constr Req $&gt; ppc.BoxCox logical - FALSE - - $&gt; ppc.YeoJohnson logical - FALSE - - $&gt; ppc.expoTrans logical - FALSE - - $&gt; ppc.center logical - TRUE - - $&gt; ppc.scale logical - TRUE - - $&gt; ppc.range logical - FALSE - - $&gt; ppc.knnImpute logical - FALSE - - $&gt; ppc.bagImpute logical - FALSE - - $&gt; ppc.medianImpute logical - FALSE - - $&gt; ppc.pca logical - FALSE - - $&gt; ppc.ica logical - FALSE - - $&gt; ppc.spatialSign logical - FALSE - - $&gt; ppc.thresh numeric - 0.95 0 to Inf - $&gt; ppc.pcaComp integer - - 1 to Inf - $&gt; ppc.na.remove logical - TRUE - - $&gt; ppc.k integer - 5 1 to Inf - $&gt; ppc.fudge numeric - 0.2 0 to Inf - $&gt; ppc.numUnique integer - 3 1 to Inf - $&gt; ppc.n.comp integer - - 1 to Inf - $&gt; method discrete - moment moment,mle,mve,t - $&gt; nu numeric - 5 2 to Inf Y $&gt; predict.method discrete - plug-in plug-in,predictive,debiased - $&gt; Tunable Trafo $&gt; ppc.BoxCox TRUE - $&gt; ppc.YeoJohnson TRUE - $&gt; ppc.expoTrans TRUE - $&gt; ppc.center TRUE - $&gt; ppc.scale TRUE - $&gt; ppc.range TRUE - $&gt; ppc.knnImpute TRUE - $&gt; ppc.bagImpute TRUE - $&gt; ppc.medianImpute TRUE - $&gt; ppc.pca TRUE - $&gt; ppc.ica TRUE - $&gt; ppc.spatialSign TRUE - $&gt; ppc.thresh TRUE - $&gt; ppc.pcaComp TRUE - $&gt; ppc.na.remove TRUE - $&gt; ppc.k TRUE - $&gt; ppc.fudge TRUE - $&gt; ppc.numUnique TRUE - $&gt; ppc.n.comp TRUE - $&gt; method TRUE - $&gt; nu TRUE - $&gt; predict.method TRUE - ppc.というプレフィックスのついたものが前処理のパラメータで、他がqda関数のパラメータだ。主成分分析の閾値をppc.threshを使って調整する代わりに、主成分の数そのものをppc.pcaCompを使って調整できる。さらに、qda関数に対しては、2種類の事後確率推定法(通常のプラグイン推定と不偏推定)を試してみよう。 今回は解像度10でグリッドサーチを行ってみよう。もっと解像度を高くしたくなるかもしれないが、今回はあくまでデモだ。 ps = makeParamSet( makeIntegerParam(&quot;ppc.pcaComp&quot;, lower = 1, upper = getTaskNFeats(sonar.task)), makeDiscreteParam(&quot;predict.method&quot;, values = c(&quot;plug-in&quot;, &quot;debiased&quot;)) ) ctrl = makeTuneControlGrid(resolution = 10) res = tuneParams(lrn, sonar.task, rin, par.set = ps, control = ctrl, show.info = FALSE) res $&gt; Tune result: $&gt; Op. pars: ppc.pcaComp=21; predict.method=plug-in $&gt; mmce.test.mean=0.168 as.data.frame(res$opt.path)[1:3] $&gt; ppc.pcaComp predict.method mmce.test.mean $&gt; 1 1 plug-in 0.5288475 $&gt; 2 8 plug-in 0.2066253 $&gt; 3 14 plug-in 0.2162871 $&gt; 4 21 plug-in 0.1681159 $&gt; 5 27 plug-in 0.2500345 $&gt; 6 34 plug-in 0.2404417 $&gt; 7 40 plug-in 0.2643892 $&gt; 8 47 plug-in 0.2836439 $&gt; 9 53 plug-in 0.3318150 $&gt; 10 60 plug-in 0.3848861 $&gt; 11 1 debiased 0.5241546 $&gt; 12 8 debiased 0.2642512 $&gt; 13 14 debiased 0.2933057 $&gt; 14 21 debiased 0.2596963 $&gt; 15 27 debiased 0.2449965 $&gt; 16 34 debiased 0.2304348 $&gt; 17 40 debiased 0.2498275 $&gt; 18 47 debiased 0.2928226 $&gt; 19 53 debiased 0.2739130 $&gt; 20 60 debiased 0.3217391 &quot;plug-in&quot;と&quot;debiased&quot;のいずれでも少なめ(27以下)の主成分が有効で、&quot;plug-in&quot;の方が若干エラー率が低いようだ。 6.4 独自の前処理ラッパーを書く makePreprocWrapperCaretで不満があれば、makePreprocWrapper関数で独自の前処理ラッパーを作成できる。 ラッパーに関するチュートリアルでも説明しているが、ラッパーは訓練と予測という2つのメソッドを使って実装される。前処理ラッパーの場合は、メソッドは学習と予測の前に何をするかを指定するものであり、これは完全にユーザーが指定する。 以下に例として、訓練と予測の前にデータの中心化とスケーリングを行うラッパーの作成方法を示そう。k最近傍法やサポートベクターマシン、ニューラルネットワークなどは通常スケーリングされた特徴量を必要とする。多くの組み込みスケーリング手法は、データセットを事前にスケーリングし、テストデータセットもそれに従ってスケーリングされる。以下では、学習器にスケーリングオプションを追加し、scale関数と組み合わせる方法を示す。 今回この単純な例を選んだのはあくまで説明のためだ。中心化とスケーリングはmakePreprocWrapperCaretでも可能だということに注意してほしい。 6.4.1 訓練関数の指定 訓練(ステップで使う)関数は以下の引数を持つ関数でなければならない。 data: 全ての特徴量と目的変数を列として含むデータフレーム。 target: dataに含まれる目的変数の名前。 args: 前処理に関わるその他の引数とパラメータのリスト。 この関数は$dataと$controlを要素として持つリストを返す必要がある。$dataは前処理されたデータセットを、$controlには予測のために必要な全ての情報を格納する。 スケーリングのための訓練関数の定義例を以下に示す。これは数値型の特徴量に対してscale関数を呼び出し、スケーリングされたデータと関連するスケーリングパラメータを返す。 argsはscale関数の引数であるcenterとscale引数を含み、予測で使用するためにこれを$controlスロットに保持する。これらの引数は、論理値または数値型の列の数に等しい長さの数値型ベクトルで指定する必要がある。center引数は数値を渡された場合にはその値を各データから引くが、TRUEが指定された場合には平均値を引く。scale引数は数値を渡されるとその値で各データを割るが、TRUEの場合は標準偏差か二乗平均平方根を引く(いずれになるかはcenter引数に依存する)。2つの引数のいずれかor両方にTRUEが指定された場合には、この値を予測の段階で使用するためには返り値の$controlスロットに保持しておく必要があるという点に注意しよう。 trainfun = function(data, target, args = list(center, scale)){ ## 数値特徴量を特定する cns = colnames(data) nums = setdiff(cns[sapply(data, is.numeric)], target) ## 数値特徴量を抽出し、scale関数を呼び出す x = as.matrix(data[, nums, drop = FALSE]) x = scale(x, center = args$center, scale = args$scale) ## スケーリングパラメータを後で予測に使うためにcontrolに保持する control = args if(is.logical(control$center) &amp;&amp; control$center){ control$center = attr(x, &quot;scaled:center&quot;) } if(is.logical(control$scale) &amp;&amp; control$scale){ control$scale = attr(x, &quot;scaled:scale&quot;) } ## 結果をdataにまとめる data = data[, setdiff(cns, nums), drop = FALSE] data = cbind(data, as.data.frame(x)) return(list(data = data, control = control)) } 6.4.2 予測関数の指定 予測(ステップで使う)関数は以下の引数を持つ必要がある。 data: 特徴量のみをもつデータフレーム。(予測ステップでは目的変数の値は未知なのが普通だ。) target: 目的変数の名前。 args: 訓練関数に渡されたargs。 control: 訓練関数が返したもの。 この関数は前処理済みのデータを返す。 今回の例では、予測関数は数値特徴量を訓練ステージでcontrolに保持されたパラメータを使ってスケーリングする。 predictfun = function(data, target, args, control){ ## 数値特徴量の特定 cns = colnames(data) nums = cns[sapply(data, is.numeric)] ## データから数値特徴量を抽出してscale関数を適用する x = as.matrix(data[, nums, drop = FALSE]) x = scale(x, center = control$center, scale = control$scale) ## dataにまとめて返す data = data[, setdiff(cns, nums), drop = FALSE] data = cbind(data, as.data.frame(x)) return(data) } 6.4.3 前処理ラッパーの作成 以下では、ニューラルネットワークによる回帰(これは自前のスケーリングオプションを持たない)をベースの学習器として前処理ラッパーを作成する。 先に定義した訓練および予測関数をmakePreprocWrapper関数のtrainとpredict引数に渡す。par.valsには、訓練関数のargsに渡すパラメータをリストとして渡す。 lrn = makeLearner(&quot;regr.nnet&quot;, trace = FALSE, decay = 1e-02) lrn = makePreprocWrapper(lrn, train = trainfun, predict = predictfun, par.vals = list(center = TRUE, scale = TRUE)) データセットBostonHousingを対象にして、スケーリングの有無による平均二乗誤差の違いを確認してみよう。 rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3) ## スケーリングあり(上で前処理を指定した) r = resample(lrn, bh.task, resampling = rdesc, show.info = FALSE) r $&gt; Resample Result $&gt; Task: BostonHousing-example $&gt; Learner: regr.nnet.preproc $&gt; Aggr perf: mse.test.mean=29.1 $&gt; Runtime: 0.145464 ## 前処理無しの学習器を再度作る lrn = makeLearner(&quot;regr.nnet&quot;, trace = FALSE, decay = 1e-02) r = resample(lrn, bh.task, resampling = rdesc, show.info = FALSE) r $&gt; Resample Result $&gt; Task: BostonHousing-example $&gt; Learner: regr.nnet $&gt; Aggr perf: mse.test.mean=32.8 $&gt; Runtime: 0.104282 6.4.4 前処理と学習器のパラメータを連結してチューニングする 前処理のオプションをどのように設定すれば特定のアルゴリズムに対して上手くいくのかということは、明確には分からないことが多い。makePreprocWrapperCaretの例で、既に前処理と学習器のパラメータを両方ともチューニングする方法を既に見た。 スケーリングの例では、ニューラルネットに対してスケーリングと中心化の両方を行うのが良いのか、いずれか片方なのか、あるいは行わないほうが良いのかという点を確認することができる。centerとscaleをチューニングするためには、適切な種類のLearnerParamをパラメータセットに追加する必要がある。 前述のように、centerとscaleには数値型か論理値型のいずれかを指定できるが、今回は論理値型のパラメータとしてチューニングしよう。 lrn = makeLearner(&quot;regr.nnet&quot;, trace = FALSE) lrn = makePreprocWrapper(lrn, train = trainfun, predict = predictfun, par.set = makeParamSet( makeLogicalLearnerParam(&quot;center&quot;), makeLogicalLearnerParam(&quot;scale&quot;) ), par.vals = list(center = TRUE, scale = TRUE)) lrn $&gt; Learner regr.nnet.preproc from package nnet $&gt; Type: regr $&gt; Name: ; Short name: $&gt; Class: PreprocWrapper $&gt; Properties: numerics,factors,weights $&gt; Predict-Type: response $&gt; Hyperparameters: size=3,trace=FALSE,center=TRUE,scale=TRUE 今回はグリッドサーチでnnetのdecayパラメータとscaleのcenterとscaleパラメータをチューニングする。 rdesc = makeResampleDesc(&quot;Holdout&quot;) ps = makeParamSet( makeDiscreteLearnerParam(&quot;decay&quot;, c(0, 0.05, 0.1)), makeLogicalLearnerParam(&quot;center&quot;), makeLogicalLearnerParam(&quot;scale&quot;) ) crrl = makeTuneControlGrid() res = tuneParams(lrn, bh.task, rdesc, par.set = ps, control = ctrl, show.info = FALSE) res $&gt; Tune result: $&gt; Op. pars: decay=0; center=TRUE; scale=TRUE $&gt; mse.test.mean=10.4 as.data.frame(res$opt.path) $&gt; decay center scale mse.test.mean dob eol error.message exec.time $&gt; 1 0 TRUE TRUE 10.35758 1 NA &lt;NA&gt; 0.051 $&gt; 2 0.05 TRUE TRUE 24.16396 2 NA &lt;NA&gt; 0.046 $&gt; 3 0.1 TRUE TRUE 13.87898 3 NA &lt;NA&gt; 0.053 $&gt; 4 0 FALSE TRUE 67.40683 4 NA &lt;NA&gt; 0.026 $&gt; 5 0.05 FALSE TRUE 12.67467 5 NA &lt;NA&gt; 0.044 $&gt; 6 0.1 FALSE TRUE 13.55953 6 NA &lt;NA&gt; 0.043 $&gt; 7 0 TRUE FALSE 54.70995 7 NA &lt;NA&gt; 0.031 $&gt; 8 0.05 TRUE FALSE 40.64841 8 NA &lt;NA&gt; 0.047 $&gt; 9 0.1 TRUE FALSE 50.72933 9 NA &lt;NA&gt; 0.045 $&gt; 10 0 FALSE FALSE 67.40683 10 NA &lt;NA&gt; 0.022 $&gt; 11 0.05 FALSE FALSE 49.67953 11 NA &lt;NA&gt; 0.040 $&gt; 12 0.1 FALSE FALSE 29.85388 12 NA &lt;NA&gt; 0.046 6.4.5 前処理ラッパー関数 よい前処理ラッパーを作成したのであれば、それを関数としてカプセル化するのは良いアイデアだ。他の人も使えると便利だろうからmlrに追加して欲しい、というのであればIssues · mlr-org/mlrからコンタクトして欲しい。 makePreprocWrapperScale = function(learner, center = TRUE, scale = TRUE) { trainfun = function(data, target, args = list(center, scale)) { cns = colnames(data) nums = setdiff(cns[sapply(data, is.numeric)], target) x = as.matrix(data[, nums, drop = FALSE]) x = scale(x, center = args$center, scale = args$scale) control = args if (is.logical(control$center) &amp;&amp; control$center) control$center = attr(x, &quot;scaled:center&quot;) if (is.logical(control$scale) &amp;&amp; control$scale) control$scale = attr(x, &quot;scaled:scale&quot;) data = data[, setdiff(cns, nums), drop = FALSE] data = cbind(data, as.data.frame(x)) return(list(data = data, control = control)) } predictfun = function(data, target, args, control) { cns = colnames(data) nums = cns[sapply(data, is.numeric)] x = as.matrix(data[, nums, drop = FALSE]) x = scale(x, center = control$center, scale = control$scale) data = data[, setdiff(cns, nums), drop = FALSE] data = cbind(data, as.data.frame(x)) return(data) } makePreprocWrapper( learner, train = trainfun, predict = predictfun, par.set = makeParamSet( makeLogicalLearnerParam(&quot;center&quot;), makeLogicalLearnerParam(&quot;scale&quot;) ), par.vals = list(center = center, scale = scale) ) } lrn = makePreprocWrapperScale(&quot;classif.lda&quot;) train(lrn, iris.task) $&gt; Model for learner.id=classif.lda.preproc; learner.class=PreprocWrapper $&gt; Trained on: task.id = iris-example; obs = 150; features = 4 $&gt; Hyperparameters: center=TRUE,scale=TRUE "],
["section-7.html", "Section 7 学習器の性能を評価する 7.1 利用可能な性能指標 7.2 指標の一覧 7.3 性能指標を計算する 7.4 指標計算に必要な情報 7.5 性能指標へのアクセス 7.6 2クラス分類", " Section 7 学習器の性能を評価する mlrには学習機の予測性能について様々な側面から評価する方法が備えられている。性能指標を計算するためには、predictの返すオブジェクトと目的の性能指標を指定してperformance関数を呼び出す。 7.1 利用可能な性能指標 mlrはすべての種類の学習問題に対して多数の性能指標を提供している。分類問題に対する典型的な性能指標としては、平均誤分類率(mmce)、精度(acc)、ROC曲線などが使える。回帰問題に対しては、平均二乗偏差(mse)、平均絶対誤差(mae)などが一般に使用される。他にもクラスタリング問題では、Dunn Index(dunn)が、生存時間分析に対してはConcordance Index(cindex)が、コスト考慮型予測問題ではMisclassification Penalty(mcp)など、様々な指標が利用可能である。また、訓練にかかった時間(timetrain)、予測にかかった時間(timepredict)、その合計(timeboth)も性能指標の一つとしてアクセスできる。 どのような指標が実装されているかについては、Implemented Performance Measures - mlr tutorialおよびmeasures function | R Documentationを確認してもらいたい。 もし新たな指標を実装したり、標準的でない誤分類コストを指標に含めたいと思うのであれば、Create Custom Measures - mlr tutorialを見てもらいたい。 7.2 指標の一覧 各指標の詳細については上述のImplemented Performance Measuresを確認してもらうとして、特定のプロパティを持つ指標や、特定のタスクに利用可能な指標を確認したければlistMeasures関数を使うと良い。 ## 多クラス問題に対する分類指標 listMeasures(&quot;classif&quot;, properties = &quot;classif.multi&quot;) $&gt; [1] &quot;kappa&quot; &quot;multiclass.brier&quot; &quot;multiclass.aunp&quot; $&gt; [4] &quot;multiclass.aunu&quot; &quot;qsr&quot; &quot;ber&quot; $&gt; [7] &quot;logloss&quot; &quot;wkappa&quot; &quot;timeboth&quot; $&gt; [10] &quot;timepredict&quot; &quot;acc&quot; &quot;lsr&quot; $&gt; [13] &quot;featperc&quot; &quot;multiclass.au1p&quot; &quot;multiclass.au1u&quot; $&gt; [16] &quot;ssr&quot; &quot;timetrain&quot; &quot;mmce&quot; ## iris.taskに対する分類指標 listMeasures(iris.task) $&gt; [1] &quot;kappa&quot; &quot;multiclass.brier&quot; &quot;multiclass.aunp&quot; $&gt; [4] &quot;multiclass.aunu&quot; &quot;qsr&quot; &quot;ber&quot; $&gt; [7] &quot;logloss&quot; &quot;wkappa&quot; &quot;timeboth&quot; $&gt; [10] &quot;timepredict&quot; &quot;acc&quot; &quot;lsr&quot; $&gt; [13] &quot;featperc&quot; &quot;multiclass.au1p&quot; &quot;multiclass.au1u&quot; $&gt; [16] &quot;ssr&quot; &quot;timetrain&quot; &quot;mmce&quot; 簡便のため、それぞれの学習問題に対しては、よく使われる指標がデフォルトとして指定してある。例えば回帰では平均二乗偏差が、分類では平均誤分類率がデフォルトだ。何がデフォルトであるかはgetDefaultMeasure関数を使うと確認できる。また、この関数のヘルプでデフォルトに使用される指標の一覧が確認できる。 ## iris.taskのデフォルト指標 getDefaultMeasure(iris.task) $&gt; Name: Mean misclassification error $&gt; Performance measure: mmce $&gt; Properties: classif,classif.multi,req.pred,req.truth $&gt; Minimize: TRUE $&gt; Best: 0; Worst: 1 $&gt; Aggregated by: test.mean $&gt; Note: Defined as: mean(response != truth) ## 回帰のデフォルト指標 getDefaultMeasure(makeLearner(&quot;regr.lm&quot;)) $&gt; Name: Mean of squared errors $&gt; Performance measure: mse $&gt; Properties: regr,req.pred,req.truth $&gt; Minimize: TRUE $&gt; Best: 0; Worst: Inf $&gt; Aggregated by: test.mean $&gt; Note: Defined as: mean((response - truth)^2) 7.3 性能指標を計算する 例として、勾配ブースティングマシンをBostonHousingデータの一部に適用し、残りのデータから標準の性能指標である平均二乗偏差を計算してみよう。 n = getTaskSize(bh.task) lrn = makeLearner(&quot;regr.gbm&quot;, n.trees = 1000) mod = train(lrn, task = bh.task, subset = seq(1, n, 2)) pred = predict(mod, task = bh.task, subset = seq(2, n, 2)) performance(pred) $&gt; mse $&gt; 42.79453 他の指標の例として中央値二乗誤差(medse)を求めてみよう。 performance(pred, measures = medse) $&gt; medse $&gt; 9.101212 もちろん、独自に作成した指標も含めて、複数の指標を一度に計算することもできる。その場合、求めたい指標をリストにして渡す。 performance(pred, measures = list(mse, medse, mae)) $&gt; mse medse mae $&gt; 42.794531 9.101212 4.556043 上記の方法は、学習問題や性能指標の種類が異なっても基本的には同じである。 7.4 指標計算に必要な情報 一部の性能指標では、計算のために予測結果だけでなく、タスクやフィット済みモデルも必要とする。 一例は訓練にかかった時間(timetrain)だ。 performance(pred, measures = timetrain, model = mod) $&gt; timetrain $&gt; 0.34 クラスター分析に関わる多くの性能指標はタスクを必要とする。 lrn = makeLearner(&quot;cluster.kmeans&quot;, centers = 3) mod = train(lrn, mtcars.task) pred = predict(mod, task = mtcars.task) performance(pred, measures = dunn, task = mtcars.task) $&gt; dunn $&gt; 0.1178415 また、いくつかの指標は特定の種類の予測を必要とする。例えば2クラス分類におけるAUC(これはROC[receiver operating characteristic]曲線の下側の面積[Area Under Curve]である)を計算するためには、事後確率が必要である。ROC分析に関する詳細が必要であればROC Analysis - mlr tutorialを確認してほしい。 lrn = makeLearner(&quot;classif.rpart&quot;, predict.type = &quot;prob&quot;) mod = train(lrn, task = sonar.task) pred = predict(mod, task = sonar.task) performance(pred, measures = auc) $&gt; auc $&gt; 0.9224018 また、分類問題に利用可能な性能指標(偽陽性率fprなど)の多くは、2クラス分類のみに利用可能であるという点に注意してもらいたい。 7.5 性能指標へのアクセス mlrにおける性能指標はMeasureクラスのオブジェクトである。オブジェクトを通じて指標のプロパティ等には直接アクセスすることができる。各スロットに関する説明はmakeMeasure function | R Documentationを確認してもらいたい。 str(mmce) $&gt; List of 10 $&gt; $ id : chr &quot;mmce&quot; $&gt; $ minimize : logi TRUE $&gt; $ properties: chr [1:4] &quot;classif&quot; &quot;classif.multi&quot; &quot;req.pred&quot; &quot;req.truth&quot; $&gt; $ fun :function (task, model, pred, feats, extra.args) $&gt; $ extra.args: list() $&gt; $ best : num 0 $&gt; $ worst : num 1 $&gt; $ name : chr &quot;Mean misclassification error&quot; $&gt; $ note : chr &quot;Defined as: mean(response != truth)&quot; $&gt; $ aggr :List of 4 $&gt; ..$ id : chr &quot;test.mean&quot; $&gt; ..$ name : chr &quot;Test mean&quot; $&gt; ..$ fun :function (task, perf.test, perf.train, measure, group, pred) $&gt; ..$ properties: chr &quot;req.test&quot; $&gt; ..- attr(*, &quot;class&quot;)= chr &quot;Aggregation&quot; $&gt; - attr(*, &quot;class&quot;)= chr &quot;Measure&quot; 7.6 2クラス分類 7.6.1 性能と閾値の関係をプロットする 2クラス分類問題においては、予測された確率からクラスラベルへの割り当てを行う際の確率の閾値を設定できるということを思い出してもらいたい。generateThreshVsPrefDataとplotThreshVsPrefは、学習器のパフォーマンスと閾値の関係をプロットできる便利な関数だ。 パフォーマンスのプロットと閾値の自動チューニングに関して詳しい情報はROC Analysis - mlr tutorialを確認してほしい。 以下の例では、Sonarデータセットを用い、偽陽性率(fpr)、偽陰性率(fnr)、平均誤分類率(mmce)を設定可能な範囲の閾値に対してプロットしている。 lrn = makeLearner(&quot;classif.lda&quot;, predict.type = &quot;prob&quot;) n = getTaskSize(sonar.task) mod = train(lrn, task = sonar.task, subset = seq(1, n, by = 2)) pred = predict(mod, task = sonar.task, subset = seq(2, n, by = 2)) d = generateThreshVsPerfData(pred, measures = list(fpr, fnr, mmce)) plotThreshVsPerf(d) ggvisを利用したplotThreshVsPerfGGVIS関数は、Shinyを使ったインタラクティブなグラフを生成する。 plotThreshVsPerfGGVIS(d) 7.6.2 ROC 2クラス分類においては、多数の分類指標が存在するが、これは1つの表としてまとめることができる。例えばROCに関するWikipediaのページReceiver operating characteristic - Wikipediaを見てもらいたい(訳注:日本語版の受信者操作特性のページには無い)。 これと同じようなものをcalculateROCMeasures関数を用いると作成できる。 calculateROCMeasures(pred) $&gt; predicted $&gt; true M R $&gt; M 0.7 0.3 tpr: 0.7 fnr: 0.3 $&gt; R 0.25 0.75 fpr: 0.25 tnr: 0.75 $&gt; ppv: 0.76 for: 0.32 lrp: 2.79 acc: 0.72 $&gt; fdr: 0.24 npv: 0.68 lrm: 0.4 dor: 6.88 $&gt; $&gt; $&gt; Abbreviations: $&gt; tpr - True positive rate (Sensitivity, Recall) $&gt; fpr - False positive rate (Fall-out) $&gt; fnr - False negative rate (Miss rate) $&gt; tnr - True negative rate (Specificity) $&gt; ppv - Positive predictive value (Precision) $&gt; for - False omission rate $&gt; lrp - Positive likelihood ratio (LR+) $&gt; fdr - False discovery rate $&gt; npv - Negative predictive value $&gt; acc - Accuracy $&gt; lrm - Negative likelihood ratio (LR-) $&gt; dor - Diagnostic odds ratio 左上の2x2行列は混同行列であり、正しく分類された観測値と誤分類された観測値の相対頻度を示している。また、その右側と下側には、混同行列から計算可能な多数の性能指標が示されている。また、デフォルトでは各項目に対する説明が追記されるが、これはprintにabbreviations = FALSEを指定することで消すことも出来る。 print(calculateROCMeasures(pred), abbreviations = FALSE) $&gt; predicted $&gt; true M R $&gt; M 0.7 0.3 tpr: 0.7 fnr: 0.3 $&gt; R 0.25 0.75 fpr: 0.25 tnr: 0.75 $&gt; ppv: 0.76 for: 0.32 lrp: 2.79 acc: 0.72 $&gt; fdr: 0.24 npv: 0.68 lrm: 0.4 dor: 6.88 "],
["section-8.html", "Section 8 リサンプリング 8.1 リサンプリング手法を決める 8.2 リサンプリングを実行する 8.3 リサンプル結果へのアクセス 8.4 階層化とブロック化 8.5 リサンプリングの詳細とリサンプルのインスタンス 8.6 性能指標の集約 8.7 便利な関数", " Section 8 リサンプリング 一般的に学習機の性能評価はリサンプリングを通じて行われる。リサンプリングの概要は次のようなものである。まず、データセット全体を\\(D\\)として、これを訓練セット\\(D^{*b}\\)とテストセット\\(D\\setminus D^{*b}\\)に分割する。この種の分割を\\(B\\)回行う(つまり、\\(b = 1,...,B\\)とする)。そして、それぞれのテストセット、訓練セットの対を用いて訓練と予測を行い、性能指標\\(S(D^{*b}, D\\setminus D^{*b}\\))を計算する。これにより\\(B\\)個の性能指標が得られるが、これを集約する(一般的には平均値が用いられる)。リサンプリングの方法には、クロスバリデーションやブートストラップなど様々な手法が存在する。 もしさらに詳しく知りたいのであれば、Simonによる論文(Resampling Strategies for Model Assessment and Selection | SpringerLink)を読むのは悪い選択ではないだろう。また、Berndらによる論文、Resampling methods for meta-model validation with recommendations for evolutionary computationでは、リサンプリング手法の統計的な背景に対して多くの説明がなされている。 8.1 リサンプリング手法を決める mlrではmakeResampleDesc関数を使ってリサンプリング手法を設定する。この関数にはリサンプリング手法の名前とともに、手法に応じてその他の情報(例えば繰り返し数など)を指定する。サポートしているサンプリング手法は以下のとおりである。 CV: クロスバリデーション(Cross-varidation) LOO: 一つ抜き法(Leave-one-out cross-varidation) RepCV: Repeatedクロスバリデーション(Repeated cross-varidation) Bootstrap: out-of-bagブートストラップとそのバリエーション(b632等) Subsample: サブサンプリング(モンテカルロクロスバリデーションとも呼ばれる) Holdout: ホールドアウト法 3-fold(3分割)クロスバリデーションの場合は rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3) rdesc $&gt; Resample description: cross-validation with 3 iterations. $&gt; Predict: test $&gt; Stratification: FALSE ホールドアウト法の場合は rdesc = makeResampleDesc(&quot;Holdout&quot;) rdesc $&gt; Resample description: holdout with 0.67 split rate. $&gt; Predict: test $&gt; Stratification: FALSE という具合だ。 これらのリサンプルdescriptionのうち、よく使うものは予め別名が用意してある。例えばホールドアウト法はhout、クロスバリデーションはcv5やcv10などよく使う分割数に対して定義してある。 hout $&gt; Resample description: holdout with 0.67 split rate. $&gt; Predict: test $&gt; Stratification: FALSE cv3 $&gt; Resample description: cross-validation with 3 iterations. $&gt; Predict: test $&gt; Stratification: FALSE 8.2 リサンプリングを実行する resample関数は指定されたリサンプリング手法により、学習機をタスク上で評価する。 最初の例として、BostonHousingデータに対する線形回帰を3分割クロスバリデーションで評価してみよう。 \\(K\\)分割クロスバリデーションはデータセット\\(D\\)を\\(K\\)個の(ほぼ)等しいサイズのサブセットに分割する。\\(K\\)回の繰り返しの\\(b\\)番目では、\\(b\\)番目のサブセットがテストに、残りが訓練に使用される。 resample関数に学習器を指定する際には、Learnerクラスのオブジェクトか学習器の名前(regr.lmなど)のいずれを渡しても良い。性能指標は指定しなければ学習器に応じたデフォルトが使用される(回帰の場合は平均二乗誤差)。 rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3) r = resample(&quot;regr.lm&quot;, bh.task, rdesc) $&gt; [Resample] cross-validation iter 1: mse.test.mean=20.7 $&gt; [Resample] cross-validation iter 2: mse.test.mean= 25 $&gt; [Resample] cross-validation iter 3: mse.test.mean=25.3 $&gt; [Resample] Aggr. Result: mse.test.mean=23.7 r $&gt; Resample Result $&gt; Task: BostonHousing-example $&gt; Learner: regr.lm $&gt; Aggr perf: mse.test.mean=23.7 $&gt; Runtime: 0.0350449 ここでrに格納したオブジェクトはResampleResultクラスである。この中には評価結果の他に、実行時間や予測値、リサンプリング毎のフィット済みモデルなどが格納されている。 ## 中身をざっと確認 names(r) $&gt; [1] &quot;learner.id&quot; &quot;task.id&quot; &quot;task.desc&quot; &quot;measures.train&quot; $&gt; [5] &quot;measures.test&quot; &quot;aggr&quot; &quot;pred&quot; &quot;models&quot; $&gt; [9] &quot;err.msgs&quot; &quot;err.dumps&quot; &quot;extract&quot; &quot;runtime&quot; r$measures.testには各テストセットの性能指標が入っている。 ## 各テストセットの性能指標 r$measures.test $&gt; iter mse $&gt; 1 1 20.74068 $&gt; 2 2 25.00755 $&gt; 3 3 25.25456 r$aggrには集約(aggrigate)後の性能指標が入っている。 ## 集約後の性能指標 r$aggr $&gt; mse.test.mean $&gt; 23.6676 名前mse.test.meanは、性能指標がmseであり、test.meanによりデータが集約されていることを表している。test.meanは多くの性能指標においてデフォルトの集約方法であり、その名前が示すようにテストデータの性能指標の平均値である。 mlrではどのような種類の学習器も同じようにリサンプリングを行える。以下では、分類問題の例としてSonarデータセットに対する分類木を5反復のサブサンプリングで評価してみよう。 サブサンプリングの各繰り返しでは、データセット\\(D\\)はランダムに訓練データとテストデータに分割される。このとき、テストデータには指定の割合のデータ数が割り当てられる。この反復が1の場合はホールドアウト法と同じである。 評価したい性能指標はリストとしてまとめて指定することもできる。以下の例では平均誤分類、偽陽性・偽陰性率、訓練時間を指定している。 rdesc = makeResampleDesc(&quot;Subsample&quot;, iter = 5, split = 4/5) lrn = makeLearner(&quot;classif.rpart&quot;, parms = list(split = &quot;information&quot;)) r = resample(lrn, sonar.task, rdesc, measures = list(mmce, fpr, fnr, timetrain)) $&gt; [Resample] subsampling iter 1: mmce.test.mean=0.19,fpr.test.mean=0.263,fnr.test.mean=0.13,timetrain.test.mean=0.017 $&gt; [Resample] subsampling iter 2: mmce.test.mean=0.286,fpr.test.mean= 0.2,fnr.test.mean=0.333,timetrain.test.mean=0.014 $&gt; [Resample] subsampling iter 3: mmce.test.mean=0.167,fpr.test.mean=0.263,fnr.test.mean=0.087,timetrain.test.mean=0.016 $&gt; [Resample] subsampling iter 4: mmce.test.mean=0.286,fpr.test.mean= 0.4,fnr.test.mean=0.182,timetrain.test.mean=0.016 $&gt; [Resample] subsampling iter 5: mmce.test.mean=0.238,fpr.test.mean=0.278,fnr.test.mean=0.208,timetrain.test.mean=0.025 $&gt; [Resample] Aggr. Result: mmce.test.mean=0.233,fpr.test.mean=0.281,fnr.test.mean=0.188,timetrain.test.mean=0.0176 r $&gt; Resample Result $&gt; Task: Sonar-example $&gt; Learner: classif.rpart $&gt; Aggr perf: mmce.test.mean=0.233,fpr.test.mean=0.281,fnr.test.mean=0.188,timetrain.test.mean=0.0176 $&gt; Runtime: 0.152282 もし指標を後から追加したくなったら、addRRMeasure関数を使うと良い。 addRRMeasure(r, list(ber, timepredict)) $&gt; Resample Result $&gt; Task: Sonar-example $&gt; Learner: classif.rpart $&gt; Aggr perf: mmce.test.mean=0.233,fpr.test.mean=0.281,fnr.test.mean=0.188,timetrain.test.mean=0.0176,ber.test.mean=0.234,timepredict.test.mean=0.0048 $&gt; Runtime: 0.152282 デフォルトではresample関数は進捗と途中結果を表示するが、show.info=FALSEで非表示にもできる。このようなメッセージを完全に制御したかったら、Configuration - mlr tutorialを確認してもらいたい。 上記例では学習器を明示的に作成してからresampleに渡したが、代わりに学習器の名前を指定しても良い。その場合、学習器のパラメータは...引数を通じて渡すことができる。 resample(&quot;classif.rpart&quot;, parms = list(split = &quot;information&quot;), sonar.task, rdesc, measures = list(mmce, fpr, fnr, timetrain), show.info = FALSE) $&gt; Resample Result $&gt; Task: Sonar-example $&gt; Learner: classif.rpart $&gt; Aggr perf: mmce.test.mean=0.262,fpr.test.mean=0.256,fnr.test.mean=0.273,timetrain.test.mean=0.0152 $&gt; Runtime: 0.138157 8.3 リサンプル結果へのアクセス 学習器の性能以外にも、リサンプル結果から様々な情報を得ることが出来る。例えばリサンプリングの各繰り返しに対応する予測値やフィット済みモデル等だ。以下で情報の取得の仕方をみていこう。 8.3.1 予測値 デフォルトでは、ResampleResultはリサンプリングで得た予測値を含んでいる。メモリ節約などの目的でこれを止めさせたければ、resample関数にkeep.pred = FALSEを指定する。 予測値は$predスロットに格納されている。また、getRRPredictions関数を使ってアクセスすることもできる。 r$pred $&gt; Resampled Prediction for: $&gt; Resample description: subsampling with 5 iterations and 0.80 split rate. $&gt; Predict: test $&gt; Stratification: FALSE $&gt; predict.type: response $&gt; threshold: $&gt; time (mean): 0.00 $&gt; id truth response iter set $&gt; 1 194 M M 1 test $&gt; 2 59 R R 1 test $&gt; 3 113 M R 1 test $&gt; 4 191 M M 1 test $&gt; 5 32 R M 1 test $&gt; 6 170 M M 1 test $&gt; ... (210 rows, 5 cols) pred = getRRPredictions(r) pred $&gt; Resampled Prediction for: $&gt; Resample description: subsampling with 5 iterations and 0.80 split rate. $&gt; Predict: test $&gt; Stratification: FALSE $&gt; predict.type: response $&gt; threshold: $&gt; time (mean): 0.00 $&gt; id truth response iter set $&gt; 1 194 M M 1 test $&gt; 2 59 R R 1 test $&gt; 3 113 M R 1 test $&gt; 4 191 M M 1 test $&gt; 5 32 R M 1 test $&gt; 6 170 M M 1 test $&gt; ... (210 rows, 5 cols) ここで作成したpredはResamplePredictionクラスのオブジェクトである。これはPredictionオブジェクトのように$dataにデータフレームとして予測値と真値(教師あり学習の場合)が格納されている。as.data.frameを使って直接$dataスロットの中身を取得できる。さらに、Predictionオブジェクトに対するゲッター関数は全て利用可能である。 head(as.data.frame(pred)) $&gt; id truth response iter set $&gt; 1 194 M M 1 test $&gt; 2 59 R R 1 test $&gt; 3 113 M R 1 test $&gt; 4 191 M M 1 test $&gt; 5 32 R M 1 test $&gt; 6 170 M M 1 test head(getPredictionTruth(pred)) $&gt; [1] M R M M R M $&gt; Levels: M R データフレームのiterとsetは繰り返し回数とデータセットの種類(訓練なのかテストなのか)を示している。 デフォルトでは予測はテストセットだけに行われるが、makeResampleDescに対し、predict = &quot;train&quot;を指定で訓練セットだけに、predict = &quot;both&quot;を指定で訓練セットとテストセットの両方に予測を行うことが出来る。後で例を見るが、b632やb632+のようなブートストラップ手法ではこれらの設定が必要となる。 以下では単純なホールドアウト法の例を見よう。つまり、テストセットと訓練セットへの分割は一度だけ行い、予測は両方のデータセットを用いて行う。 rdesc = makeResampleDesc(&quot;Holdout&quot;, predict = &quot;both&quot;) r = resample(&quot;classif.lda&quot;, iris.task, rdesc, show.info = FALSE) r $&gt; Resample Result $&gt; Task: iris-example $&gt; Learner: classif.lda $&gt; Aggr perf: mmce.test.mean=0.02 $&gt; Runtime: 0.016861 r$aggr $&gt; mmce.test.mean $&gt; 0.02 (predict=&quot;both&quot;の指定にかかわらず、r$aggrではテストデータに対するmmceしか計算しないことに注意してもらいたい。訓練セットに対して計算する方法はこの後で説明する。) リサンプリング結果から予測を取り出す方法として、getRRPredictionListを使う方法もある。これは、分割されたデータセット(訓練/テスト)それぞれと、リサンプリングの繰り返し毎に分割した単位でまとめた予測結果のリストを返す。 getRRPredictionList(r) $&gt; $train $&gt; $train$`1` $&gt; Prediction: 100 observations $&gt; predict.type: response $&gt; threshold: $&gt; time: 0.00 $&gt; id truth response $&gt; 2 2 setosa setosa $&gt; 118 118 virginica virginica $&gt; 65 65 versicolor versicolor $&gt; 42 42 setosa setosa $&gt; 124 124 virginica virginica $&gt; 34 34 setosa setosa $&gt; ... (100 rows, 3 cols) $&gt; $&gt; $&gt; $&gt; $test $&gt; $test$`1` $&gt; Prediction: 50 observations $&gt; predict.type: response $&gt; threshold: $&gt; time: 0.00 $&gt; id truth response $&gt; 91 91 versicolor versicolor $&gt; 78 78 versicolor versicolor $&gt; 7 7 setosa setosa $&gt; 146 146 virginica virginica $&gt; 139 139 virginica virginica $&gt; 9 9 setosa setosa $&gt; ... (50 rows, 3 cols) 8.3.2 訓練済みモデルの抽出 リサンプリング毎に学習器は訓練セットにフィットさせられる。標準では、WrappedModelはResampleResultオブジェクトには含まれておらず、$modelsスロットは空だ。これを保持するためには、resample関数を呼び出す際に引数models = TRUEを指定する必要がある。以下に生存時間分析の例を見よう。 ## 3分割クロスバリデーション rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3) r = resample(&quot;surv.coxph&quot;, lung.task, rdesc, show.info = FALSE, models = TRUE) r$models $&gt; [[1]] $&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph $&gt; Trained on: task.id = lung-example; obs = 111; features = 8 $&gt; Hyperparameters: $&gt; $&gt; [[2]] $&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph $&gt; Trained on: task.id = lung-example; obs = 111; features = 8 $&gt; Hyperparameters: $&gt; $&gt; [[3]] $&gt; Model for learner.id=surv.coxph; learner.class=surv.coxph $&gt; Trained on: task.id = lung-example; obs = 112; features = 8 $&gt; Hyperparameters: 8.3.3 他の抽出方法 完全なフィット済みモデルを保持しようとすると、リサンプリングの繰り返し数が多かったりオブジェクトが大きかったりする場合にメモリの消費量が大きくなってしまう。モデルの全ての情報を保持する代わりに、resample関数のextract引数に指定することで必要な情報だけを保持することができる。引数extractに対しては、リサンプリング毎の各WrapedModelオブジェクトに適用するための関数を渡す必要がある。 以下では、mtcarsデータセットをk=3のk-meansでクラスタリングし、クラスター中心だけを保持する例を紹介する。 rdesc = makeResampleDesc(&quot;CV&quot;, iter = 3) r = resample(&quot;cluster.kmeans&quot;, mtcars.task, rdesc, show.info = FALSE, centers = 3, extract = function(x){getLearnerModel(x)$centers}) r$extract $&gt; [[1]] $&gt; mpg cyl disp hp drat wt qsec vs $&gt; 1 24.33333 4.666667 119.9111 105.4444 3.972222 2.388667 17.98556 0.6666667 $&gt; 2 17.31667 7.333333 271.4000 150.8333 2.968333 3.629167 18.25500 0.3333333 $&gt; 3 14.53333 8.000000 386.8333 229.0000 3.423333 4.131500 16.33500 0.0000000 $&gt; am gear carb $&gt; 1 0.7777778 4.222222 2.555556 $&gt; 2 0.0000000 3.000000 2.166667 $&gt; 3 0.1666667 3.333333 3.666667 $&gt; $&gt; [[2]] $&gt; mpg cyl disp hp drat wt qsec vs $&gt; 1 24.69167 4.666667 121.1333 93.83333 4.018333 2.560833 18.68167 0.75 $&gt; 2 14.76667 8.000000 437.3333 203.33333 3.080000 4.813333 17.48333 0.00 $&gt; 3 15.35714 8.000000 328.8286 227.71429 3.438571 3.543571 16.09571 0.00 $&gt; am gear carb $&gt; 1 0.7500000 4.083333 2.500000 $&gt; 2 0.0000000 3.000000 3.333333 $&gt; 3 0.2857143 3.571429 3.857143 $&gt; $&gt; [[3]] $&gt; mpg cyl disp hp drat wt qsec vs am gear $&gt; 1 19.5000 6 195.640 114.200 3.51600 3.286000 18.77600 0.800 0.200 3.600 $&gt; 2 14.9250 8 350.825 198.750 3.07500 4.105500 17.07750 0.000 0.125 3.250 $&gt; 3 26.3375 4 110.675 83.625 4.04625 2.324125 19.13875 0.875 0.625 4.125 $&gt; carb $&gt; 1 2.800 $&gt; 2 3.500 $&gt; 3 1.625 他の例として、フィット済みの回帰木から変数の重要度をgetFeatureImportanceを使って抽出してみよう(より詳しい内容はFeature Selection - mlr tutorialを確認してもらいたい)。 r = resample(&quot;regr.rpart&quot;, bh.task, rdesc, show.info = FALSE, extract = getFeatureImportance) r$extract $&gt; [[1]] $&gt; FeatureImportance: $&gt; Task: BostonHousing-example $&gt; $&gt; Learner: regr.rpart $&gt; Measure: NA $&gt; Contrast: NA $&gt; Aggregation: function (x) x $&gt; Replace: NA $&gt; Number of Monte-Carlo iterations: NA $&gt; Local: FALSE $&gt; crim zn indus chas nox rm age dis $&gt; 1 3399.046 1192.183 4051.922 0 2303.742 15941.78 2269.408 2636.903 $&gt; rad tax ptratio b lstat $&gt; 1 830.9189 1045.856 2626.595 0 11415.22 $&gt; $&gt; [[2]] $&gt; FeatureImportance: $&gt; Task: BostonHousing-example $&gt; $&gt; Learner: regr.rpart $&gt; Measure: NA $&gt; Contrast: NA $&gt; Aggregation: function (x) x $&gt; Replace: NA $&gt; Number of Monte-Carlo iterations: NA $&gt; Local: FALSE $&gt; crim zn indus chas nox rm age dis $&gt; 1 2122.88 579.2956 4377.805 188.1338 3020.542 14975.56 3097.911 3183.877 $&gt; rad tax ptratio b lstat $&gt; 1 657.2457 2952.654 2856.316 0 10148.19 $&gt; $&gt; [[3]] $&gt; FeatureImportance: $&gt; Task: BostonHousing-example $&gt; $&gt; Learner: regr.rpart $&gt; Measure: NA $&gt; Contrast: NA $&gt; Aggregation: function (x) x $&gt; Replace: NA $&gt; Number of Monte-Carlo iterations: NA $&gt; Local: FALSE $&gt; crim zn indus chas nox rm age dis $&gt; 1 2588.126 1981.96 3616.241 365.7574 3703.958 16503.61 3212.413 4428.26 $&gt; rad tax ptratio b lstat $&gt; 1 639.1926 2930.041 2398.208 747.6475 11787.72 8.4 階層化とブロック化 カテゴリー変数に対する階層化とは、訓練セットとテストセット内で各値の比率が変わらないようにすることを指す。階層化が可能なのは目的変数がカテゴリーである場合(教師あり学習における分類や生存時間分析)や、説明変数がカテゴリーである場合に限られる。 ブロック化とは、観測値の一部分をブロックとして扱い、リサンプリングの間にブロックが分割されないように扱うことを指す。つまり、ブロック全体は訓練セットかテストセットのいずれかにまとまって属すことになる。 8.4.1 目的変数の階層化 分類においては、元のデータと同じ比率で各クラスの値が含まれていることが望ましい。これはクラス間の観測数が不均衡であったり、データセットの大きさが小さい場合に有効である。さもなければ、観測数が少ないクラスのデータが訓練セットに含まれないということが起こりうる。これは分類性能の低下やモデルのクラッシュにつながる。階層化リサンプリングを行うためには、makeResampleDesc実行時にstratify = TRUEを指定する。 rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3, stratify = TRUE) r = resample(&quot;classif.lda&quot;, iris.task, rdesc, show.info = FALSE) r $&gt; Resample Result $&gt; Task: iris-example $&gt; Learner: classif.lda $&gt; Aggr perf: mmce.test.mean=0.0199 $&gt; Runtime: 0.0286942 階層化を生存時間分析に対して行う場合は、打ち切りの割合が制御される。 8.4.2 説明変数の階層化 説明変数の階層化が必要な場合もある。この場合は、stratify.cols引数に対して階層化したい因子型変数を指定する。 rdesc = makeResampleDesc(&quot;CV&quot;, iter = 3, stratify.cols = &quot;chas&quot;) r = resample(&quot;regr.rpart&quot;, bh.task, rdesc, show.info = FALSE) r $&gt; Resample Result $&gt; Task: BostonHousing-example $&gt; Learner: regr.rpart $&gt; Aggr perf: mse.test.mean= 23 $&gt; Runtime: 0.0463572 8.4.3 ブロック化 いくつかの観測値が互いに関連しており、これらが訓練データとテストデータに分割されるのが望ましくない場合には、タスク作成時にその情報をblocking引数に因子型ベクトルを与えることで指定する。 ## それぞれ30の観測値からなる5つのブロックを指定する例 task = makeClassifTask(data = iris, target = &quot;Species&quot;, blocking = factor(rep(1:5, each = 30))) task $&gt; Supervised task: iris $&gt; Type: classif $&gt; Target: Species $&gt; Observations: 150 $&gt; Features: $&gt; numerics factors ordered $&gt; 4 0 0 $&gt; Missings: FALSE $&gt; Has weights: FALSE $&gt; Has blocking: TRUE $&gt; Classes: 3 $&gt; setosa versicolor virginica $&gt; 50 50 50 $&gt; Positive class: NA 8.5 リサンプリングの詳細とリサンプルのインスタンス 既に説明したように、リサンプリング手法はmakeResampleDesc関数を使って指定する。 rdesc = makeResampleDesc(&quot;CV&quot;, iter = 3) rdesc $&gt; Resample description: cross-validation with 3 iterations. $&gt; Predict: test $&gt; Stratification: FALSE str(rdesc) $&gt; List of 4 $&gt; $ id : chr &quot;cross-validation&quot; $&gt; $ iters : int 3 $&gt; $ predict : chr &quot;test&quot; $&gt; $ stratify: logi FALSE $&gt; - attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot; 上記rdescはResampleDescクラス(resample descriptionの略)を継承しており、原則として、リサンプリング手法に関する必要な情報(繰り返し数、訓練セットとテストセットの比率、階層化したい変数など)を全て含んでいる。 makeResampleInstance関数は、データセットに含まれるデータ数を直接指定するか、タスクを指定することで、ResampleDescに従って訓練セットとテストセットの概要を生成する。 ## taskに基づくリサンプルインスタンスの生成 rin = makeResampleInstance(rdesc, iris.task) rin $&gt; Resample instance for 150 cases. $&gt; Resample description: cross-validation with 3 iterations. $&gt; Predict: test $&gt; Stratification: FALSE str(rin) $&gt; List of 5 $&gt; $ desc :List of 4 $&gt; ..$ id : chr &quot;cross-validation&quot; $&gt; ..$ iters : int 3 $&gt; ..$ predict : chr &quot;test&quot; $&gt; ..$ stratify: logi FALSE $&gt; ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot; $&gt; $ size : int 150 $&gt; $ train.inds:List of 3 $&gt; ..$ : int [1:100] 104 35 40 114 123 13 9 31 146 16 ... $&gt; ..$ : int [1:100] 104 55 35 114 13 8 17 97 78 111 ... $&gt; ..$ : int [1:100] 55 40 123 9 8 31 146 16 17 128 ... $&gt; $ test.inds :List of 3 $&gt; ..$ : int [1:50] 6 8 12 15 17 24 26 29 33 36 ... $&gt; ..$ : int [1:50] 2 4 9 14 16 18 20 22 23 31 ... $&gt; ..$ : int [1:50] 1 3 5 7 10 11 13 19 21 25 ... $&gt; $ group : Factor w/ 0 levels: $&gt; - attr(*, &quot;class&quot;)= chr &quot;ResampleInstance&quot; ## データセットのサイズを指定してリサンプルインスタンスを生成する例 rin = makeResampleInstance(rdesc, size = nrow(iris)) str(rin) $&gt; List of 5 $&gt; $ desc :List of 4 $&gt; ..$ id : chr &quot;cross-validation&quot; $&gt; ..$ iters : int 3 $&gt; ..$ predict : chr &quot;test&quot; $&gt; ..$ stratify: logi FALSE $&gt; ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot; $&gt; $ size : int 150 $&gt; $ train.inds:List of 3 $&gt; ..$ : int [1:100] 119 64 54 128 100 34 63 110 22 56 ... $&gt; ..$ : int [1:100] 119 128 140 47 100 34 115 139 95 58 ... $&gt; ..$ : int [1:100] 64 54 140 47 63 110 22 56 115 139 ... $&gt; $ test.inds :List of 3 $&gt; ..$ : int [1:50] 1 4 8 11 12 17 18 19 24 26 ... $&gt; ..$ : int [1:50] 3 6 7 10 14 20 22 23 25 28 ... $&gt; ..$ : int [1:50] 2 5 9 13 15 16 21 27 29 31 ... $&gt; $ group : Factor w/ 0 levels: $&gt; - attr(*, &quot;class&quot;)= chr &quot;ResampleInstance&quot; ここでrinはResampleInstanceクラスを継承しており、訓練セットとテストセットのインデックスをリストとして含んでいる。 ResampleDescがresampleに渡されると、インスタンスの生成は内部的に行われる。もちろん、ResampleInstanceを直接渡すこともできる。 リサンプルの詳細(resample description)とリサンプルのインスタンス、そしてリサンプル関数と分割するのは、複雑にしすぎているのではと感じるかもしれないが、幾つかの利点がある。 リサンプルインスタンスを用いると、同じ訓練セットとテストセットを用いて学習器の性能比較を行うことが容易になる。これは、既に実施した性能比較試験に対し、他の手法を追加したい場合などに特に便利である。また、後で結果を再現するためにデータとリサンプルインスタンスをセットで保管しておくこともできる。 rdesc = makeResampleDesc(&quot;CV&quot;, iter = 3) rin = makeResampleInstance(rdesc, task = iris.task) ## 同じインスタンスを使い、2種類の学習器で性能指標を計算する r.lda = resample(&quot;classif.lda&quot;, iris.task, rin, show.info = FALSE) r.rpart = resample(&quot;classif.rpart&quot;, iris.task, rin, show.info = FALSE) c(&quot;lda&quot; = r.lda$aggr, &quot;rpart&quot; = r.rpart$aggr) $&gt; lda.mmce.test.mean rpart.mmce.test.mean $&gt; 0.04000000 0.06666667 新しいリサンプリング手法を追加したければ、ResampleDescおよびResampleInstanceクラスのインスタンスを作成すればよく、resample関数やそれ以上のメソッドに触る必要はない。 通常、makeResampleInstanceを呼び出したときの訓練セットとテストセットのインデックスはランダムに割り当てられる。主にホールドアウト法においては、これを完全にマニュアルで行わなければならない場面がある。これはmakeFixedHoldoutInstance関数を使うと実現できる。 rin = makeFixedHoldoutInstance(train.inds = 1:100, test.inds = 101:150, size = 150) rin $&gt; Resample instance for 150 cases. $&gt; Resample description: holdout with 0.67 split rate. $&gt; Predict: test $&gt; Stratification: FALSE 8.6 性能指標の集約 リサンプリングそれぞれに対して性能指標を計算したら、それを集計する必要がある。 大半のリサンプリング手法(ホールドアウト法、クロスバリデーション、サブサンプリングなど)では、性能指標はテストデータのみで計算され、平均によって集約される。 mlrにおける性能指標を表現するMeasureクラスのオブジェクトは、$aggrスロットに対応するデフォルトの集約手法を格納している。大半はtest.meanである。例外の一つは平均二乗誤差平方根(rmse)である。 ## 一般的な集約手法 mmce$aggr $&gt; Aggregation function: test.mean ## 具体的な計算方法 mmce$aggr$fun $&gt; function (task, perf.test, perf.train, measure, group, pred) $&gt; mean(perf.test) $&gt; &lt;bytecode: 0x7fd68823bdf0&gt; $&gt; &lt;environment: namespace:mlr&gt; ## rmseの場合 rmse$aggr $&gt; Aggregation function: test.rmse ## test.rmseの具体的な計算方法 rmse$aggr$fun $&gt; function (task, perf.test, perf.train, measure, group, pred) $&gt; sqrt(mean(perf.test^2)) $&gt; &lt;bytecode: 0x7fd685f35678&gt; $&gt; &lt;environment: namespace:mlr&gt; setAggrigation関数を使うと、集約方法を変更することも出来る。利用可能な集約手法の一覧はaggregations function | R Documentationを確認してほしい。 8.6.1 例: 一つの指標に複数の集約方法 test.median、test.min、test.maxはそれぞれテストセットから求めた性能指標を中央値、最小値、最大値で集約する。 mseTestMedian = setAggregation(mse, test.median) mseTestMin = setAggregation(mse, test.min) mseTestMax = setAggregation(mse, test.max) rdesc = makeResampleDesc(&quot;CV&quot;, iter = 3) r = resample(&quot;regr.lm&quot;, bh.task, rdesc, show.info = FALSE, measures = list(mse, mseTestMedian, mseTestMin, mseTestMax)) r $&gt; Resample Result $&gt; Task: BostonHousing-example $&gt; Learner: regr.lm $&gt; Aggr perf: mse.test.mean=25.7,mse.test.median=25.5,mse.test.min=18.5,mse.test.max=33.1 $&gt; Runtime: 0.038976 r$aggr $&gt; mse.test.mean mse.test.median mse.test.min mse.test.max $&gt; 25.69050 25.50319 18.46241 33.10591 8.6.2 例: 訓練セットの誤差を計算する 平均誤分類率を訓練セットとテストセットに対して計算する例を示す。makeResampleDesc実行時にpredict = &quot;both&quot;を指定しておく必要があることに注意してもらいたい。 mmceTrainMean = setAggregation(mmce, train.mean) rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3, predict = &quot;both&quot;) r = resample(&quot;classif.rpart&quot;, iris.task, rdesc, measures = list(mmce, mmceTrainMean)) $&gt; [Resample] cross-validation iter 1: mmce.train.mean=0.03,mmce.test.mean=0.18 $&gt; [Resample] cross-validation iter 2: mmce.train.mean=0.04,mmce.test.mean=0.04 $&gt; [Resample] cross-validation iter 3: mmce.train.mean=0.03,mmce.test.mean=0.06 $&gt; [Resample] Aggr. Result: mmce.test.mean=0.0933,mmce.train.mean=0.0333 8.6.3 例: ブートストラップ out-of-bagブートストラップ推定では、まず元のデータセット\\(D\\)から重複ありの抽出によって\\(D^{*1}, ...,D^{*B}\\)と\\(B\\)個の新しいデータセット(要素数は元のデータセットと同じ)を作成する。そして、\\(b\\)回目の繰り返しでは、\\(D^{*b}\\)を訓練セットに使い、使われなかった要素\\(D\\setminus D^{*b}\\)をテストセットに用いて各繰り返しに対する推定値を計算し、最終的に\\(B\\)個の推定値を得る。 out-of-bagブートストラップの変種であるb632とb632+では、訓練セットのパフォーマンスとOOBサンプルのパフォーマンスの凸結合を計算するため、訓練セットに対する予測と適切な集計方法を必要とする。 ## ブートストラップをリサンプリング手法に選び、予測は訓練セットとテストセットの両方に行う rdesc = makeResampleDesc(&quot;Bootstrap&quot;, predict = &quot;both&quot;, iters = 10) ## b632およびb632+専用の集計手法を設定する mmceB632 = setAggregation(mmce, b632) mmceB632plus = setAggregation(mmce, b632plus) r = resample(&quot;classif.rpart&quot;, iris.task, rdesc, measures = list(mmce, mmceB632, mmceB632plus), show.info = FALSE) r$measures.train $&gt; iter mmce mmce mmce $&gt; 1 1 0.026666667 0.026666667 0.026666667 $&gt; 2 2 0.020000000 0.020000000 0.020000000 $&gt; 3 3 0.026666667 0.026666667 0.026666667 $&gt; 4 4 0.026666667 0.026666667 0.026666667 $&gt; 5 5 0.013333333 0.013333333 0.013333333 $&gt; 6 6 0.020000000 0.020000000 0.020000000 $&gt; 7 7 0.020000000 0.020000000 0.020000000 $&gt; 8 8 0.020000000 0.020000000 0.020000000 $&gt; 9 9 0.006666667 0.006666667 0.006666667 $&gt; 10 10 0.020000000 0.020000000 0.020000000 r$aggr $&gt; mmce.test.mean mmce.b632 mmce.b632plus $&gt; 0.07758371 0.05639290 0.05790858 8.7 便利な関数 これまでに説明した方法は柔軟ではあるが、学習器を少し試してみたい場合にはタイプ数が多くて面倒である。mlrには様々な略記法が用意してあるが、リサンプリング手法についても同様である。ホールドアウトやクロスバリデーション、ブートストラップ(b632)等のよく使うリサンプリング手法にはそれぞれ特有の関数が用意してある。 crossval(&quot;classif.lda&quot;, iris.task, iters = 3, measures = list(mmce, ber)) $&gt; [Resample] cross-validation iter 1: mmce.test.mean=0.02,ber.test.mean=0.0222 $&gt; [Resample] cross-validation iter 2: mmce.test.mean=0.04,ber.test.mean=0.0333 $&gt; [Resample] cross-validation iter 3: mmce.test.mean=0.02,ber.test.mean=0.0167 $&gt; [Resample] Aggr. Result: mmce.test.mean=0.0267,ber.test.mean=0.0241 $&gt; Resample Result $&gt; Task: iris-example $&gt; Learner: classif.lda $&gt; Aggr perf: mmce.test.mean=0.0267,ber.test.mean=0.0241 $&gt; Runtime: 0.054131 bootstrapB632plus(&quot;regr.lm&quot;, bh.task, iters = 3, measures = list(mse, mae)) $&gt; [Resample] OOB bootstrapping iter 1: mse.b632plus=18.6,mae.b632plus=3.06,mse.b632plus=30.8,mae.b632plus=3.42 $&gt; [Resample] OOB bootstrapping iter 2: mse.b632plus=23.2,mae.b632plus=3.49,mse.b632plus=17.3,mae.b632plus=3.06 $&gt; [Resample] OOB bootstrapping iter 3: mse.b632plus=18.9,mae.b632plus=2.96,mse.b632plus=27.4,mae.b632plus=3.58 $&gt; [Resample] Aggr. Result: mse.b632plus=23.5,mae.b632plus=3.29 $&gt; Resample Result $&gt; Task: BostonHousing-example $&gt; Learner: regr.lm $&gt; Aggr perf: mse.b632plus=23.5,mae.b632plus=3.29 $&gt; Runtime: 0.0609651 "],
["section-9.html", "Section 9 ハイパーパラメータのチューニング 9.1 パラメータ探索空間の指定 9.2 最適化アルゴリズムの指定 9.3 チューニングの実行 9.4 チューニング結果へのアクセス 9.5 ハイパーパラメータチューニングの影響を調査する 9.6 その他いろいろ", " Section 9 ハイパーパラメータのチューニング 多くの機械学習アルゴリズムはハイパーパラメータを持っている。学習器のチュートリアルでも説明したが、ハイパーパラメータとして特定の値を設定したければその値をmakeLearnerに渡すだけで良い。しかし、ハイパーパラメータの最適な値というのは大抵の場合は自明ではなく、できれば自動的に調整する手法が欲しい。 機械学習アルゴリズムをチューニングするためには、以下の点を指定する必要がある。 パラメータの探索範囲 最適化アルゴリズム(チューニングメソッドとも呼ぶ) 評価手法(すなわち、リサンプリング手法と性能指標) パラメータの探索範囲: 例としてサポートベクターマシン(SVM)におけるパラメータCの探索範囲を指定してみよう。 ps = makeParamSet( makeNumericParam(&quot;C&quot;, lower = 0.01, upper = 0.1) ) 最適化アルゴリズム: 例としてランダムサーチを指定してみよう。 ctrl = makeTuneControlRandom(maxit = 100L) 評価手法: リサンプリング手法として3分割クロスバリデーションを、性能指標として精度を指定してみよう。 rdesc = makeResampleDesc(&quot;CV&quot;, iter = 3L) measure = acc 評価手法の指定方法については既に説明したところであるので、ここから先は探索範囲と最適化アルゴリズムの指定方法と、チューニングをどのように行い、結果にどのようにアクセスし、さらにチューニング結果を可視化する方法について幾つかの例を通して説明していこう。 このセクションを通して、例としては分類問題を取り上げるが、他の学習問題についても同様の手順で実行できるはずだ。 このさき、irisの分類タスクを使用して、SVMのハイパーパラメータを放射基底関数(RBF)カーネルを使ってチューニングする例を説明する。以下の例では、コストパラメータCと、RBFカーネルのパラメータsigmaをチューニングする。 9.1 パラメータ探索空間の指定 チューニングの際にまず指定しなければならないのは値の探索範囲である。これは例えば“いくつかの値の中のどれか”かもしれないし、“\\(10^{-10}\\)から\\(10^{10}\\)までの間の中のどこか”かもしれない。 探索空間の指定に際して、パラメータの探索範囲についての情報を含むParamSetオブジェクトを作成する。これにはmakeParamSet関数を用いる。 例として、パメータCとsigmaの探索範囲を両方共0.5, 1.0, 1.5, 2.0という離散値に設定する例を見よう。それぞれのパラメータにどのような名前が使われているのかは、kernlabパッケージで定義されている(cf. kernlab package | R Documentation)。 discrete_ps = makeParamSet( makeDiscreteParam(&quot;C&quot;, values = c(0.5, 1.0, 1.5, 2.0)), makeDiscreteParam(&quot;sigma&quot;, values = c(0.5, 1.0, 1.5, 2.0)) ) discrete_ps $&gt; Type len Def Constr Req Tunable Trafo $&gt; C discrete - - 0.5,1,1.5,2 - TRUE - $&gt; sigma discrete - - 0.5,1,1.5,2 - TRUE - 連続値の探索範囲を指定する際にはmakeDiscreteParamの代わりにmakeNumericParamを使用する。また、探索範囲として\\(10^{-10}\\)から\\(10^{10}\\)のような範囲を指定する際には、trafo引数に変換用の関数を指定できる(trafoはtransformationの略)。変換用の関数を指定した場合、変換前のスケールで行われ、学習アルゴリズムに値を渡す前に変換が行われる。 num_ps = makeParamSet( makeNumericParam(&quot;C&quot;, lower = -10, upper = 10, trafo = function(x) 10^x), makeNumericParam(&quot;sigma&quot;, lower = -10, upper = 10, trafo = function(x) 10^x) ) 他にも数多くのパラメータが利用できるが、詳しくはmakeParamSet function | R Documentationを確認してもらいたい。 パラメータをリストの形で指定しなければならない関数もあるが、mlrを通じてその関数を扱う場合、mlrはできるかぎりリスト構造を除去し、パラメータを直接指定できるように試みる。例えばSVMを実行する関数のksvmは、kpar引数にsigmaのようなカーネルパラメータをリストで渡す必要がある。今例を見たように、mlrはsigmaを直接扱うことができる。この仕組みのおかげで、mlrは様々なパッケージの学習器を統一したインターフェースで扱うことができるのだ。 9.2 最適化アルゴリズムの指定 パラメータの探索範囲を決めたら次は最適化アルゴリズムを指定する。mlrにおいて最適化アルゴリズムはTuneControlクラスのオブジェクトとして扱われる。 グリッドサーチは適切なパラメータを見つけるための標準的な(しかし遅い)方法の一つだ。 先に例を挙げたdiscrete_psの場合、グリッドサーチは単純に値の全ての組合せを探索する。 ctrl = makeTuneControlGrid() num_psの場合は、グリッドサーチは探索範囲をまず均等なサイズのステップに分割する。標準では分割数は10だが、これはresolution引数で変更できる。ここではresolutionに15を指定してみよう。なお、ここで言う均等な15分割というのは、10^seq(-10, 10, length.out = 15)という意味である。 ctrl = makeTuneControlGrid(resolution = 15L) クロスバリデーション以外にも多くの最適化アルゴリズムが利用可能であるが、詳しくはTuneControl function | R Documentationを確認してもらいたい。 グリッドサーチは一般的には遅すぎるので、ランダムサーチについても検討してみよう。ランダムサーチはその名の通り値をランダムに選択する。maxit引数に試行回数を指定できる。 ctrl = makeTuneControlRandom(maxit = 200L) 9.3 チューニングの実行 パラメータの探索範囲と最適化アルゴリズムを決めたら、いよいよチューニングの実行の時だ。あとは、リサンプリング手法と評価尺度を設定する必要がある。 今回は3分割クロスバリデーションをパラメータ設定の評価に使用する。まずはリサンプリングdescriptionを生成する。 rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3L) では、今まで作成したものを組合せて、tuneParams関数によりパラメータチューニングを実行しよう。今回はdiscrete_psに対してグリッドサーチを行う。 ctrl = makeTuneControlGrid() res = tuneParams(&quot;classif.ksvm&quot;, task = iris.task, resampling = rdesc, par.set = discrete_ps, control = ctrl) $&gt; [Tune] Started tuning learner classif.ksvm for parameter set: $&gt; Type len Def Constr Req Tunable Trafo $&gt; C discrete - - 0.5,1,1.5,2 - TRUE - $&gt; sigma discrete - - 0.5,1,1.5,2 - TRUE - $&gt; With control class: TuneControlGrid $&gt; Imputation value: 1 $&gt; [Tune-x] 1: C=0.5; sigma=0.5 $&gt; [Tune-y] 1: mmce.test.mean=0.0533; time: 0.0 min $&gt; [Tune-x] 2: C=1; sigma=0.5 $&gt; [Tune-y] 2: mmce.test.mean=0.0533; time: 0.0 min $&gt; [Tune-x] 3: C=1.5; sigma=0.5 $&gt; [Tune-y] 3: mmce.test.mean=0.06; time: 0.0 min $&gt; [Tune-x] 4: C=2; sigma=0.5 $&gt; [Tune-y] 4: mmce.test.mean=0.06; time: 0.0 min $&gt; [Tune-x] 5: C=0.5; sigma=1 $&gt; [Tune-y] 5: mmce.test.mean=0.0667; time: 0.0 min $&gt; [Tune-x] 6: C=1; sigma=1 $&gt; [Tune-y] 6: mmce.test.mean=0.06; time: 0.0 min $&gt; [Tune-x] 7: C=1.5; sigma=1 $&gt; [Tune-y] 7: mmce.test.mean=0.0467; time: 0.0 min $&gt; [Tune-x] 8: C=2; sigma=1 $&gt; [Tune-y] 8: mmce.test.mean=0.0533; time: 0.0 min $&gt; [Tune-x] 9: C=0.5; sigma=1.5 $&gt; [Tune-y] 9: mmce.test.mean=0.06; time: 0.0 min $&gt; [Tune-x] 10: C=1; sigma=1.5 $&gt; [Tune-y] 10: mmce.test.mean=0.06; time: 0.0 min $&gt; [Tune-x] 11: C=1.5; sigma=1.5 $&gt; [Tune-y] 11: mmce.test.mean=0.0667; time: 0.0 min $&gt; [Tune-x] 12: C=2; sigma=1.5 $&gt; [Tune-y] 12: mmce.test.mean=0.06; time: 0.0 min $&gt; [Tune-x] 13: C=0.5; sigma=2 $&gt; [Tune-y] 13: mmce.test.mean=0.0667; time: 0.0 min $&gt; [Tune-x] 14: C=1; sigma=2 $&gt; [Tune-y] 14: mmce.test.mean=0.0667; time: 0.0 min $&gt; [Tune-x] 15: C=1.5; sigma=2 $&gt; [Tune-y] 15: mmce.test.mean=0.0667; time: 0.0 min $&gt; [Tune-x] 16: C=2; sigma=2 $&gt; [Tune-y] 16: mmce.test.mean=0.06; time: 0.0 min $&gt; [Tune] Result: C=1.5; sigma=1 : mmce.test.mean=0.0467 res $&gt; Tune result: $&gt; Op. pars: C=1.5; sigma=1 $&gt; mmce.test.mean=0.0467 tuneParamsはパラメータの全ての組み合わせに対してクロスバリデーションによる性能評価を行い、最も良い値を出した組合せをパラメータとして採用する。性能指標を指定しなかった場合は誤分類率(mmce)が使用される。 それぞれのmeasureは、その値を最大化すべきか最小化すべきかを知っている。 mmce$minimize $&gt; [1] TRUE acc$minimize $&gt; [1] FALSE もちろん、他の指標をリストとして同時にtuneParamsに渡すこともできる。この場合、最初の指標が最適化に使われ、残りの指標は単に計算されるだけとなる。もし複数の指標を同時に最適化したいと考えるのであれば、Advanced Tuning - mlr tutorialを参照してほしい。 誤分類率の代わりに精度(acc)を計算する例を示そう。同時に、他の性能指標として精度の標準偏差を求めるため、setAggregation関数を使用している。また、今回は探索範囲num_setに対して100回のランダムサーチを行う。100回分の出力は長くなるので、show.info = FALSEを指定している。 ctrl = makeTuneControlRandom(maxit = 100L) res = tuneParams(&quot;classif.ksvm&quot;, task = iris.task, resampling = rdesc, par.set = num_ps, control = ctrl, measures = list(acc, setAggregation(acc, test.sd)), show.info = FALSE) res $&gt; Tune result: $&gt; Op. pars: C=7.99e+03; sigma=5.62e-05 $&gt; acc.test.mean=0.953,acc.test.sd=0.0115 9.4 チューニング結果へのアクセス チューニングの結果はTuneResultクラスのオブジェクトである。見つかった最適値は$xスロット、性能指標については$yスロットを通じてアクセスできる。 res$x $&gt; $C $&gt; [1] 7985.08 $&gt; $&gt; $sigma $&gt; [1] 5.623177e-05 res$y $&gt; acc.test.mean acc.test.sd $&gt; 0.95333333 0.01154701 最適化されたパラメータをセットした学習器は次のように作成できる。 lrn = setHyperPars(makeLearner(&quot;classif.ksvm&quot;), par.vals = res$x) lrn $&gt; Learner classif.ksvm from package kernlab $&gt; Type: classif $&gt; Name: Support Vector Machines; Short name: ksvm $&gt; Class: classif.ksvm $&gt; Properties: twoclass,multiclass,numerics,factors,prob,class.weights $&gt; Predict-Type: response $&gt; Hyperparameters: fit=FALSE,C=7.99e+03,sigma=5.62e-05 あとはこれまでと同じだ。irisデータセットに対して再度学習と予測を行ってみよう。 m = train(lrn, iris.task) predict(m, task = iris.task) $&gt; Prediction: 150 observations $&gt; predict.type: response $&gt; threshold: $&gt; time: 0.00 $&gt; id truth response $&gt; 1 1 setosa setosa $&gt; 2 2 setosa setosa $&gt; 3 3 setosa setosa $&gt; 4 4 setosa setosa $&gt; 5 5 setosa setosa $&gt; 6 6 setosa setosa $&gt; ... (150 rows, 3 cols) しかし、この方法だと最適化された状態のハイパーパラメータの影響しか見ることができない。検索時に生成された他の値を使った場合の影響はどのように確認すれば良いだろうか？ 9.5 ハイパーパラメータチューニングの影響を調査する generateHyperParsEffectDataを使うと、サーチ中に生成された全ての値について調査を行うことができる。 generateHyperParsEffectData(res) $&gt; HyperParsEffectData: $&gt; Hyperparameters: C,sigma $&gt; Measures: acc.test.mean,acc.test.sd $&gt; Optimizer: TuneControlRandom $&gt; Nested CV Used: FALSE $&gt; Snapshot of data: $&gt; C sigma acc.test.mean acc.test.sd iteration exec.time $&gt; 1 3.90155148 9.392509 0.2733333 0.02309401 1 0.056 $&gt; 2 -0.47745952 3.929691 0.2733333 0.02309401 2 0.051 $&gt; 3 0.99951412 9.447758 0.2733333 0.02309401 3 0.053 $&gt; 4 6.24138379 -8.314684 0.8866667 0.03055050 4 0.290 $&gt; 5 0.04530898 2.955353 0.2733333 0.02309401 5 0.051 $&gt; 6 8.61392138 -5.444293 0.9400000 0.06928203 6 0.051 この中に含まれているパラメータの値はオリジナルのスケールであることに注意しよう。trafoに指定した関数で変換後の値が欲しければ、trafo引数にTRUEを指定する必要がある。 generateHyperParsEffectData(res, trafo = TRUE) $&gt; HyperParsEffectData: $&gt; Hyperparameters: C,sigma $&gt; Measures: acc.test.mean,acc.test.sd $&gt; Optimizer: TuneControlRandom $&gt; Nested CV Used: FALSE $&gt; Snapshot of data: $&gt; C sigma acc.test.mean acc.test.sd iteration exec.time $&gt; 1 7.971710e+03 2.468934e+09 0.2733333 0.02309401 1 0.056 $&gt; 2 3.330738e-01 8.505326e+03 0.2733333 0.02309401 2 0.051 $&gt; 3 9.988818e+00 2.803873e+09 0.2733333 0.02309401 3 0.053 $&gt; 4 1.743347e+06 4.845250e-09 0.8866667 0.03055050 4 0.290 $&gt; 5 1.109964e+00 9.023045e+02 0.2733333 0.02309401 5 0.051 $&gt; 6 4.110753e+08 3.595068e-06 0.9400000 0.06928203 6 0.051 また、リサンプリングの部分で説明したように、テストデータに加えて訓練データに対しても性能指標を求められることに注意してもらいたい。 rdesc2 = makeResampleDesc(&quot;Holdout&quot;, predict = &quot;both&quot;) res2 = tuneParams(&quot;classif.ksvm&quot;, task = iris.task, resampling = rdesc2, par.set = num_ps, control = ctrl, measures = list(acc, setAggregation(acc, train.mean)), show.info = FALSE) generateHyperParsEffectData(res2) $&gt; HyperParsEffectData: $&gt; Hyperparameters: C,sigma $&gt; Measures: acc.test.mean,acc.train.mean $&gt; Optimizer: TuneControlRandom $&gt; Nested CV Used: FALSE $&gt; Snapshot of data: $&gt; C sigma acc.test.mean acc.train.mean iteration exec.time $&gt; 1 -9.6272136 2.46479089 0.28 0.36 1 0.025 $&gt; 2 0.5922449 -2.19815745 0.98 0.94 2 0.024 $&gt; 3 5.2125327 -0.46505868 0.96 1.00 3 0.021 $&gt; 4 -1.1182917 3.99346631 0.28 0.36 4 0.024 $&gt; 5 0.5484059 9.10947156 0.30 1.00 5 0.022 $&gt; 6 3.8318971 0.04571449 0.96 1.00 6 0.025 パラメータ値の評価結果はplotHyperParsEffect関数を使うと簡単に可視化できる。例を示そう。以下では、繰り返し毎の性能指標の変化をプロットしている。ここでresは先に示したものとほぼ同じだが、2つの性能指標を使用している。 res = tuneParams(&quot;classif.ksvm&quot;, task = iris.task, resampling = rdesc, par.set = num_ps, control = ctrl, measures = list(acc, mmce), show.info = FALSE) data = generateHyperParsEffectData(res) plotHyperParsEffect(data, x = &quot;iteration&quot;, y = &quot;acc.test.mean&quot;, plot.type = &quot;line&quot;) デフォルトではプロットされるのは現在の大域的な最適値のみであるという点に注意してほしい。これはglobal.only引数で制御できる。 ハイパーパラメータチューニング結果のプロットについてより詳細な話題はHyperparameter Tuning Effects - mlr tutorialを確認してほしい。 9.6 その他いろいろ 回帰や生存時間分析、その他のタスクについてもチューニングのやり方は変わらない。 時間のかかるチューニングで、数値エラーやその他のエラーで計算が停止してしまうのは非常に煩わしい。この点に関する解決策を得るには、configureMlr関数のon.learner.error引数について調べてみると良いだろう。Configuration - mlr tutorialにこの件に関するチュートリアルがある。また、TuneControl function | R Documentationのimpute.val引数に関する情報も役立つだろう。 チューニングは同じデータに対して継続的に実施するため、推定値は楽観的な方向にバイアスがかかっている可能性がある。バイアスのない推定値を得るためのより良いアプローチとしてnested resamplingがある。これは、モデル選択のプロセスを外部リサンプリングループに埋め込む。詳しくはNested Resampling - mlr tutorialを参照。 "],
["section-10.html", "Section 10 ベンチマーク試験 10.1 ベンチマーク試験の実施 10.2 ベンチマーク結果へのアクセス 10.3 ベンチマーク結果のマージ 10.4 ベンチマークの分析と可視化 10.5 その他のコメント", " Section 10 ベンチマーク試験 ベンチマーク試験では、1つ、あるいは複数の性能指標に基いてアルゴリズムを比較するために、異なる学習手法を1つあるいは複数のデータセットに適用する。 mlrではbenchmark関数に学習器とタスクをリストで渡すことでベンチマーク試験を実施できる。benchmarkは通常、学習器とタスクの対に対してリサンプリングを実行する。タスクと性能指標の組み合わせに対してどのようなリサンプリング手法を適用するかは選択することができる。 10.1 ベンチマーク試験の実施 小さな例から始めよう。線形判別分析(lda)と分類木(rpart)をsonar.taskに適用する。リサンプリング手法はホールドアウト法を用いる。 以下の例ではResampleDescオブジェクトを作成する。各リサンプリングのインスタンスはbenchmark関数によって自動的に作成される。インスタンス化はタスクに対して1度だけ実行される。つまり、全ての学習器は全くおなじ訓練セット、テストセットを用いることになる。なお、明示的にResampleInstanceを渡しても良い。 もし、データセットの作成を無作為ではなく任意に行いたければ、makeFixedHoldoutinstanceを使うと良いだろう。 lrns = list(makeLearner(&quot;classif.lda&quot;), makeLearner(&quot;classif.rpart&quot;)) rdesc = makeResampleDesc(&quot;Holdout&quot;) bmr = benchmark(lrns, sonar.task, rdesc) $&gt; Task: Sonar-example, Learner: classif.lda $&gt; [Resample] holdout iter 1: mmce.test.mean=0.271 $&gt; [Resample] Aggr. Result: mmce.test.mean=0.271 $&gt; Task: Sonar-example, Learner: classif.rpart $&gt; [Resample] holdout iter 1: mmce.test.mean=0.357 $&gt; [Resample] Aggr. Result: mmce.test.mean=0.357 bmr $&gt; task.id learner.id mmce.test.mean $&gt; 1 Sonar-example classif.lda 0.2714286 $&gt; 2 Sonar-example classif.rpart 0.3571429 もしmakeLearnerに学習器の種類以外の引数を指定するつもりがなければ、明示的にmakeLearnerを呼び出さずに単に学習器の名前を指定しても良い。上記の例は次のように書き換えることができる。 ## 学習器の名前だけをベクトルで指定しても良い lrns = c(&quot;classif.lda&quot;, &quot;classif.rpart&quot;) ## 学習器の名前とLearnerオブジェクトを混ぜたリストでも良い lrns = list(makeLearner(&quot;classif.lda&quot;, predict.type = &quot;prob&quot;), &quot;classif.rpart&quot;) bmr = benchmark(lrns, sonar.task, rdesc) $&gt; Task: Sonar-example, Learner: classif.lda $&gt; [Resample] holdout iter 1: mmce.test.mean=0.314 $&gt; [Resample] Aggr. Result: mmce.test.mean=0.314 $&gt; Task: Sonar-example, Learner: classif.rpart $&gt; [Resample] holdout iter 1: mmce.test.mean=0.329 $&gt; [Resample] Aggr. Result: mmce.test.mean=0.329 bmr $&gt; task.id learner.id mmce.test.mean $&gt; 1 Sonar-example classif.lda 0.3142857 $&gt; 2 Sonar-example classif.rpart 0.3285714 printの結果は各行がタスクと学習器の1つの組合せに対応している。ここでは分類のデフォルトの指標である平均誤分類率が示されている。 bmrはBenchmarcResultクラスのオブジェクトである。基本的には、これはResampleResultクラスのオブジェクトのリストのリストを含んでおり、最初のリストはタスク、その中のリストは学習器に対応した並びになっている。 10.1.1 実験を再現可能にする 一般的にいって、実験は再現可能であることが望ましい。mlrはset.seed関数の設定に従うので、スクリプト実行前にset.seedによって乱数種を固定しておけば再現性が確保できる。 もし並列計算を使用する場合は、ユースケースに合わせてset.seedの呼び出し方を調整する必要がある。例えば、set.seed(123, &quot;L'Ecuyer&quot;)と指定すると子プロセス単位で再現性が確保できる。mcapplyの例(mclapply function | R Documentation)を見ると並列計算と再現性に関するもう少し詳しい情報が得られるだろう(訳注:こちらのほうが良いかも？R: Parallel version of lapply)。 10.2 ベンチマーク結果へのアクセス mlrはgetBMR&lt;抽出対象&gt;という名前のアクセサ関数を幾つか用意している。これにより、さらなる分析のために情報を探索することができる。これには検討中の学習アルゴリズムに関するパフォーマンスや予測などが含まれる。 10.2.1 学習器の性能 先程のベンチマーク試験の結果を見てみよう。getBMRPerformancesは個々のリサンプリング毎の性能指標を返し、getMBRAggrPerformancesは性能指標の集約値を返す。 getBMRPerformances(bmr) $&gt; $`Sonar-example` $&gt; $`Sonar-example`$classif.lda $&gt; iter mmce $&gt; 1 1 0.3142857 $&gt; $&gt; $`Sonar-example`$classif.rpart $&gt; iter mmce $&gt; 1 1 0.3285714 getBMRAggrPerformances(bmr) $&gt; $`Sonar-example` $&gt; $`Sonar-example`$classif.lda $&gt; mmce.test.mean $&gt; 0.3142857 $&gt; $&gt; $`Sonar-example`$classif.rpart $&gt; mmce.test.mean $&gt; 0.3285714 今回の例ではリサンプリング手法にホールドアウト法を選んだので、リサンプリングは1回しか行っていない。そのため、個々のリサンプリング結果に基づく性能指標と集約値はどちらも同じ表示結果になっている。 デフォルトでは、ほぼすべてのゲッター関数ネストされたリストを返す。リストの最初のレベルはタスクで分類されており、二番目のレベルは学習器での分類になる。学習器またはタスクが1つしかない場合は、drop = TRUEを指定するとフラットなリストを得ることもできる。 getBMRPerformances(bmr, drop = TRUE) $&gt; $classif.lda $&gt; iter mmce $&gt; 1 1 0.3142857 $&gt; $&gt; $classif.rpart $&gt; iter mmce $&gt; 1 1 0.3285714 大抵の場合はデータフレームの方が便利だろう。as.df = TRUEを指定すると結果をデータフレームに変換できる。 getBMRPerformances(bmr, as.df = TRUE) $&gt; task.id learner.id iter mmce $&gt; 1 Sonar-example classif.lda 1 0.3142857 $&gt; 2 Sonar-example classif.rpart 1 0.3285714 10.2.2 予測 デフォルトでは、BenchmarkResultは学習器の予測結果も含んでいる。もし、メモリ節約などの目的でこれを止めさせたければkeep.pred = FALSEをbenchmark関数に指定すれば良い。 予測へのアクセスはgetBMRPredictions関数を使う。デフォルトでは、ResamplePredictionオブジェクトのネストされたリストが返ってくる。性能指標の場合と同様に、ここでもdrop及びas.df引数を使うことができる。 getBMRPredictions(bmr) $&gt; $`Sonar-example` $&gt; $`Sonar-example`$classif.lda $&gt; Resampled Prediction for: $&gt; Resample description: holdout with 0.67 split rate. $&gt; Predict: test $&gt; Stratification: FALSE $&gt; predict.type: prob $&gt; threshold: M=0.50,R=0.50 $&gt; time (mean): 0.01 $&gt; id truth prob.M prob.R response iter set $&gt; 1 165 M 9.739057e-01 0.0260942571 M 1 test $&gt; 2 118 M 9.769969e-01 0.0230031469 M 1 test $&gt; 3 107 M 5.205392e-01 0.4794608221 M 1 test $&gt; 4 159 M 9.996184e-01 0.0003815522 M 1 test $&gt; 5 66 R 4.726013e-07 0.9999995274 R 1 test $&gt; 6 193 M 9.955122e-01 0.0044878035 M 1 test $&gt; ... (70 rows, 7 cols) $&gt; $&gt; $&gt; $`Sonar-example`$classif.rpart $&gt; Resampled Prediction for: $&gt; Resample description: holdout with 0.67 split rate. $&gt; Predict: test $&gt; Stratification: FALSE $&gt; predict.type: response $&gt; threshold: $&gt; time (mean): 0.01 $&gt; id truth response iter set $&gt; 1 165 M M 1 test $&gt; 2 118 M M 1 test $&gt; 3 107 M R 1 test $&gt; 4 159 M M 1 test $&gt; 5 66 R R 1 test $&gt; 6 193 M M 1 test $&gt; ... (70 rows, 5 cols) head(getBMRPredictions(bmr, as.df = TRUE)) $&gt; task.id learner.id id truth prob.M prob.R response $&gt; 1 Sonar-example classif.lda 165 M 9.739057e-01 0.0260942571 M $&gt; 2 Sonar-example classif.lda 118 M 9.769969e-01 0.0230031469 M $&gt; 3 Sonar-example classif.lda 107 M 5.205392e-01 0.4794608221 M $&gt; 4 Sonar-example classif.lda 159 M 9.996184e-01 0.0003815522 M $&gt; 5 Sonar-example classif.lda 66 R 4.726013e-07 0.9999995274 R $&gt; 6 Sonar-example classif.lda 193 M 9.955122e-01 0.0044878035 M $&gt; iter set $&gt; 1 1 test $&gt; 2 1 test $&gt; 3 1 test $&gt; 4 1 test $&gt; 5 1 test $&gt; 6 1 test IDを通じて特定の学習器やタスクの結果にアクセスすることもできる。多くのゲッター関数はIDを指定するためのlearner.ids引数とtask.ids引数が用意されている。 head(getBMRPredictions(bmr, learner.ids = &quot;classif.rpart&quot;, as.df = TRUE)) $&gt; task.id learner.id id truth response iter set $&gt; 1 Sonar-example classif.rpart 165 M M 1 test $&gt; 2 Sonar-example classif.rpart 118 M M 1 test $&gt; 3 Sonar-example classif.rpart 107 M R 1 test $&gt; 4 Sonar-example classif.rpart 159 M M 1 test $&gt; 5 Sonar-example classif.rpart 66 R R 1 test $&gt; 6 Sonar-example classif.rpart 193 M M 1 test デフォルトのIDが嫌なら、makeLearnerやmake*Task関数のid引数を通じて設定できる。さらに、学習器のIDを簡単に変更するための関数としてsetLearnerId関数も用意されている。 10.2.3 ID ベンチマーク試験における学習器、タスク、性能指標のIDは、以下のように取得できる。 getBMRTaskIds(bmr) $&gt; [1] &quot;Sonar-example&quot; getBMRLearnerIds(bmr) $&gt; [1] &quot;classif.lda&quot; &quot;classif.rpart&quot; getBMRMeasureIds(bmr) $&gt; [1] &quot;mmce&quot; 10.2.4 フィット済みモデル デフォルトではBenchmarkResultオブジェクトはフィット済みモデルも含んでいる。これは、benchmark関数を呼び出す際にmodels = FALSEを指定することで抑制できる。フィット済みモデルはgetBMRModels関数を使うことで確認できる。この関数が返すのは(おそらくネストされた)WrappedModelオブジェクトのリストである。 getBMRModels(bmr) $&gt; $`Sonar-example` $&gt; $`Sonar-example`$classif.lda $&gt; $`Sonar-example`$classif.lda[[1]] $&gt; Model for learner.id=classif.lda; learner.class=classif.lda $&gt; Trained on: task.id = Sonar-example; obs = 138; features = 60 $&gt; Hyperparameters: $&gt; $&gt; $&gt; $`Sonar-example`$classif.rpart $&gt; $`Sonar-example`$classif.rpart[[1]] $&gt; Model for learner.id=classif.rpart; learner.class=classif.rpart $&gt; Trained on: task.id = Sonar-example; obs = 138; features = 60 $&gt; Hyperparameters: xval=0 10.2.5 学習器と性能指標 使用された学習器はgetBMRLearnersで、性能指標はgetBMRMeasuresでそれぞれ抽出できる。 getBMRLearners(bmr) $&gt; $classif.lda $&gt; Learner classif.lda from package MASS $&gt; Type: classif $&gt; Name: Linear Discriminant Analysis; Short name: lda $&gt; Class: classif.lda $&gt; Properties: twoclass,multiclass,numerics,factors,prob $&gt; Predict-Type: prob $&gt; Hyperparameters: $&gt; $&gt; $&gt; $classif.rpart $&gt; Learner classif.rpart from package rpart $&gt; Type: classif $&gt; Name: Decision Tree; Short name: rpart $&gt; Class: classif.rpart $&gt; Properties: twoclass,multiclass,missings,numerics,factors,ordered,prob,weights,featimp $&gt; Predict-Type: response $&gt; Hyperparameters: xval=0 getBMRMeasures(bmr) $&gt; [[1]] $&gt; Name: Mean misclassification error $&gt; Performance measure: mmce $&gt; Properties: classif,classif.multi,req.pred,req.truth $&gt; Minimize: TRUE $&gt; Best: 0; Worst: 1 $&gt; Aggregated by: test.mean $&gt; Note: Defined as: mean(response != truth) 10.3 ベンチマーク結果のマージ ベンチマーク試験が終わった後で、他の学習器やタスクを追加したくなったらどうすればよいだろうか。このような場合は、mergeBenchmarkResults関数を使えば、複数のBenchmarkResutlオブジェクトをマージすることができる。 先程行った線形判別分析と決定木のベンチマーク試験結果に対し、ランダムフォレストと二次判別分析の結果を追加してみよう。 まず、ランダムフォレストと二次判別分析のベンチマーク試験を行う。 lrns2 = list(makeLearner(&quot;classif.randomForest&quot;), makeLearner(&quot;classif.qda&quot;)) bmr2 = benchmark(lrns2, sonar.task, rdesc, show.info = FALSE) bmr2 $&gt; task.id learner.id mmce.test.mean $&gt; 1 Sonar-example classif.randomForest 0.1857143 $&gt; 2 Sonar-example classif.qda 0.4428571 次に、bmrとbmr2をマージする。BenchmarkResultオブジェクトはリストで渡す。 mergeBenchmarkResults(list(bmr, bmr2)) $&gt; task.id learner.id mmce.test.mean $&gt; 1 Sonar-example classif.lda 0.3142857 $&gt; 2 Sonar-example classif.rpart 0.3285714 $&gt; 3 Sonar-example classif.randomForest 0.1857143 $&gt; 4 Sonar-example classif.qda 0.4428571 上記の例ではリサンプルdescriptionをbenchmark関数に指定していることに注意してもらいたい。つまり、ldaとrpartはrandamForestおよびqdaとは異なる訓練/テストセットを用いて評価された可能性が高い。 異なる訓練/テストセットを用いて評価を行うと、学習器間の正確な性能比較が難しくなる。もし、他の学習器を使った試験を後から追加する見込みがあるのなら、最初からResampleInstancesを使用したほうが良い。リサンプルをインスタンス化しておけば、同じ訓練/テストセットを後の試験でも使用することができるからだ。 あるいは、BenchmarkResultオブジェクトからResampleInstanceを抽出し、これを他の試験に使用しても良い。例を示そう。 # インスタンスの抽出 rin = getBMRPredictions(bmr)[[1]][[1]]$instance # インスタンスを用いてベンチマーク試験を行う bmr3 = benchmark(lrns2, sonar.task, rin, show.info = FALSE) # 結果をマージする mergeBenchmarkResults(list(bmr, bmr3)) $&gt; task.id learner.id mmce.test.mean $&gt; 1 Sonar-example classif.lda 0.3142857 $&gt; 2 Sonar-example classif.rpart 0.3285714 $&gt; 3 Sonar-example classif.randomForest 0.1714286 $&gt; 4 Sonar-example classif.qda 0.4285714 10.4 ベンチマークの分析と可視化 mlrはベンチマーク試験を分析する機能も備えている。これには、可視化、アルゴリズムの順位付け、パフォーマンスの差に対する仮説検定が含まれる。 今回はこの機能を紹介するために、5つの分類タスクと3つの学習アルゴリズムを使用する、やや大きなベンチマーク試験を実施する。 10.4.1 例：線形判別分析と分類木、ランダムフォレストの比較 3つのアルゴリズムは線形判別分析、決定木、ランダムフォレストである。これらのデフォルトの学習器IDはやや長いので、以下の例ではもう少し短い別名を設定した。 5つの分類タスクと言ったが、3つは既に紹介したものだ。これに加えて、mlbenchパッケージに含まれるデータをconvertMLBenchObjToTask関数でタスクに変換したものを用いる。 全てのタスクは10分割クロスバリデーションによりリサンプリングを行う。これは、一つのresample descriptionをbenchmark関数に渡すことで行う。これにより、それぞれのタスクに対するリサンプリングのインスタンス化が自動的に実行される。この方法では、一つのタスク内で全ての学習器に対して同じインスタンスが使用されることになる。 タスクの数と同じ長さのリストでリサンプリング手法を指定すれば、それぞれのタスクに異なるリサンプリング手法を適用することもできる。この際渡すのはresample descriptionsでも良いし、インスタンスでも良い。 評価手法は平均誤分類率を主とするが、合わせてbalanced error rate(ber)と訓練時間(timetrain)も算出する。 ## 学習器リストの作成 lrns = list( makeLearner(&quot;classif.lda&quot;, id = &quot;lda&quot;), makeLearner(&quot;classif.rpart&quot;, id = &quot;rpart&quot;), makeLearner(&quot;classif.randomForest&quot;, id = &quot;randomForest&quot;) ) ## mlbenchパッケージから追加タスクを生成する ring.task = convertMLBenchObjToTask(&quot;mlbench.ringnorm&quot;, n = 600) $&gt; Loading required package: mlbench wave.task = convertMLBenchObjToTask(&quot;mlbench.waveform&quot;, n = 600) ## タスクリストの作成 tasks = list(iris.task, sonar.task, pid.task, ring.task, wave.task) ## リサンプリング手法の指定 rdesc = makeResampleDesc(&quot;CV&quot;, iters = 10) ## 評価指標の指定 meas = list(mmce, ber, timetrain) ## ベンチマーク試験の実行 bmr = benchmark(lrns, tasks, rdesc, meas, show.info = FALSE) bmr $&gt; task.id learner.id mmce.test.mean ber.test.mean $&gt; 1 iris-example lda 0.02000000 0.01666667 $&gt; 2 iris-example rpart 0.08000000 0.07277778 $&gt; 3 iris-example randomForest 0.06000000 0.05500000 $&gt; 4 mlbench.ringnorm lda 0.40666667 0.40395082 $&gt; 5 mlbench.ringnorm rpart 0.20000000 0.20307555 $&gt; 6 mlbench.ringnorm randomForest 0.04666667 0.04691889 $&gt; 7 mlbench.waveform lda 0.16666667 0.16451184 $&gt; 8 mlbench.waveform rpart 0.24500000 0.24799876 $&gt; 9 mlbench.waveform randomForest 0.16000000 0.16211064 $&gt; 10 PimaIndiansDiabetes-example lda 0.22650376 0.27578705 $&gt; 11 PimaIndiansDiabetes-example rpart 0.25768968 0.30048359 $&gt; 12 PimaIndiansDiabetes-example randomForest 0.22790499 0.27238976 $&gt; 13 Sonar-example lda 0.30285714 0.30454643 $&gt; 14 Sonar-example rpart 0.28428571 0.28040571 $&gt; 15 Sonar-example randomForest 0.16380952 0.16538045 $&gt; timetrain.test.mean $&gt; 1 0.0033 $&gt; 2 0.0041 $&gt; 3 0.0291 $&gt; 4 0.0090 $&gt; 5 0.0110 $&gt; 6 0.4260 $&gt; 7 0.0078 $&gt; 8 0.0105 $&gt; 9 0.4347 $&gt; 10 0.0055 $&gt; 11 0.0059 $&gt; 12 0.3345 $&gt; 13 0.0170 $&gt; 14 0.0138 $&gt; 15 0.2496 iris-exampleとPimaIndiansDiabetes-exampleでは線形判別分析が優れいているが、他のタスクではランダムフォレストが良い成績を出しているようだ。一方、訓練時間を見るとランダムフォレストは他の学習器よりも長い時間がかかっている。 パフォーマンスの平均値から何らかの結論を言いたければ、値の変動も考慮に入れる必要がある。リサンプリングの繰り返し全体で値がどのように分布しているかも考慮できれば尚良い。 10分割クロスバリデーションにより、各タスクは10回評価されていることになるが、これは以下の様にして詳細を確認できる。 perf = getBMRPerformances(bmr, as.df = TRUE) head(perf) $&gt; task.id learner.id iter mmce ber timetrain $&gt; 1 iris-example lda 1 0.00000000 0.00000000 0.003 $&gt; 2 iris-example lda 2 0.00000000 0.00000000 0.003 $&gt; 3 iris-example lda 3 0.00000000 0.00000000 0.003 $&gt; 4 iris-example lda 4 0.06666667 0.08333333 0.003 $&gt; 5 iris-example lda 5 0.00000000 0.00000000 0.003 $&gt; 6 iris-example lda 6 0.13333333 0.08333333 0.003 結果を詳しく確認すると、ランダムフォレストは全てのインスタンスで分類木より優れており、線形判別分析は時間の面でほとんどどの場合も優れている事が分かる。また、線形判別分析は時々ランダムフォレストより優れた結果を出している。このサイズの試験結果ならまだ「詳しく確認する」は可能であるが、これよりももっと大きなスケールのベンチマーク試験では、このような判断はずっと難しくなる。 mlrには可視化と仮説検定の仕組みがあるので、より大きなスケールの試験に対してはそれを使おう。 10.4.2 可視化 プロットにはggplot2パッケージが使用される。したがって、要素のリネームや配色変更などのカスタマイズは容易に行える。 10.4.2.1 パフォーマンスの可視化 plotBMRBoxplotは箱ひげ図またはバイオリンプロットによって、リサンプリングの繰り返しの間に指標がどのような値をとったのかを可視化する。これはつまりgetBMRPerformancesの可視化である。 以下に箱ひげ図でmmceの分布を示す。 plotBMRBoxplots(bmr, measure = mmce) 次にバイオリンプロットの例を示す。 # aes, theme, element_textをggplot2::なしで呼び出すためには # ライブラリのロードが必要 library(ggplot2) plotBMRBoxplots(bmr, measure = ber, style = &quot;violin&quot;, pretty.names = FALSE) + aes(color = learner.id) + theme(strip.text.x = element_text(size = 6)) ここでは、指標としてberを使用するとともに、learner.idに基づく色の塗り分けも行っている。また、themeは各パネルのラベル(strip)のフォントサイズを調整している。 pretty.names=FALSEは何かというと、性能指標や学習器のラベルとしてidを使ってくれという指定である。これを指定しなかったときにどのような名前が使われるかは、性能指標であれば指標名$name、学習器ではgetBMRLEarnerShortNameで確認できる。 mmce$name $&gt; [1] &quot;Mean misclassification error&quot; getBMRLearnerShortNames(bmr) $&gt; [1] &quot;lda&quot; &quot;rpart&quot; &quot;rf&quot; プロットに関してよくある質問は、「パネルのラベルと学習器の名前はどうやったら変更できるのか」といったものだ。例えば、今見せた例で言えば、パネルのラベル名に含まれている-exampleやmlbench.を取り除いたり、学習機の名前を大文字の略称に変更したい、などの思ったのではないだろうか。現状、これを解決する一番簡単なやり方はfactorのlevelを書き換えてしまうことだ。例を示そう。 plt = plotBMRBoxplots(bmr, measure = mmce) levels(plt$data$task.id) = c(&quot;Iris&quot;, &quot;Ringnorm&quot;, &quot;Waveform&quot;, &quot;Diabetes&quot;, &quot;Sonar&quot;) levels(plt$data$learner.id) = c(&quot;LDA&quot;, &quot;CART&quot;, &quot;RF&quot;) plt 10.4.3 集約結果の可視化 集約された性能指標(getBMRAggrPerformancesで得られるもの)は、plotBMRSummaryで可視化できる。このプロットでは各タスクの性能指標集約値が同一の線上に並べられる(注: ドットプロット)。標準では、benchmarkで指定された最初の指標がプロット対象となる。今回の例ではmmceだ。加えて、各ポイントには縦方向に若干の誤差が加えられる。これはデータポイントが重なった場合にも識別できるようにするためだ。 plotBMRSummary(bmr) 10.4.4 順位の計算と可視化 性能指標の値に加えて、順位のような相対指標があると新しい知見が得られる場合がある。 convertBMRToRankMatrix関数は、集約された性能指標のひとつに基づいて順位を計算する。例としてmmceに基づくランキングを求めてみよう。 convertBMRToRankMatrix(bmr) $&gt; iris-example mlbench.ringnorm mlbench.waveform $&gt; lda 1 3 2 $&gt; rpart 3 2 3 $&gt; randomForest 2 1 1 $&gt; PimaIndiansDiabetes-example Sonar-example $&gt; lda 1 3 $&gt; rpart 3 2 $&gt; randomForest 2 1 順位は最高のパフォーマンスを示した、つまりmmceが最も低かった手法に対して小さな値が割り当てられる。今回の例ではLDAがirisとPimaIndiansDiabetesに対して最良の結果を示したが、他のタスクではランダムフォレストが優れていた事がわかる。 plotBMRRanksAsBarChart関数を使うと順位を可視化することができる。pos = &quot;tile&quot;を指定すると、順位・学習器・タスクの関係がヒートマップで図示される。この場合、x軸が順位、y軸がタスク、学習器の種類が色にそれぞれ割り当てられる。 plotBMRRanksAsBarChart(bmr, pos = &quot;tile&quot;) なお、plotBMRSummaryでもオプションにtrafo = &quot;rank&quot;を指定することで、性能指標が順位に変換されるため、同様の情報を含むプロットを作成できる。 plotBMRSummary(bmr, trafo = &quot;rank&quot;) plotBMRRanksAsBarChartはデフォルトでは積み上げ棒グラフを、pos = &quot;dodge&quot;オプションを指定すると通常の棒グラフを描画する。これは各種法が獲得した順位の頻度を確認する場合に適している。 plotBMRRanksAsBarChart(bmr) plotBMRRanksAsBarChart(bmr, pos = &quot;dodge&quot;) 10.4.5 仮説検定で学習器を比較する 多くの研究者はアルゴリズムの有意性を仮説検定によって示す必要性を感じていることだろう。ベンチマーク試験の結果の比較などに適していると思われるノンパラメトリック検定として、mlrはOverall Friedman testとFriedman-Nemenyi post hoc testをサポートしている。 Friedman testはstatsパッケージのfriedman.test関数に基いており、これは学習器間に差があるかどうかを検定する。一方、Friedman-Nemenyi testは全ての学習器間の組合せについて差があるかどうかを検定する。ノンパラメトリック検定はパラメトリック検定と違い、データの分布に関する仮定を持たなくて済むという利点がある。しかしこれは、妥当な有意水準の元で有意な差を示すためには多くのデータセットが必要であるということを意味していることが多い。 さて、今我々が扱っている例では3つの学習器を比較している。まずは、そもそも学習器間に差があるのかどうかを検定したいのではないだろうか。Friedman testを実行してみよう。 friedmanTestBMR(bmr) $&gt; $&gt; Friedman rank sum test $&gt; $&gt; data: mmce.test.mean and learner.id and task.id $&gt; Friedman chi-squared = 3.6, df = 2, p-value = 0.1653 今回の例はチュートリアルなので、計算時間節約のために学習器を評価するタスクは5つしかなかった点に注意してほしい。従って、有意水準として少し甘めの\\(\\alpha=0.1\\)程度を見積もっても良いだろう。この場合帰無仮説は棄却されるので、今度はこの差がどの学習器の間に存在するのかを検定してみよう。 # install.packages(&quot;PMCMRplus&quot;) # Friedman testで帰無仮説を棄却できないとNemenyi検定をしてくれないので、 # p.value =で有意水準を引き上げる必要がある。 friedmanPostHocTestBMR(bmr, p.value = 0.1) $&gt; Loading required package: PMCMR $&gt; PMCMR is superseded by PMCMRplus and will be no longer maintained. You may wish to install PMCMRplus instead. $&gt; Warning in friedmanPostHocTestBMR(bmr, p.value = 0.1): Cannot reject null hypothesis of overall Friedman test, $&gt; returning overall Friedman test. $&gt; $&gt; Friedman rank sum test $&gt; $&gt; data: mmce.test.mean and learner.id and task.id $&gt; Friedman chi-squared = 3.6, df = 2, p-value = 0.1653 決定木とランダムフォレストの間の差について帰無仮説を棄却できた。 10.4.6 臨界差ダイアグラム 学習器の性能に関する差を可視化する手法として、critical differences diagramが使用できる。検定手法はNemeny検定(test = &quot;nemenyui&quot;)またはBonferroni-Dunn検定(test = &quot;bd&quot;)が選択できる。 プロットの際、x軸には学習器の平均順位が対応する。 test = &quot;nemenyui&quot;を選択した場合、全てのグループ間で比較が行われるため、出力では互いに有意な差が無い学習器がグループとなるような描画が行われる。グループは学習器間をバーで接続することで図示される。従って、バーで接続されていない学習器間には有意な差が存在しており、平均順位が低い方の学習器の方が(選択した有意水準のもとで)優れていると言うことができる。 test = &quot;bd&quot;を選択した場合は、各学習器はベースラインと比較される。すなわち、ベースラインとして選択した学習器から両方向に臨界差(critical difference)の範囲を示すラインが描画される。従って比較はベースラインの学習器との間でのみ可能となる。臨界差の範囲外の学習器は、ベースラインとした学習器に対して優れている(または劣っている)と考えることができる。 ここで臨界差\\(CD\\)は次のように計算される値である。 \\(CD = q_\\alpha\\sqrt{\\frac{k(k+1)}{6N}}\\) \\(N\\)はタスクの数を、\\(k\\)は学習器の数を、\\(q_\\alpha\\)はスチューデント化された範囲を\\(\\sqrt{2}\\)で除した値である。詳しくはDamsar (2006)を参照してほしい。 createCritDifferencesData関数は、plotCritDifferencesでプロットを作成するために必要な全ての量を計算する。プロット関数に関する詳細は後ほどあらためて可視化のチュートリアルで触れる予定である。 ## Nemeyui test g = generateCritDifferencesData(bmr, p.value = 0.1, test = &quot;nemenyi&quot;) $&gt; Warning in friedmanPostHocTestBMR(bmr, measure, p.value): Cannot reject null hypothesis of overall Friedman test, $&gt; returning overall Friedman test. plotCritDifferences(g) + coord_cartesian(xlim = c(-1, 5), ylim = c(0, 2)) ## Bonferroni-Dunn test g = generateCritDifferencesData(bmr, p.value = 0.1, test = &quot;bd&quot;, baseline = &quot;randomForest&quot;) $&gt; Warning in friedmanPostHocTestBMR(bmr, measure, p.value): Cannot reject null hypothesis of overall Friedman test, $&gt; returning overall Friedman test. plotCritDifferences(g) + coord_cartesian(xlim = c(-1, 5), ylim = c(0, 2)) 10.4.7 プロットの調整 プロットはggplotのオブジェクトなので、これをカスタマイズすることで容易に独自のプロットを作成できる。これは既に見たところだ。一方、getBMRPerformancesやgetBMRAggrPerformancesが返すデータフレームを使って独自のプロットを作成することもできる。以下に例を見よう。 plotBMRBoxplotsでは箱ひげ図を作成したが、密度プロットで性能指標を可視化してみよう(訳注: 原文ではqplotを使用しているが個人的にわかりにくいのでggplotで書き直した。また、strip textのフォントサイズ調整を省略している)。 pref = getBMRPerformances(bmr, as.df = TRUE) ggplot(data = pref[pref$task.id %in% c(&quot;iris-example&quot;, &quot;Sonar-example&quot;), ], aes(x = mmce, colour = learner.id)) + facet_grid(.~task.id) + geom_density() 複数の指標を並列に比較したければ、prefをlong formatに変換する必要がある。以下にmmceとtimetrainを箱ひげ図で表示する例を示そう。 (訳注: 原文とは異なり、tidyr、dplyr、ggplotを使用している。パイプ演算子%&gt;%を使えばより簡潔に書き換えることもできるだろう。) df = tidyr::gather(pref, key = variable, value = value, mmce:timetrain) df = dplyr::filter(df, variable != &quot;ber&quot;) ggplot(df, aes(x = variable, y = value, color = learner.id)) + geom_boxplot(position = &quot;dodge&quot;) + labs(x = &quot;measure&quot;, y = &quot;performance&quot;) + facet_wrap(~ task.id, nrow = 2) リサンプリング毎の学習器間のパフォーマンスの関係を調べることが有用な場合もある。ある学習器が例外的に良い成績を出している場合に他の学習器の成績が悪いという様な場合があれば、より深い洞察が得られるだろう。これはまた、学習アルゴリズムにおいてアンサンブルを構築する際にも便利な場合がある。以下では、GGallyパッケージのggpairs関数を使って、Sonarデータセットで学習を行った場合のmmceの散布図行列を作成する例を見てみよう。 (訳注:ここも書き換えている) pref = getBMRPerformances(bmr, task.id = &quot;Sonar-example&quot;, as.df = TRUE) df = tidyr::gather(pref, key = variable, value = value, mmce:timetrain) df = dplyr::filter(df, variable == &quot;mmce&quot;) df = tidyr::spread(df, key = learner.id, value = value) GGally::ggpairs(df, 4:6) 10.5 その他のコメント 教師あり学習については、mlrはBenchmarkResultオブジェクトを使用して学習アルゴリズムを比較するためのプロットをさらにいくつか提供している。以下のページに例がある。 ROC Analysis - mlr tutorial generateThreshVsPerfData function | R Documentation plotROCCurves function | R Documentation plotViperCharts function | R Documentation Classifier Calibration Plots - mlr tutorial generateCalibrationData function | R Documentation このセクションの例では「生の」学習アルゴリズムを用いたが、通常はもっと事は複雑である。少なくとも、大抵の学習アルゴリズムは調整すべきハイパーパラメータを持っている。信頼性のある性能指標の推定値を得るためには、nested resampling、すなわち、内側のループでハイパーパラメータをチューニングしつつ外側のループで性能指標を推定するといった作業が必要になる。さらに、補完やスケーリング、外れ値除去、次元削減、特徴量選択などの前処理を組み合わせたい場合もあるだろう。これらの全ての作業はmlrのラッパー機能を使用すると容易に実行できる。より詳しい話はチュートリアルのAdvancedパートで説明する。 -ベンチマーク試験を行っていくと、すぐに多量の計算量が必要となるはずだ。mlrはこの問題に対応するため、並列計算の可能性をいくつか提供している。 "]
]
